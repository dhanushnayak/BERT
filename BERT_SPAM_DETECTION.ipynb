{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_SPAM_DETECTION.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM6+DfYqgtWZXugGHyKwW7t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cfb0df77c85047db9870caa8683eb231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de41afbd592744509f9a9f24b4749255",
              "IPY_MODEL_55c4329b49e34de5a1e96f9c885d20ee",
              "IPY_MODEL_927cd149b6534e1ab232bab0fcb3ecf3"
            ],
            "layout": "IPY_MODEL_471fc6b1f42d4d40805ad964f6473d9f"
          }
        },
        "de41afbd592744509f9a9f24b4749255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94773860194e4b3eb2d74bfaa2d06fae",
            "placeholder": "​",
            "style": "IPY_MODEL_175de363959f4781912330d0dbf7ccfc",
            "value": "Downloading: 100%"
          }
        },
        "55c4329b49e34de5a1e96f9c885d20ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a25c7dbf6514a62af38f03668207589",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c204eb0e6c2410fb55b7aa970249427",
            "value": 231508
          }
        },
        "927cd149b6534e1ab232bab0fcb3ecf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c44f9339a0e4014ad95e93e33114e96",
            "placeholder": "​",
            "style": "IPY_MODEL_901b4bfb3d454916aa4f91b7e93ca3d6",
            "value": " 226k/226k [00:00&lt;00:00, 903kB/s]"
          }
        },
        "471fc6b1f42d4d40805ad964f6473d9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94773860194e4b3eb2d74bfaa2d06fae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175de363959f4781912330d0dbf7ccfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a25c7dbf6514a62af38f03668207589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c204eb0e6c2410fb55b7aa970249427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c44f9339a0e4014ad95e93e33114e96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "901b4bfb3d454916aa4f91b7e93ca3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "326dcf4e1e33410d9d0ca8bff639d1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4351273ec16b451aa95ca812fada48d4",
              "IPY_MODEL_86b1531c7b7346e4b8cbd147d8588744",
              "IPY_MODEL_84dbe1074b8f45a590ba118acb8d47d9"
            ],
            "layout": "IPY_MODEL_815da6bfe29e48fc9fb6d3cbf8087978"
          }
        },
        "4351273ec16b451aa95ca812fada48d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_082e1867b102437eba6166049352baae",
            "placeholder": "​",
            "style": "IPY_MODEL_192aecea83af4dd28b9fd0c1f822475e",
            "value": "Downloading: 100%"
          }
        },
        "86b1531c7b7346e4b8cbd147d8588744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_365993dd188247c3ad4633b0f1c8f395",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e06e95a19da44b7e9fe7547de9673e75",
            "value": 28
          }
        },
        "84dbe1074b8f45a590ba118acb8d47d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54136931b8a84f5d9b18207f093296b0",
            "placeholder": "​",
            "style": "IPY_MODEL_f05d622d590f4d6c91fdfd0f1dd98945",
            "value": " 28.0/28.0 [00:00&lt;00:00, 800B/s]"
          }
        },
        "815da6bfe29e48fc9fb6d3cbf8087978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "082e1867b102437eba6166049352baae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192aecea83af4dd28b9fd0c1f822475e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "365993dd188247c3ad4633b0f1c8f395": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e06e95a19da44b7e9fe7547de9673e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54136931b8a84f5d9b18207f093296b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f05d622d590f4d6c91fdfd0f1dd98945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38484fe247a64931bdfa9511657ead78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff660ae741ca401f80dd75b6534409db",
              "IPY_MODEL_31d32483b4ac4e169a7f20ba98d8d3cf",
              "IPY_MODEL_07498f71c2cb4b86aa7aecd7d24e1bc7"
            ],
            "layout": "IPY_MODEL_33cb20482528414fbaf57000d62eb465"
          }
        },
        "ff660ae741ca401f80dd75b6534409db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3458b22570941b4ac2ea8cc87a16343",
            "placeholder": "​",
            "style": "IPY_MODEL_c40aef8fd53a41e1aa9a200d1402c0ec",
            "value": "Downloading: 100%"
          }
        },
        "31d32483b4ac4e169a7f20ba98d8d3cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de5ab530b36d43f7875f04a0e2958855",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ddc9518feda48558374def44dbe22c2",
            "value": 570
          }
        },
        "07498f71c2cb4b86aa7aecd7d24e1bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5424e3264d3044ff8abd13d5d140b007",
            "placeholder": "​",
            "style": "IPY_MODEL_1a40ced0c1304c258c950eeb4899b008",
            "value": " 570/570 [00:00&lt;00:00, 18.4kB/s]"
          }
        },
        "33cb20482528414fbaf57000d62eb465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3458b22570941b4ac2ea8cc87a16343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c40aef8fd53a41e1aa9a200d1402c0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de5ab530b36d43f7875f04a0e2958855": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ddc9518feda48558374def44dbe22c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5424e3264d3044ff8abd13d5d140b007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a40ced0c1304c258c950eeb4899b008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhanushnayak/BERT/blob/main/BERT_SPAM_DETECTION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8blofy9GI2F",
        "outputId": "8f396a6e-5903-4cd1-8c5e-436e89979aa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 8.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 55.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 14.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 70.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "BSXIzZ4kH10O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/spam.csv\",encoding=\"ISO-8859-1\").iloc[:,:2]"
      ],
      "metadata": {
        "id": "9IKUS40IIALK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = df.iloc[:,1].to_list()\n",
        "y = df.iloc[:,0].map({\"spam\":1,\"ham\":0}).to_list()"
      ],
      "metadata": {
        "id": "LoymxxgAIGmp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)"
      ],
      "metadata": {
        "id": "tLnZhS-rI-Vi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer,BertForSequenceClassification,TrainingArguments,Trainer"
      ],
      "metadata": {
        "id": "LYfqlxUlJOaT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\",do_lower_case=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "cfb0df77c85047db9870caa8683eb231",
            "de41afbd592744509f9a9f24b4749255",
            "55c4329b49e34de5a1e96f9c885d20ee",
            "927cd149b6534e1ab232bab0fcb3ecf3",
            "471fc6b1f42d4d40805ad964f6473d9f",
            "94773860194e4b3eb2d74bfaa2d06fae",
            "175de363959f4781912330d0dbf7ccfc",
            "0a25c7dbf6514a62af38f03668207589",
            "2c204eb0e6c2410fb55b7aa970249427",
            "9c44f9339a0e4014ad95e93e33114e96",
            "901b4bfb3d454916aa4f91b7e93ca3d6",
            "326dcf4e1e33410d9d0ca8bff639d1a4",
            "4351273ec16b451aa95ca812fada48d4",
            "86b1531c7b7346e4b8cbd147d8588744",
            "84dbe1074b8f45a590ba118acb8d47d9",
            "815da6bfe29e48fc9fb6d3cbf8087978",
            "082e1867b102437eba6166049352baae",
            "192aecea83af4dd28b9fd0c1f822475e",
            "365993dd188247c3ad4633b0f1c8f395",
            "e06e95a19da44b7e9fe7547de9673e75",
            "54136931b8a84f5d9b18207f093296b0",
            "f05d622d590f4d6c91fdfd0f1dd98945",
            "38484fe247a64931bdfa9511657ead78",
            "ff660ae741ca401f80dd75b6534409db",
            "31d32483b4ac4e169a7f20ba98d8d3cf",
            "07498f71c2cb4b86aa7aecd7d24e1bc7",
            "33cb20482528414fbaf57000d62eb465",
            "e3458b22570941b4ac2ea8cc87a16343",
            "c40aef8fd53a41e1aa9a200d1402c0ec",
            "de5ab530b36d43f7875f04a0e2958855",
            "3ddc9518feda48558374def44dbe22c2",
            "5424e3264d3044ff8abd13d5d140b007",
            "1a40ced0c1304c258c950eeb4899b008"
          ]
        },
        "id": "YtNS0w_WJuV2",
        "outputId": "d6af6142-b780-4462-e7a7-ac2d2339e96f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfb0df77c85047db9870caa8683eb231"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "326dcf4e1e33410d9d0ca8bff639d1a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38484fe247a64931bdfa9511657ead78"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encoding = tokenizer(x_train,padding=True)\n",
        "test_encoding = tokenizer(x_test,padding=True)"
      ],
      "metadata": {
        "id": "b41v3FkAJ5aX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_encoding.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R41W54fLKgfS",
        "outputId": "51305fe1-240f-4f28-ff92-28f0fee3218b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a306nxwRLse8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset,Dataset\n",
        "class CreateDataset(Dataset):\n",
        "  def __init__(self,encoding,labels):\n",
        "    self.encoding = encoding\n",
        "    self.labels = labels\n",
        "  def __getitem__(self,idx):\n",
        "    item = {key: torch.tensor(val[idx]) for key,val in self.encoding.items()}\n",
        "    item['labels']=torch.tensor(self.labels[idx])\n",
        "    return item\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "trainset = CreateDataset(train_encoding,y_train)\n",
        "\n",
        "testset = CreateDataset(test_encoding,y_test)"
      ],
      "metadata": {
        "id": "pjgIi05yKroK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uKaJoeaM-5d",
        "outputId": "44269c80-a835-4ebb-9e55-6fd6bfcf25f2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "  output_dir=\"/content/outmodel\", \n",
        "  overwrite_output_dir=True,\n",
        "  logging_dir='/logs',\n",
        "  num_train_epochs=1,\n",
        "  logging_steps=10,\n",
        "  per_device_train_batch_size=16,\n",
        "  per_device_eval_batch_size=64,\n",
        "  weight_decay=0.1,\n",
        "  learning_rate=1e-5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJFNjkGHNhij",
        "outputId": "c3e2ce88-277b-49d0-9224-079861cb74d0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LVK6ubtVacn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=trainset,\n",
        "    eval_dataset= testset\n",
        ")"
      ],
      "metadata": {
        "id": "FhKsiBFbNhlJ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_nu-RHX8PNjS",
        "outputId": "77422f4d-27c3-4016-a2e3-7af959a0f847"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3900\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 244\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='244' max='244' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [244/244 02:36, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.050900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.042800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.024800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.021900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.013900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.003200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.024900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.011700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.046600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.042000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>0.071100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>0.022800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>0.001500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.012000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.004200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.035900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.037300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.042300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.102500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=244, training_loss=0.025517721967695313, metrics={'train_runtime': 157.6202, 'train_samples_per_second': 24.743, 'train_steps_per_second': 1.548, 'total_flos': 442920739482000.0, 'train_loss': 0.025517721967695313, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yZ5S7z36adcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"/content/modelr\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2SrvyaEadlG",
        "outputId": "9ffe58b7-b711-4a17-9fd1-d3d26e0e533d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/modelr\n",
            "Configuration saved in /content/modelr/config.json\n",
            "Model weights saved in /content/modelr/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "3jyDb-YkZqV0"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_r = pipeline(\"text-classification\",model=\"/content/modelr\",tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9m1CwmuZyXT",
        "outputId": "599b38e9-472d-4060-f23c-ec841b7bbda4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/modelr/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"/content/modelr\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file /content/modelr/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"/content/modelr\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file /content/modelr/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/modelr.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_r(x_test[9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0MXk2L2anbc",
        "outputId": "2d06ce6c-448d-4411-eb7a-c895415b511f"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'LABEL_1', 'score': 0.9980745315551758}]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[9],x_test[9]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuyGWeIparWP",
        "outputId": "1c46fda8-be85-4a49-c339-f2d70760d577"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,\n",
              " 'REMINDER FROM O2: To get 2.50 pounds free call credit and details of great offers pls reply 2 this text with your valid name, house no and postcode')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cjN8LNCEO212"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LaQExzWkO24x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from transformers import AdamW\n",
        "\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQyNULLeO292",
        "outputId": "51edd2d9-a4ce-46ed-cc5d-5058792fc458"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "optim = AdamW(model.parameters(),lr=5e-5)\n",
        "train_loader = DataLoader(trainset,batch_size=16,shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvUihilNPl4d",
        "outputId": "f19404b0-efd1-40d8-b819-8fdcce72c04a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epoch = 5\n",
        "for _ in range(num_epoch):\n",
        "  for train_batch in train_loader:\n",
        "    optim.zero_grad()\n",
        "    input_ids = train_batch['input_ids'].to(device)\n",
        "    attention_mask = train_batch['attention_mask'].to(device)\n",
        "    labels = train_batch['labels'].to(device)\n",
        "\n",
        "    out = model(input_ids,attention_mask=attention_mask,labels=labels)\n",
        "    print(_,out)\n",
        "    loss = out[0]\n",
        "    loss.backward()\n",
        "    optim.step()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf8NoUj-P-pd",
        "outputId": "6f7b412a-19bb-4ff9-9a22-b2d2956e27a3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "3 SequenceClassifierOutput(loss=tensor(0.2893, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.8651, -3.2679],\n",
            "        [-0.3678, -0.3180],\n",
            "        [-3.1621,  3.3722],\n",
            "        [ 3.3273, -3.7436],\n",
            "        [ 3.1828, -3.6186],\n",
            "        [ 3.0621, -3.4511],\n",
            "        [-3.1618,  3.6586],\n",
            "        [ 3.0714, -3.4998],\n",
            "        [ 3.1687, -3.6821],\n",
            "        [-3.2539,  3.6640],\n",
            "        [ 3.0199, -3.5165],\n",
            "        [-1.8690,  2.0015],\n",
            "        [ 3.0535, -3.5896],\n",
            "        [-3.3263,  3.6447],\n",
            "        [ 3.1001, -3.5307],\n",
            "        [ 2.8543, -3.3358]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.0234, -3.4804],\n",
            "        [ 2.8081, -3.2423],\n",
            "        [ 3.1370, -3.7092],\n",
            "        [ 2.3649, -3.1364],\n",
            "        [ 3.1446, -3.7445],\n",
            "        [ 2.6954, -3.0616],\n",
            "        [ 3.1271, -3.6533],\n",
            "        [ 3.2441, -3.8389],\n",
            "        [ 3.1529, -3.7027],\n",
            "        [ 2.9986, -3.5210],\n",
            "        [ 3.0587, -3.6005],\n",
            "        [ 2.9793, -3.3157],\n",
            "        [ 2.6665, -3.1611],\n",
            "        [-3.2357,  3.4514],\n",
            "        [-3.2612,  3.4340],\n",
            "        [ 3.0131, -3.4135]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.9731, -3.6171],\n",
            "        [ 3.0335, -3.4618],\n",
            "        [-1.8773,  1.9881],\n",
            "        [ 3.0857, -3.5654],\n",
            "        [ 3.0544, -3.5173],\n",
            "        [-2.3582,  2.4091],\n",
            "        [-2.9158,  3.1432],\n",
            "        [-1.5960,  1.8106],\n",
            "        [ 3.2223, -3.7473],\n",
            "        [ 3.1593, -3.7890],\n",
            "        [ 2.8893, -3.2979],\n",
            "        [ 2.9531, -3.3534],\n",
            "        [-2.9197,  2.9546],\n",
            "        [ 3.1258, -3.6785],\n",
            "        [ 2.9446, -3.3236],\n",
            "        [ 2.9669, -3.3421]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.8516, -3.2884],\n",
            "        [ 2.8959, -3.2902],\n",
            "        [ 3.1800, -3.6294],\n",
            "        [-2.1778,  2.1451],\n",
            "        [-1.0902,  1.1220],\n",
            "        [ 3.0277, -3.6819],\n",
            "        [ 3.1718, -3.6670],\n",
            "        [ 3.0541, -3.4495],\n",
            "        [ 2.9453, -3.5851],\n",
            "        [ 2.7475, -3.1250],\n",
            "        [ 2.9006, -3.3102],\n",
            "        [ 3.1903, -3.7236],\n",
            "        [ 3.1165, -3.5935],\n",
            "        [ 3.0690, -3.5727],\n",
            "        [-2.3431,  2.4590],\n",
            "        [ 3.1098, -3.5081]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.8703, -3.2638],\n",
            "        [ 3.0211, -3.4334],\n",
            "        [ 3.1702, -3.7449],\n",
            "        [-2.1893,  2.3536],\n",
            "        [ 1.0038, -1.9617],\n",
            "        [ 3.1376, -3.6776],\n",
            "        [ 3.2048, -3.7364],\n",
            "        [ 2.8897, -3.2887],\n",
            "        [ 3.1222, -3.5413],\n",
            "        [ 2.8525, -3.4175],\n",
            "        [ 2.9580, -3.3863],\n",
            "        [ 2.9268, -3.3752],\n",
            "        [ 3.1657, -3.6628],\n",
            "        [ 3.0470, -3.4315],\n",
            "        [ 3.0942, -3.5392],\n",
            "        [ 3.0834, -3.5780]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.8867, -3.4772],\n",
            "        [ 3.1395, -3.7167],\n",
            "        [ 3.0991, -3.5930],\n",
            "        [ 2.7620, -3.5078],\n",
            "        [ 2.9934, -3.4817],\n",
            "        [ 3.0425, -3.5064],\n",
            "        [ 3.0182, -3.4897],\n",
            "        [ 3.1148, -3.5726],\n",
            "        [ 3.1753, -3.7088],\n",
            "        [ 3.0304, -3.6588],\n",
            "        [ 2.9951, -3.5033],\n",
            "        [ 3.0863, -3.5040],\n",
            "        [ 3.0505, -3.4329],\n",
            "        [ 3.1636, -3.6327],\n",
            "        [ 3.0517, -3.4466],\n",
            "        [ 3.1426, -3.6806]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.9387, -3.5253],\n",
            "        [ 3.1354, -3.5048],\n",
            "        [ 2.9228, -3.3498],\n",
            "        [ 3.1455, -3.6658],\n",
            "        [ 2.6495, -3.4352],\n",
            "        [-0.4612,  0.3279],\n",
            "        [ 3.0729, -3.4656],\n",
            "        [-0.7597,  0.8194],\n",
            "        [ 3.0763, -3.6312],\n",
            "        [ 2.2949, -3.1444],\n",
            "        [ 3.1810, -3.7076],\n",
            "        [ 3.1351, -3.6758],\n",
            "        [ 3.0254, -3.6919],\n",
            "        [ 3.0201, -3.4437],\n",
            "        [ 2.9961, -3.5706],\n",
            "        [ 3.1187, -3.5745]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.0742,  1.2997],\n",
            "        [ 3.0494, -3.4381],\n",
            "        [ 3.1776, -3.6914],\n",
            "        [ 3.1087, -3.7350],\n",
            "        [ 3.1741, -3.7271],\n",
            "        [ 3.0392, -3.4770],\n",
            "        [ 3.0518, -3.4656],\n",
            "        [ 2.8505, -3.2509],\n",
            "        [ 2.9872, -3.4864],\n",
            "        [ 2.9546, -3.2934],\n",
            "        [ 3.0887, -3.5904],\n",
            "        [ 2.9632, -3.3919],\n",
            "        [ 3.1451, -3.7103],\n",
            "        [-1.8097,  1.9636],\n",
            "        [-0.8483,  0.9667],\n",
            "        [ 2.8459, -3.2645]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0323, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.0864, -3.5671],\n",
            "        [ 2.8844, -3.2457],\n",
            "        [-0.4656,  0.4830],\n",
            "        [ 2.7944, -3.1917],\n",
            "        [ 3.0578, -3.5266],\n",
            "        [ 2.9497, -3.3566],\n",
            "        [ 3.0036, -3.3578],\n",
            "        [ 3.2056, -3.7189],\n",
            "        [ 3.2017, -3.7069],\n",
            "        [ 3.0102, -3.4615],\n",
            "        [ 3.1086, -3.5114],\n",
            "        [ 3.0574, -3.6203],\n",
            "        [ 3.1606, -3.7540],\n",
            "        [-0.9575,  1.0711],\n",
            "        [-1.4399,  1.6063],\n",
            "        [ 2.8687, -3.4271]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.2478, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 0.3622, -1.1249],\n",
            "        [ 2.9791, -3.5094],\n",
            "        [ 3.1379, -3.5897],\n",
            "        [ 3.1397, -3.6211],\n",
            "        [ 2.9586, -3.3926],\n",
            "        [ 3.1203, -3.6332],\n",
            "        [ 3.0707, -3.6402],\n",
            "        [ 0.6140, -1.5296],\n",
            "        [ 2.9608, -3.4810],\n",
            "        [ 3.0511, -3.6571],\n",
            "        [ 3.1145, -3.6533],\n",
            "        [ 3.1414, -3.6135],\n",
            "        [ 3.0764, -3.5299],\n",
            "        [ 3.0041, -3.4564],\n",
            "        [ 2.9762, -3.3771],\n",
            "        [ 3.0862, -3.6680]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.8094,  2.9760],\n",
            "        [ 3.1808, -3.5793],\n",
            "        [ 2.9176, -3.2790],\n",
            "        [ 3.0821, -3.7007],\n",
            "        [ 2.9525, -3.5387],\n",
            "        [ 3.0882, -3.5532],\n",
            "        [ 3.0563, -3.6105],\n",
            "        [ 3.0493, -3.6622],\n",
            "        [ 2.9964, -3.4536],\n",
            "        [ 3.1722, -3.6836],\n",
            "        [-1.5194,  1.6763],\n",
            "        [ 3.0954, -3.7256],\n",
            "        [ 3.0555, -3.5633],\n",
            "        [ 3.0309, -3.6069],\n",
            "        [ 3.1993, -3.6092],\n",
            "        [ 3.1394, -3.6204]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.0849, -3.4868],\n",
            "        [ 3.0409, -3.6336],\n",
            "        [ 2.7224, -3.1133],\n",
            "        [ 3.1559, -3.6637],\n",
            "        [ 3.1196, -3.6851],\n",
            "        [ 3.0665, -3.5876],\n",
            "        [ 3.0687, -3.5646],\n",
            "        [ 3.0532, -3.4650],\n",
            "        [ 3.1023, -3.6053],\n",
            "        [ 3.1407, -3.7233],\n",
            "        [ 3.0646, -3.4784],\n",
            "        [ 3.0852, -3.5970],\n",
            "        [ 3.1076, -3.6580],\n",
            "        [ 3.0596, -3.5743],\n",
            "        [ 3.1163, -3.6976],\n",
            "        [ 2.8291, -3.2331]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.0964, -3.6159],\n",
            "        [ 3.0100, -3.5773],\n",
            "        [ 3.0221, -3.5107],\n",
            "        [ 3.0127, -3.4492],\n",
            "        [ 3.0776, -3.6177],\n",
            "        [ 3.1509, -3.6916],\n",
            "        [ 3.0566, -3.5466],\n",
            "        [ 3.1299, -3.6006],\n",
            "        [-3.1709,  3.4382],\n",
            "        [ 3.0874, -3.5350],\n",
            "        [ 3.0188, -3.5830],\n",
            "        [ 3.0867, -3.7040],\n",
            "        [ 3.0662, -3.5358],\n",
            "        [ 2.8024, -3.1960],\n",
            "        [ 3.1967, -3.6665],\n",
            "        [ 3.1188, -3.5807]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.8565, -3.5316],\n",
            "        [ 3.1545, -3.6276],\n",
            "        [ 3.0392, -3.5083],\n",
            "        [ 3.1544, -3.7384],\n",
            "        [-3.1634,  3.4021],\n",
            "        [ 3.0329, -3.5375],\n",
            "        [ 2.9757, -3.3916],\n",
            "        [ 3.0527, -3.5679],\n",
            "        [ 3.0378, -3.5572],\n",
            "        [ 3.0242, -3.4153],\n",
            "        [ 3.0549, -3.5302],\n",
            "        [-2.0589,  2.2753],\n",
            "        [-3.1612,  3.3704],\n",
            "        [ 3.0884, -3.4694],\n",
            "        [ 3.0707, -3.5953],\n",
            "        [ 3.0518, -3.5465]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.1703, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.9512, -3.3788],\n",
            "        [-3.2010,  3.4197],\n",
            "        [ 3.2073, -3.6504],\n",
            "        [ 2.9268, -3.3606],\n",
            "        [ 3.1215, -3.6717],\n",
            "        [ 3.0189, -3.6195],\n",
            "        [-3.2127,  3.4782],\n",
            "        [ 3.0377, -3.5787],\n",
            "        [ 3.0692, -3.5269],\n",
            "        [ 2.9314, -3.4858],\n",
            "        [ 2.9611, -3.3780],\n",
            "        [ 3.0083, -3.4109],\n",
            "        [ 2.7865, -3.1820],\n",
            "        [ 3.1534, -3.6601],\n",
            "        [ 3.1345, -3.6330],\n",
            "        [ 0.9625, -1.6711]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.8884, -3.4993],\n",
            "        [ 3.0103, -3.4487],\n",
            "        [ 3.1499, -3.6564],\n",
            "        [ 2.9724, -3.4498],\n",
            "        [ 3.0940, -3.5267],\n",
            "        [-3.1577,  3.4589],\n",
            "        [ 3.0883, -3.5350],\n",
            "        [ 2.9789, -3.3774],\n",
            "        [ 2.9055, -3.3143],\n",
            "        [ 3.1383, -3.5709],\n",
            "        [ 3.0069, -3.5328],\n",
            "        [ 2.9337, -3.3102],\n",
            "        [ 3.1039, -3.6706],\n",
            "        [ 3.1144, -3.6206],\n",
            "        [-3.1990,  3.4967],\n",
            "        [ 3.0875, -3.5213]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.0886, -3.6098],\n",
            "        [ 3.1180, -3.6121],\n",
            "        [ 2.9448, -3.3660],\n",
            "        [ 2.9537, -3.5039],\n",
            "        [ 3.1090, -3.5444],\n",
            "        [ 2.9922, -3.4259],\n",
            "        [ 3.0481, -3.5980],\n",
            "        [ 3.0586, -3.5058],\n",
            "        [ 2.6438, -3.5018],\n",
            "        [ 3.1096, -3.6787],\n",
            "        [ 2.8968, -3.5081],\n",
            "        [ 2.8706, -3.4726],\n",
            "        [ 2.9469, -3.4773],\n",
            "        [ 3.0048, -3.4388],\n",
            "        [ 3.0085, -3.5513],\n",
            "        [ 2.9738, -3.4923]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.9017, -3.3020],\n",
            "        [ 3.0306, -3.4877],\n",
            "        [ 2.9906, -3.5790],\n",
            "        [ 3.1105, -3.6353],\n",
            "        [ 3.0158, -3.5538],\n",
            "        [ 3.1007, -3.6241],\n",
            "        [ 3.0294, -3.5458],\n",
            "        [ 3.0621, -3.5465],\n",
            "        [ 3.0644, -3.5845],\n",
            "        [ 3.0050, -3.6482],\n",
            "        [ 2.9414, -3.4967],\n",
            "        [-3.2439,  3.4618],\n",
            "        [ 3.1550, -3.5544],\n",
            "        [ 2.9301, -3.4290],\n",
            "        [ 2.8954, -3.4495],\n",
            "        [-3.2984,  3.4853]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.9462, -3.5171],\n",
            "        [ 2.9934, -3.5443],\n",
            "        [ 2.9139, -3.4162],\n",
            "        [ 3.0554, -3.4736],\n",
            "        [-3.2243,  3.5119],\n",
            "        [-1.7360,  1.9345],\n",
            "        [ 2.8557, -3.4282],\n",
            "        [ 2.8909, -3.3923],\n",
            "        [ 2.6563, -3.2608],\n",
            "        [ 2.7489, -3.4394],\n",
            "        [ 2.6543, -3.2783],\n",
            "        [ 3.0040, -3.5315],\n",
            "        [ 3.0957, -3.5744],\n",
            "        [ 3.0508, -3.4788],\n",
            "        [ 2.9995, -3.4789],\n",
            "        [ 3.0651, -3.5586]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.0432, -3.5227],\n",
            "        [ 2.9567, -3.4260],\n",
            "        [ 2.9711, -3.5932],\n",
            "        [ 2.8164, -3.3685],\n",
            "        [ 2.9128, -3.4814],\n",
            "        [ 3.0272, -3.5004],\n",
            "        [ 3.0970, -3.5952],\n",
            "        [ 2.8947, -3.3168],\n",
            "        [ 3.0884, -3.5282],\n",
            "        [ 2.9468, -3.4723],\n",
            "        [ 3.0297, -3.5486],\n",
            "        [ 3.0177, -3.5828],\n",
            "        [ 3.1183, -3.5781],\n",
            "        [-3.1785,  3.5160],\n",
            "        [ 2.9307, -3.3604],\n",
            "        [ 2.8290, -3.4687]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.2386,  3.5154],\n",
            "        [ 2.8644, -3.2437],\n",
            "        [ 3.0146, -3.4096],\n",
            "        [ 2.7148, -3.2190],\n",
            "        [ 2.8732, -3.3110],\n",
            "        [ 2.9930, -3.5445],\n",
            "        [ 3.0009, -3.5457],\n",
            "        [ 2.5724, -3.1235],\n",
            "        [ 3.0789, -3.5880],\n",
            "        [ 2.5913, -3.2143],\n",
            "        [ 3.0305, -3.4415],\n",
            "        [ 2.7300, -3.3350],\n",
            "        [ 3.0297, -3.5383],\n",
            "        [ 1.7045, -2.3358],\n",
            "        [ 3.0090, -3.5178],\n",
            "        [ 2.9336, -3.4202]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.8824, -3.3101],\n",
            "        [-3.2175,  3.4588],\n",
            "        [-3.0765,  3.3910],\n",
            "        [ 3.0136, -3.5484],\n",
            "        [-3.2345,  3.5051],\n",
            "        [ 2.9216, -3.3626],\n",
            "        [ 2.8909, -3.3776],\n",
            "        [ 2.9651, -3.5274],\n",
            "        [ 2.9604, -3.3928],\n",
            "        [ 2.8752, -3.4486],\n",
            "        [ 2.9570, -3.3625],\n",
            "        [ 3.0188, -3.5254],\n",
            "        [ 2.9425, -3.5012],\n",
            "        [ 2.8510, -3.1920],\n",
            "        [ 2.9876, -3.4898],\n",
            "        [ 2.9683, -3.4515]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.9197, -3.4451],\n",
            "        [ 2.9430, -3.3667],\n",
            "        [ 3.0464, -3.5414],\n",
            "        [ 2.7383, -3.2817],\n",
            "        [ 2.6599, -3.2894],\n",
            "        [ 2.9882, -3.4716],\n",
            "        [ 2.9506, -3.4058],\n",
            "        [ 3.0240, -3.3974],\n",
            "        [ 3.0402, -3.5018],\n",
            "        [ 3.0176, -3.4908],\n",
            "        [ 2.9617, -3.4314],\n",
            "        [ 3.0505, -3.5709],\n",
            "        [ 3.0026, -3.4757],\n",
            "        [ 2.8920, -3.4301],\n",
            "        [ 2.9576, -3.4553],\n",
            "        [ 2.8672, -3.4504]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.9535, -3.4459],\n",
            "        [ 2.7253, -3.3428],\n",
            "        [ 2.8158, -3.4370],\n",
            "        [ 2.9349, -3.4219],\n",
            "        [ 2.5960, -3.1979],\n",
            "        [ 3.0507, -3.5390],\n",
            "        [ 2.9907, -3.3514],\n",
            "        [ 2.9479, -3.3669],\n",
            "        [ 2.9447, -3.4844],\n",
            "        [ 3.1093, -3.5746],\n",
            "        [ 2.7590, -3.3867],\n",
            "        [ 3.1212, -3.5861],\n",
            "        [-3.1949,  3.4341],\n",
            "        [ 2.9758, -3.5054],\n",
            "        [ 2.7092, -3.3082],\n",
            "        [ 2.9371, -3.4227]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.0990, -3.5954],\n",
            "        [ 3.0332, -3.5449],\n",
            "        [ 2.9660, -3.4216],\n",
            "        [ 2.9106, -3.3549],\n",
            "        [ 2.8054, -3.2227],\n",
            "        [ 2.8745, -3.4778],\n",
            "        [ 2.0925, -2.7996],\n",
            "        [ 2.9521, -3.3348],\n",
            "        [ 3.0687, -3.5208],\n",
            "        [ 2.6983, -3.2891],\n",
            "        [ 2.8477, -3.3379],\n",
            "        [ 2.6489, -3.1668],\n",
            "        [ 3.0288, -3.4577],\n",
            "        [ 2.8281, -3.4301],\n",
            "        [ 3.0367, -3.5297],\n",
            "        [ 3.0322, -3.5318]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.0817, -3.5423],\n",
            "        [ 3.0855, -3.6024],\n",
            "        [ 2.9001, -3.3950],\n",
            "        [ 2.8762, -3.3773],\n",
            "        [ 3.0801, -3.5342],\n",
            "        [ 3.0623, -3.4936],\n",
            "        [ 3.0048, -3.4649],\n",
            "        [ 2.9236, -3.4463],\n",
            "        [ 2.9795, -3.4236],\n",
            "        [ 3.0565, -3.4689],\n",
            "        [ 2.9157, -3.4596],\n",
            "        [ 2.6063, -3.1800],\n",
            "        [ 3.0541, -3.5552],\n",
            "        [ 2.6994, -3.2290],\n",
            "        [ 2.8711, -3.2785],\n",
            "        [ 3.0689, -3.4870]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.0559, -3.4241],\n",
            "        [ 0.5663, -1.2639],\n",
            "        [ 2.3266, -2.9577],\n",
            "        [ 1.7857, -2.4299],\n",
            "        [ 2.5818, -3.2370],\n",
            "        [ 2.7662, -3.4414],\n",
            "        [ 2.4249, -3.0591],\n",
            "        [ 3.0860, -3.6046],\n",
            "        [ 1.9469, -2.5525],\n",
            "        [ 2.7477, -3.3073],\n",
            "        [ 2.8052, -3.2157],\n",
            "        [ 2.8071, -3.3622],\n",
            "        [ 2.8791, -3.4148],\n",
            "        [ 3.0761, -3.5026],\n",
            "        [ 2.3496, -2.9842],\n",
            "        [ 3.0365, -3.4267]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.9868, -3.5316],\n",
            "        [ 2.9842, -3.4558],\n",
            "        [ 2.8783, -3.4771],\n",
            "        [ 2.9684, -3.3629],\n",
            "        [ 2.9946, -3.5075],\n",
            "        [-3.2106,  3.4581],\n",
            "        [-3.3305,  3.4178],\n",
            "        [ 3.0354, -3.4786],\n",
            "        [ 2.8742, -3.2797],\n",
            "        [-3.2835,  3.4935],\n",
            "        [ 3.1529, -3.6082],\n",
            "        [-0.2645, -0.3780],\n",
            "        [ 2.9549, -3.3861],\n",
            "        [ 3.0415, -3.5040],\n",
            "        [ 3.1028, -3.6309],\n",
            "        [ 0.6545, -1.3589]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.0824, -3.5642],\n",
            "        [ 3.0635, -3.5399],\n",
            "        [ 2.2867, -2.8323],\n",
            "        [ 2.9567, -3.4869],\n",
            "        [ 1.7278, -2.4562],\n",
            "        [ 3.0714, -3.5201],\n",
            "        [ 2.9508, -3.4536],\n",
            "        [-3.2910,  3.4965],\n",
            "        [-3.1757,  3.4992],\n",
            "        [ 2.9557, -3.5718],\n",
            "        [ 3.0461, -3.5030],\n",
            "        [ 3.1046, -3.6585],\n",
            "        [ 2.8967, -3.4012],\n",
            "        [ 2.9685, -3.5891],\n",
            "        [ 2.7669, -3.3036],\n",
            "        [ 3.0917, -3.6617]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.1844, -3.6442],\n",
            "        [ 3.0218, -3.4959],\n",
            "        [ 2.6209, -3.2187],\n",
            "        [ 3.0613, -3.5515],\n",
            "        [ 2.8330, -3.3964],\n",
            "        [ 3.1640, -3.6956],\n",
            "        [ 2.8796, -3.4199],\n",
            "        [ 3.2245, -3.5850],\n",
            "        [ 3.1433, -3.6517],\n",
            "        [ 3.0444, -3.5770],\n",
            "        [ 3.1536, -3.6644],\n",
            "        [ 2.9902, -3.5363],\n",
            "        [ 3.1130, -3.5965],\n",
            "        [ 3.0329, -3.5295],\n",
            "        [ 3.1343, -3.7008],\n",
            "        [ 3.0807, -3.6095]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.2350, -3.7002],\n",
            "        [ 3.0726, -3.5848],\n",
            "        [ 3.0001, -3.5612],\n",
            "        [ 3.1997, -3.6302],\n",
            "        [ 2.8649, -3.3664],\n",
            "        [ 3.2506, -3.7153],\n",
            "        [ 2.9267, -3.4320],\n",
            "        [ 2.7635, -3.2986],\n",
            "        [ 2.7399, -3.2425],\n",
            "        [ 2.5313, -3.2062],\n",
            "        [ 3.0648, -3.5301],\n",
            "        [ 3.0366, -3.5846],\n",
            "        [ 2.9890, -3.5108],\n",
            "        [ 3.0366, -3.5846],\n",
            "        [ 3.2138, -3.7333],\n",
            "        [ 3.0216, -3.5295]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.2058, -3.6540],\n",
            "        [ 3.1369, -3.6793],\n",
            "        [ 3.0749, -3.6315],\n",
            "        [ 3.1130, -3.6448],\n",
            "        [-3.2212,  3.4524],\n",
            "        [-3.2261,  3.4881],\n",
            "        [ 3.2559, -3.7722],\n",
            "        [-2.2119,  2.4075],\n",
            "        [ 3.1819, -3.7357],\n",
            "        [ 3.1795, -3.7501],\n",
            "        [ 3.2552, -3.7378],\n",
            "        [ 3.1989, -3.7067],\n",
            "        [ 3.0845, -3.6415],\n",
            "        [ 3.1573, -3.6663],\n",
            "        [ 3.1480, -3.6934],\n",
            "        [ 3.0923, -3.6008]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.3027, -3.7584],\n",
            "        [ 3.1961, -3.6508],\n",
            "        [ 3.1433, -3.6384],\n",
            "        [ 2.9796, -3.5501],\n",
            "        [ 3.1491, -3.6529],\n",
            "        [ 3.1585, -3.6325],\n",
            "        [ 3.0344, -3.6265],\n",
            "        [ 3.0056, -3.4315],\n",
            "        [-3.1492,  3.0763],\n",
            "        [ 3.0064, -3.5468],\n",
            "        [ 3.0911, -3.6383],\n",
            "        [ 3.2116, -3.7100],\n",
            "        [ 3.0741, -3.6332],\n",
            "        [ 3.2118, -3.6689],\n",
            "        [ 2.3405, -2.8815],\n",
            "        [-3.0334,  3.2152]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.2699, -3.7747],\n",
            "        [-3.2151,  3.4710],\n",
            "        [ 3.3536, -3.8240],\n",
            "        [ 3.1987, -3.6928],\n",
            "        [ 2.9355, -3.5061],\n",
            "        [ 3.1300, -3.6311],\n",
            "        [ 3.2316, -3.7905],\n",
            "        [ 3.0102, -3.5900],\n",
            "        [-3.2604,  3.5665],\n",
            "        [ 3.3168, -3.8089],\n",
            "        [-3.2193,  3.4985],\n",
            "        [ 3.2306, -3.7353],\n",
            "        [-3.2299,  3.5043],\n",
            "        [ 2.7430, -3.2535],\n",
            "        [ 3.1858, -3.7532],\n",
            "        [ 3.3095, -3.7512]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.2388, -3.7598],\n",
            "        [ 3.1972, -3.7185],\n",
            "        [ 3.0927, -3.6374],\n",
            "        [ 3.2762, -3.7752],\n",
            "        [ 3.0403, -3.6044],\n",
            "        [ 2.9411, -3.5271],\n",
            "        [ 3.1986, -3.6503],\n",
            "        [ 3.0762, -3.6716],\n",
            "        [ 3.1963, -3.7160],\n",
            "        [ 3.2343, -3.7673],\n",
            "        [ 3.2246, -3.8121],\n",
            "        [ 2.9871, -3.5163],\n",
            "        [ 3.1363, -3.7055],\n",
            "        [ 3.2493, -3.7411],\n",
            "        [ 3.3147, -3.8087],\n",
            "        [ 3.1220, -3.7116]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.1829, -3.7190],\n",
            "        [ 3.2838, -3.8018],\n",
            "        [ 3.3097, -3.8566],\n",
            "        [ 3.2188, -3.7937],\n",
            "        [ 3.1889, -3.6808],\n",
            "        [ 3.2379, -3.7603],\n",
            "        [ 3.1889, -3.7861],\n",
            "        [ 2.2811, -2.7715],\n",
            "        [ 3.0911, -3.6160],\n",
            "        [ 3.2112, -3.7242],\n",
            "        [ 3.0783, -3.6460],\n",
            "        [ 3.2448, -3.8521],\n",
            "        [ 3.2904, -3.8092],\n",
            "        [ 3.3087, -3.7779],\n",
            "        [-3.2625,  3.5078],\n",
            "        [ 3.2396, -3.7754]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.1696, -3.7783],\n",
            "        [ 3.1965, -3.8068],\n",
            "        [ 3.0754, -3.5949],\n",
            "        [ 3.1903, -3.7085],\n",
            "        [ 3.1658, -3.7453],\n",
            "        [ 3.2097, -3.6693],\n",
            "        [-1.2634,  1.3967],\n",
            "        [ 3.1120, -3.6329],\n",
            "        [ 3.3882, -3.8453],\n",
            "        [ 3.2615, -3.7576],\n",
            "        [ 3.2630, -3.8118],\n",
            "        [ 3.1171, -3.7021],\n",
            "        [ 3.2771, -3.8194],\n",
            "        [-3.2252,  3.5464],\n",
            "        [ 3.1666, -3.7950],\n",
            "        [ 3.1782, -3.7192]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.3472, -3.8409],\n",
            "        [ 2.9220, -3.4806],\n",
            "        [ 3.1340, -3.7181],\n",
            "        [ 3.1135, -3.6841],\n",
            "        [ 3.1786, -3.7546],\n",
            "        [ 3.3850, -3.8738],\n",
            "        [ 3.2870, -3.8044],\n",
            "        [-3.3342,  3.5318],\n",
            "        [ 2.9652, -3.5864],\n",
            "        [-3.2463,  3.5538],\n",
            "        [-3.3036,  3.5385],\n",
            "        [-3.3148,  3.5718],\n",
            "        [ 3.0008, -3.5969],\n",
            "        [ 3.3794, -3.8626],\n",
            "        [ 3.2143, -3.7776],\n",
            "        [ 3.2043, -3.7820]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.2308,  3.4725],\n",
            "        [ 2.8919, -3.5232],\n",
            "        [ 3.2595, -3.7730],\n",
            "        [ 3.2700, -3.7993],\n",
            "        [ 2.9259, -3.5822],\n",
            "        [ 3.2507, -3.8215],\n",
            "        [-3.2315,  3.4896],\n",
            "        [ 3.2311, -3.7711],\n",
            "        [ 2.9240, -3.5713],\n",
            "        [ 3.4069, -3.8707],\n",
            "        [ 3.3847, -3.8857],\n",
            "        [ 3.2805, -3.8274],\n",
            "        [ 3.2758, -3.8754],\n",
            "        [ 3.3372, -3.8620],\n",
            "        [ 3.2920, -3.7955],\n",
            "        [ 3.3334, -3.8092]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.2363,  3.4591],\n",
            "        [-3.0807,  3.1836],\n",
            "        [ 3.3148, -3.8746],\n",
            "        [ 3.1335, -3.6761],\n",
            "        [ 3.2234, -3.7784],\n",
            "        [ 2.9302, -3.4549],\n",
            "        [-3.3259,  3.4855],\n",
            "        [ 2.8580, -3.3986],\n",
            "        [ 3.1692, -3.6840],\n",
            "        [ 3.3593, -3.8757],\n",
            "        [ 3.2523, -3.8356],\n",
            "        [ 3.1044, -3.7535],\n",
            "        [ 3.2249, -3.7872],\n",
            "        [ 3.3181, -3.9063],\n",
            "        [-3.2421,  3.5329],\n",
            "        [ 3.3977, -3.8481]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.2615, -3.8290],\n",
            "        [ 3.1394, -3.7264],\n",
            "        [-3.2968,  3.5367],\n",
            "        [ 3.1577, -3.7401],\n",
            "        [-3.3281,  3.4644],\n",
            "        [ 3.3109, -3.8544],\n",
            "        [-3.2943,  3.5032],\n",
            "        [ 3.1681, -3.7253],\n",
            "        [ 3.1618, -3.8074],\n",
            "        [ 3.1559, -3.7444],\n",
            "        [ 3.4138, -3.8410],\n",
            "        [ 3.4013, -3.9096],\n",
            "        [ 3.3675, -3.8375],\n",
            "        [ 3.1015, -3.7018],\n",
            "        [ 3.3176, -3.8650],\n",
            "        [ 3.2829, -3.8198]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.2430, -3.8315],\n",
            "        [ 3.2419, -3.8312],\n",
            "        [ 3.3170, -3.8289],\n",
            "        [-3.3337,  3.5861],\n",
            "        [ 3.1620, -3.7714],\n",
            "        [ 3.4286, -3.9405],\n",
            "        [ 3.2804, -3.8165],\n",
            "        [ 3.2547, -3.7934],\n",
            "        [ 3.2976, -3.8437],\n",
            "        [-3.2330,  3.4621],\n",
            "        [ 3.1784, -3.7437],\n",
            "        [ 3.2511, -3.8013],\n",
            "        [ 3.3594, -3.8451],\n",
            "        [ 2.7685, -3.3203],\n",
            "        [ 3.3411, -3.8120],\n",
            "        [ 3.1815, -3.7695]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0968, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.4223, -3.9328],\n",
            "        [ 3.4805, -3.9508],\n",
            "        [-0.6752,  0.6179],\n",
            "        [ 3.4720, -3.9577],\n",
            "        [ 3.0522, -3.6702],\n",
            "        [ 3.3014, -3.8596],\n",
            "        [-3.2018,  3.5154],\n",
            "        [ 3.2266, -3.7713],\n",
            "        [ 3.3735, -3.9180],\n",
            "        [ 3.2578, -3.7756],\n",
            "        [ 3.3367, -3.8683],\n",
            "        [ 3.2337, -3.7516],\n",
            "        [ 3.4268, -3.9084],\n",
            "        [-3.2827,  3.5323],\n",
            "        [-3.3175,  3.5615],\n",
            "        [ 3.1219, -3.6543]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.4207, -3.9163],\n",
            "        [ 3.4031, -3.8802],\n",
            "        [ 3.2123, -3.7507],\n",
            "        [ 3.2453, -3.7786],\n",
            "        [ 3.2862, -3.8419],\n",
            "        [ 3.4393, -3.9283],\n",
            "        [ 3.2668, -3.7929],\n",
            "        [ 3.2839, -3.8376],\n",
            "        [ 3.3155, -3.8294],\n",
            "        [-3.2995,  3.4984],\n",
            "        [-3.3734,  3.5984],\n",
            "        [ 3.3646, -3.9420],\n",
            "        [ 3.3178, -3.8922],\n",
            "        [ 3.3321, -3.8243],\n",
            "        [ 3.1344, -3.6989],\n",
            "        [ 3.2620, -3.8419]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0299, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.1028, -3.7181],\n",
            "        [ 3.2417, -3.8093],\n",
            "        [ 3.3277, -3.7887],\n",
            "        [ 3.3487, -3.8334],\n",
            "        [-3.3310,  3.5067],\n",
            "        [ 3.4071, -3.8365],\n",
            "        [-3.2580,  3.4667],\n",
            "        [ 3.2060, -3.8125],\n",
            "        [ 3.3293, -3.8596],\n",
            "        [ 3.1965, -3.7802],\n",
            "        [ 3.2689, -3.8739],\n",
            "        [ 3.2590, -3.8421],\n",
            "        [ 3.1195, -3.7287],\n",
            "        [-3.2833,  3.4896],\n",
            "        [-0.3059,  0.2179],\n",
            "        [ 3.2224, -3.7854]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.2823,  3.5005],\n",
            "        [ 3.3492, -3.9218],\n",
            "        [ 3.3207, -3.9112],\n",
            "        [ 3.3167, -3.8435],\n",
            "        [ 3.2678, -3.8533],\n",
            "        [ 3.4045, -3.9233],\n",
            "        [ 3.2001, -3.7701],\n",
            "        [ 3.2752, -3.8855],\n",
            "        [ 3.2387, -3.8283],\n",
            "        [ 3.4254, -3.9579],\n",
            "        [ 3.3262, -3.8558],\n",
            "        [ 3.2638, -3.8158],\n",
            "        [ 3.3715, -3.9310],\n",
            "        [ 3.1238, -3.7453],\n",
            "        [-3.3164,  3.6037],\n",
            "        [ 3.4921, -3.9675]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.4111, -3.9054],\n",
            "        [ 3.2612, -3.8025],\n",
            "        [ 3.3507, -3.8773],\n",
            "        [ 3.4795, -3.9244],\n",
            "        [-3.3039,  3.5445],\n",
            "        [-3.2608,  3.4642],\n",
            "        [-3.3152,  3.5201],\n",
            "        [ 3.3647, -3.8061],\n",
            "        [ 3.4274, -3.9756],\n",
            "        [ 3.3972, -3.8164],\n",
            "        [ 3.3551, -3.8904],\n",
            "        [-3.3088,  3.5146],\n",
            "        [ 3.0434, -3.6759],\n",
            "        [ 3.3991, -3.9227],\n",
            "        [ 2.3250, -2.8885],\n",
            "        [ 3.3972, -3.8164]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.3156,  3.5508],\n",
            "        [ 3.4932, -4.0001],\n",
            "        [ 3.1849, -3.7802],\n",
            "        [ 3.3399, -3.8996],\n",
            "        [ 3.1736, -3.7516],\n",
            "        [ 3.2697, -3.8730],\n",
            "        [ 3.4107, -3.9792],\n",
            "        [ 3.0791, -3.6156],\n",
            "        [ 3.2659, -3.9244],\n",
            "        [ 3.3058, -3.9186],\n",
            "        [ 3.0865, -3.7483],\n",
            "        [ 3.2660, -3.8396],\n",
            "        [ 3.2456, -3.7821],\n",
            "        [ 3.4368, -3.9438],\n",
            "        [ 3.3658, -3.9395],\n",
            "        [ 3.3093, -3.7967]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.1303, -3.6983],\n",
            "        [ 3.3901, -3.9160],\n",
            "        [ 3.2667, -3.8365],\n",
            "        [ 3.3415, -3.9342],\n",
            "        [ 3.4747, -3.9786],\n",
            "        [ 3.2176, -3.8054],\n",
            "        [ 3.4747, -3.9655],\n",
            "        [-3.2860,  3.4918],\n",
            "        [ 3.2227, -3.8112],\n",
            "        [ 3.5295, -4.0130],\n",
            "        [ 3.3025, -3.8244],\n",
            "        [ 3.3857, -3.9637],\n",
            "        [ 2.8626, -3.4376],\n",
            "        [ 3.1992, -3.7733],\n",
            "        [ 2.8688, -3.4701],\n",
            "        [-3.2990,  3.5305]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.3601, -3.9525],\n",
            "        [-3.3208,  3.5648],\n",
            "        [ 3.2998, -3.8813],\n",
            "        [ 3.4194, -3.9794],\n",
            "        [ 3.3168, -3.8872],\n",
            "        [ 2.1742, -2.9569],\n",
            "        [ 3.1695, -3.7788],\n",
            "        [ 3.2519, -3.7861],\n",
            "        [ 3.4178, -3.9383],\n",
            "        [-3.3288,  3.5897],\n",
            "        [ 3.3409, -3.8016],\n",
            "        [-3.3312,  3.5592],\n",
            "        [ 2.7847, -3.4029],\n",
            "        [ 3.4301, -3.9613],\n",
            "        [ 3.3921, -3.9168],\n",
            "        [ 3.1015, -3.6896]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.1895, -3.8052],\n",
            "        [ 3.3499, -3.8949],\n",
            "        [ 2.3771, -3.0773],\n",
            "        [ 3.1132, -3.7513],\n",
            "        [-3.3618,  3.5729],\n",
            "        [-3.3385,  3.5105],\n",
            "        [ 3.2164, -3.7084],\n",
            "        [ 3.0299, -3.6400],\n",
            "        [ 3.5189, -4.0328],\n",
            "        [ 3.2224, -3.7900],\n",
            "        [-3.3252,  3.3993],\n",
            "        [ 3.1621, -3.7776],\n",
            "        [ 2.8636, -3.5279],\n",
            "        [ 3.4209, -3.9748],\n",
            "        [ 3.3764, -3.9493],\n",
            "        [ 3.0778, -3.7101]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.3735, -3.9555],\n",
            "        [ 3.5661, -4.0269],\n",
            "        [ 1.2134, -2.0410],\n",
            "        [ 3.3911, -3.9079],\n",
            "        [ 3.1680, -3.7993],\n",
            "        [ 3.4104, -3.9309],\n",
            "        [ 3.3470, -3.9568],\n",
            "        [ 3.4424, -3.9824],\n",
            "        [ 3.4077, -3.9858],\n",
            "        [ 3.2430, -3.8465],\n",
            "        [ 3.0491, -3.6044],\n",
            "        [ 3.5257, -4.0327],\n",
            "        [ 3.3189, -3.8876],\n",
            "        [ 3.3059, -3.8890],\n",
            "        [ 3.2895, -3.8874],\n",
            "        [ 3.2606, -3.8229]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.5521, -4.0221],\n",
            "        [ 3.1615, -3.7573],\n",
            "        [ 3.3784, -3.9945],\n",
            "        [ 3.4062, -3.8572],\n",
            "        [ 2.7125, -3.3020],\n",
            "        [-3.3214,  3.5009],\n",
            "        [ 2.7341, -3.4187],\n",
            "        [ 3.3113, -3.8394],\n",
            "        [ 3.3308, -3.9195],\n",
            "        [ 1.4462, -2.1696],\n",
            "        [-3.3735,  3.5388],\n",
            "        [ 3.2998, -3.9099],\n",
            "        [ 3.3863, -3.9734],\n",
            "        [ 3.3460, -3.8517],\n",
            "        [ 3.4439, -3.9603],\n",
            "        [ 3.3062, -3.8912]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.2540, -3.8396],\n",
            "        [-3.3934,  3.5694],\n",
            "        [ 3.3504, -3.9123],\n",
            "        [ 3.1888, -3.7558],\n",
            "        [ 3.2590, -3.8731],\n",
            "        [-3.3561,  3.5757],\n",
            "        [ 3.4984, -3.9856],\n",
            "        [-3.3685,  3.5427],\n",
            "        [ 3.3669, -3.9304],\n",
            "        [ 3.1616, -3.5132],\n",
            "        [ 3.2791, -3.8714],\n",
            "        [ 2.8574, -3.4367],\n",
            "        [ 3.3645, -3.9452],\n",
            "        [ 3.4946, -4.0036],\n",
            "        [ 3.2217, -3.7091],\n",
            "        [ 3.2400, -3.8703]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.1896, -3.7096],\n",
            "        [ 3.3455, -3.9328],\n",
            "        [ 3.1472, -3.6899],\n",
            "        [ 3.1356, -3.7042],\n",
            "        [ 2.9728, -3.5802],\n",
            "        [ 3.5210, -4.0199],\n",
            "        [ 3.4479, -3.9821],\n",
            "        [-3.3417,  3.4900],\n",
            "        [ 3.2792, -3.8545],\n",
            "        [ 3.5253, -4.0352],\n",
            "        [ 2.9163, -3.5149],\n",
            "        [ 3.0337, -3.6371],\n",
            "        [ 3.2150, -3.7935],\n",
            "        [ 3.1558, -3.7996],\n",
            "        [ 3.2060, -3.7693],\n",
            "        [-3.3966,  3.5650]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.3330, -3.8387],\n",
            "        [ 3.2513, -3.7391],\n",
            "        [ 3.1894, -3.8111],\n",
            "        [-3.3327,  3.5024],\n",
            "        [ 3.2599, -3.7871],\n",
            "        [-3.3847,  3.5575],\n",
            "        [ 3.4911, -4.0479],\n",
            "        [ 3.5437, -4.0599],\n",
            "        [-3.3940,  3.4617],\n",
            "        [ 1.8503, -2.5792],\n",
            "        [ 3.3386, -3.8474],\n",
            "        [ 3.5341, -4.0665],\n",
            "        [ 3.4371, -3.9724],\n",
            "        [ 3.2842, -3.8186],\n",
            "        [ 3.4051, -3.9316],\n",
            "        [ 3.3013, -3.8442]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.4900, -4.0174],\n",
            "        [ 3.4847, -4.0147],\n",
            "        [ 2.5410, -3.1047],\n",
            "        [ 3.3446, -3.9186],\n",
            "        [ 3.4654, -3.8728],\n",
            "        [ 3.3078, -3.8861],\n",
            "        [ 3.2531, -3.7884],\n",
            "        [ 3.1657, -3.7202],\n",
            "        [ 3.4997, -4.0428],\n",
            "        [ 3.1275, -3.7257],\n",
            "        [ 3.3176, -3.8928],\n",
            "        [ 3.3111, -3.8392],\n",
            "        [ 2.7136, -3.2944],\n",
            "        [-3.3927,  3.5767],\n",
            "        [ 2.6719, -3.3224],\n",
            "        [ 3.1309, -3.7738]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.9938, -3.6013],\n",
            "        [ 3.2033, -3.8079],\n",
            "        [ 2.5521, -3.2860],\n",
            "        [ 3.2209, -3.7550],\n",
            "        [ 2.9603, -3.5975],\n",
            "        [-3.3937,  3.6286],\n",
            "        [ 3.2488, -3.8172],\n",
            "        [-3.4208,  3.6046],\n",
            "        [ 3.4300, -3.9770],\n",
            "        [ 3.3230, -3.7679],\n",
            "        [ 1.9521, -2.5934],\n",
            "        [ 3.1278, -3.7677],\n",
            "        [ 3.4381, -3.9507],\n",
            "        [ 2.5858, -3.1439],\n",
            "        [-3.3648,  3.5066],\n",
            "        [ 3.3676, -3.9528]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.3484, -3.9535],\n",
            "        [ 3.4083, -3.9684],\n",
            "        [-3.3892,  3.6229],\n",
            "        [ 3.4306, -4.0131],\n",
            "        [ 3.4761, -3.9956],\n",
            "        [ 3.0942, -3.7052],\n",
            "        [ 2.4551, -3.1753],\n",
            "        [ 2.9776, -3.5978],\n",
            "        [ 3.5777, -4.0889],\n",
            "        [ 2.9744, -3.5206],\n",
            "        [ 1.0467, -1.8666],\n",
            "        [ 3.4582, -4.0526],\n",
            "        [ 3.4816, -3.9798],\n",
            "        [-3.4147,  3.5660],\n",
            "        [-3.4067,  3.5717],\n",
            "        [ 2.7008, -3.3347]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.5717, -4.0867],\n",
            "        [ 3.2630, -3.8611],\n",
            "        [ 2.9697, -3.5964],\n",
            "        [ 2.7337, -3.3766],\n",
            "        [ 3.2179, -3.6700],\n",
            "        [ 3.1145, -3.7260],\n",
            "        [-3.4635,  3.5920],\n",
            "        [ 3.4465, -3.9463],\n",
            "        [ 3.2740, -3.8548],\n",
            "        [-3.2918,  3.4931],\n",
            "        [ 3.4951, -3.9000],\n",
            "        [ 3.3104, -3.8262],\n",
            "        [ 3.4848, -4.0057],\n",
            "        [-3.3894,  3.5734],\n",
            "        [-3.3962,  3.5244],\n",
            "        [ 2.9531, -3.7063]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.6247, -4.0837],\n",
            "        [-3.4049,  3.5894],\n",
            "        [ 3.0172, -3.6476],\n",
            "        [ 3.4854, -4.0409],\n",
            "        [ 2.9978, -3.5849],\n",
            "        [ 3.2538, -3.8537],\n",
            "        [ 3.3130, -3.8437],\n",
            "        [ 2.0001, -2.7160],\n",
            "        [ 3.3559, -3.9582],\n",
            "        [ 3.3735, -3.8459],\n",
            "        [-3.3976,  3.5701],\n",
            "        [ 2.5973, -3.1915],\n",
            "        [-3.3974,  3.6097],\n",
            "        [ 3.6130, -4.0983],\n",
            "        [ 3.5460, -4.0510],\n",
            "        [ 2.9176, -3.5075]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.3651, -3.1056],\n",
            "        [ 3.3439, -3.8941],\n",
            "        [ 3.4848, -4.0184],\n",
            "        [ 3.1805, -3.6195],\n",
            "        [ 3.4307, -3.8851],\n",
            "        [ 3.3001, -3.9104],\n",
            "        [ 3.2823, -3.7846],\n",
            "        [ 2.0189, -2.7208],\n",
            "        [-2.5193,  2.6507],\n",
            "        [ 2.9525, -3.6760],\n",
            "        [ 3.3981, -3.9008],\n",
            "        [ 3.1106, -3.7689],\n",
            "        [-3.3875,  3.6216],\n",
            "        [ 3.5087, -4.0528],\n",
            "        [ 3.1448, -3.7234],\n",
            "        [ 3.4238, -3.9990]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.3050, -3.8119],\n",
            "        [ 3.4608, -3.9536],\n",
            "        [ 3.5076, -4.0668],\n",
            "        [ 3.4858, -4.0611],\n",
            "        [ 3.3926, -3.9661],\n",
            "        [-3.4591,  3.5750],\n",
            "        [ 3.2606, -3.7394],\n",
            "        [ 3.5062, -3.9522],\n",
            "        [ 3.2515, -3.8687],\n",
            "        [ 3.4836, -3.9751],\n",
            "        [ 3.4571, -3.9816],\n",
            "        [-3.4373,  3.5867],\n",
            "        [ 3.3864, -3.9581],\n",
            "        [ 3.5862, -4.1069],\n",
            "        [ 3.5243, -4.0424],\n",
            "        [ 3.4478, -3.9503]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.4573,  3.6169],\n",
            "        [ 3.2920, -3.8866],\n",
            "        [-3.4056,  3.6227],\n",
            "        [ 3.3587, -3.8819],\n",
            "        [ 3.3827, -3.9713],\n",
            "        [ 3.4567, -4.0203],\n",
            "        [ 2.5256, -3.1996],\n",
            "        [ 3.3043, -3.8699],\n",
            "        [ 3.1490, -3.7150],\n",
            "        [-3.4132,  3.6026],\n",
            "        [ 3.0732, -3.6613],\n",
            "        [-3.4766,  3.6171],\n",
            "        [ 2.7012, -3.3502],\n",
            "        [ 2.1472, -2.9652],\n",
            "        [ 3.1609, -3.7211],\n",
            "        [ 3.4724, -4.0565]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.4395, -3.9610],\n",
            "        [ 2.6100, -3.3034],\n",
            "        [ 3.4743, -4.0136],\n",
            "        [ 3.1675, -3.7352],\n",
            "        [-3.3814,  3.5413],\n",
            "        [ 2.3358, -3.0494],\n",
            "        [ 3.4687, -3.9523],\n",
            "        [ 2.6401, -3.2037],\n",
            "        [ 3.1818, -3.7256],\n",
            "        [ 3.3593, -3.9702],\n",
            "        [-3.4463,  3.6040],\n",
            "        [ 3.6308, -4.1094],\n",
            "        [ 3.4364, -3.9512],\n",
            "        [ 3.3039, -3.8817],\n",
            "        [ 3.4588, -3.9873],\n",
            "        [ 3.6387, -4.1328]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.4580,  3.6763],\n",
            "        [ 3.2258, -3.8019],\n",
            "        [ 2.8525, -3.3761],\n",
            "        [ 3.3796, -3.9923],\n",
            "        [ 3.0207, -3.6191],\n",
            "        [ 3.2567, -3.7498],\n",
            "        [ 3.3099, -3.8950],\n",
            "        [ 3.4400, -4.0059],\n",
            "        [ 3.5680, -4.0424],\n",
            "        [-3.4453,  3.6545],\n",
            "        [ 3.4534, -3.9710],\n",
            "        [-3.4634,  3.6370],\n",
            "        [-3.4608,  3.6574],\n",
            "        [-3.3633,  3.6382],\n",
            "        [ 3.2590, -3.7942],\n",
            "        [ 3.2212, -3.7954]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.6446, -4.1291],\n",
            "        [ 3.6724, -4.1682],\n",
            "        [ 2.4457, -3.1521],\n",
            "        [ 3.6128, -4.1081],\n",
            "        [ 3.2266, -3.8000],\n",
            "        [ 3.2174, -3.8178],\n",
            "        [ 3.3852, -3.9470],\n",
            "        [ 3.4558, -3.9945],\n",
            "        [ 3.1913, -3.7663],\n",
            "        [ 3.5480, -4.0851],\n",
            "        [ 3.1411, -3.6717],\n",
            "        [ 3.6627, -4.1390],\n",
            "        [ 3.4435, -3.9919],\n",
            "        [ 3.4950, -4.0659],\n",
            "        [ 3.5550, -4.1009],\n",
            "        [ 3.5487, -4.0720]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.9322, -3.4865],\n",
            "        [-1.6499,  1.7740],\n",
            "        [ 3.4654, -3.9813],\n",
            "        [ 2.0748, -2.6747],\n",
            "        [ 3.2819, -3.9409],\n",
            "        [-3.5008,  3.6241],\n",
            "        [ 3.1920, -3.8314],\n",
            "        [ 3.6125, -4.0831],\n",
            "        [ 2.8371, -3.4447],\n",
            "        [ 3.4926, -4.0680],\n",
            "        [ 3.1886, -3.8148],\n",
            "        [ 3.6013, -4.1336],\n",
            "        [ 3.6411, -4.1072],\n",
            "        [ 3.0510, -3.6344],\n",
            "        [ 3.4291, -4.0009],\n",
            "        [ 3.2000, -3.7525]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "3 SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.4686,  3.6564],\n",
            "        [ 3.3542, -3.8757],\n",
            "        [ 3.6089, -4.1372],\n",
            "        [ 3.5827, -4.1264],\n",
            "        [ 3.4788, -4.0673],\n",
            "        [ 3.5597, -4.0534],\n",
            "        [ 3.4165, -3.9801],\n",
            "        [ 3.6063, -4.0852],\n",
            "        [ 3.5613, -4.0843],\n",
            "        [-3.4643,  3.6177],\n",
            "        [ 3.5823, -4.1312],\n",
            "        [ 3.2267, -3.8146]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.4269, -4.0088],\n",
            "        [ 3.5838, -4.0594],\n",
            "        [ 3.4005, -4.0078],\n",
            "        [ 3.5423, -4.1003],\n",
            "        [ 3.5436, -4.0218],\n",
            "        [ 3.3236, -3.8355],\n",
            "        [ 3.6809, -4.1659],\n",
            "        [ 3.4416, -4.0432],\n",
            "        [ 3.5469, -4.0716],\n",
            "        [-3.4856,  3.6512],\n",
            "        [ 3.6444, -4.1518],\n",
            "        [ 3.4074, -3.9249],\n",
            "        [-3.4561,  3.6792],\n",
            "        [ 2.8336, -3.3670],\n",
            "        [ 3.5652, -4.0971],\n",
            "        [ 3.1757, -3.6735]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.4777, -4.0163],\n",
            "        [ 3.6049, -4.1352],\n",
            "        [ 3.2867, -3.9094],\n",
            "        [ 3.4798, -4.0294],\n",
            "        [ 3.5738, -4.0547],\n",
            "        [ 3.5097, -3.9927],\n",
            "        [ 3.4994, -4.0581],\n",
            "        [ 3.5124, -4.0768],\n",
            "        [-3.5082,  3.6021],\n",
            "        [ 3.4984, -4.0474],\n",
            "        [ 3.3310, -3.8722],\n",
            "        [ 3.5812, -4.1049],\n",
            "        [ 3.4725, -4.0267],\n",
            "        [ 3.6089, -4.1058],\n",
            "        [ 3.5027, -4.0437],\n",
            "        [ 3.0413, -3.6321]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.6465, -4.1598],\n",
            "        [ 3.7226, -4.1404],\n",
            "        [ 3.6122, -4.1158],\n",
            "        [-3.4554,  3.6272],\n",
            "        [ 3.5741, -4.1014],\n",
            "        [ 3.4584, -3.8547],\n",
            "        [-1.7173,  1.8385],\n",
            "        [ 3.4403, -3.9495],\n",
            "        [ 3.6230, -4.1654],\n",
            "        [ 3.3726, -3.9477],\n",
            "        [ 3.4812, -3.9301],\n",
            "        [ 3.4317, -3.9996],\n",
            "        [-3.4847,  3.6166],\n",
            "        [ 3.6124, -4.0897],\n",
            "        [ 3.5277, -4.0601],\n",
            "        [ 3.6964, -4.1595]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.4791,  3.6503],\n",
            "        [ 3.4122, -3.8609],\n",
            "        [ 3.0019, -3.6346],\n",
            "        [ 3.5737, -4.0546],\n",
            "        [ 3.3800, -3.9210],\n",
            "        [ 3.4475, -3.9891],\n",
            "        [ 3.1995, -3.7559],\n",
            "        [ 3.4023, -3.8828],\n",
            "        [ 3.5476, -4.0562],\n",
            "        [ 3.5473, -4.1282],\n",
            "        [ 3.5642, -4.1448],\n",
            "        [ 2.2303, -2.7906],\n",
            "        [ 3.6141, -4.1360],\n",
            "        [ 3.4564, -4.0293],\n",
            "        [ 3.0238, -3.6069],\n",
            "        [ 3.6911, -4.1359]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 2.2538, -2.9517],\n",
            "        [ 3.1348, -3.6623],\n",
            "        [ 3.6751, -4.1761],\n",
            "        [ 3.5806, -4.0661],\n",
            "        [ 3.6344, -4.0845],\n",
            "        [ 3.6032, -4.0826],\n",
            "        [ 3.3497, -3.9186],\n",
            "        [ 3.5595, -4.1376],\n",
            "        [-3.1895,  3.3587],\n",
            "        [ 3.7417, -4.1913],\n",
            "        [ 2.8834, -3.5043],\n",
            "        [ 3.6510, -4.1345],\n",
            "        [ 3.4697, -4.0388],\n",
            "        [ 3.6794, -4.1909],\n",
            "        [ 3.5227, -3.9928],\n",
            "        [ 3.3141, -3.9320]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.4627, -3.9271],\n",
            "        [ 3.6479, -4.1709],\n",
            "        [-1.9169,  2.1537],\n",
            "        [ 3.3967, -3.9842],\n",
            "        [ 3.2720, -3.8591],\n",
            "        [ 3.7286, -4.2084],\n",
            "        [ 2.6127, -3.3803],\n",
            "        [ 2.9518, -3.4663],\n",
            "        [ 3.5120, -4.1122],\n",
            "        [ 3.5540, -4.0343],\n",
            "        [ 3.3805, -3.9567],\n",
            "        [ 3.3742, -3.7914],\n",
            "        [ 3.4045, -3.9676],\n",
            "        [ 3.6558, -4.1310],\n",
            "        [ 2.5839, -3.2362],\n",
            "        [ 3.4414, -3.9700]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.6336, -4.1569],\n",
            "        [ 3.5420, -4.0409],\n",
            "        [ 3.5110, -3.9674],\n",
            "        [ 3.5889, -4.1235],\n",
            "        [ 3.2456, -3.8011],\n",
            "        [-3.4877,  3.6455],\n",
            "        [ 3.4605, -4.0057],\n",
            "        [-3.4703,  3.6743],\n",
            "        [ 3.1442, -3.7000],\n",
            "        [ 3.3818, -3.9024],\n",
            "        [ 3.3423, -3.9641],\n",
            "        [ 3.6913, -4.1758],\n",
            "        [ 3.2944, -3.9140],\n",
            "        [ 3.2695, -3.8748],\n",
            "        [ 3.8088, -4.2026],\n",
            "        [ 3.5442, -4.0565]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.5004,  3.7022],\n",
            "        [ 3.5371, -4.1562],\n",
            "        [ 3.1242, -3.6567],\n",
            "        [ 3.5843, -4.1402],\n",
            "        [ 3.5805, -4.0921],\n",
            "        [ 3.5870, -4.0780],\n",
            "        [ 3.0103, -3.6525],\n",
            "        [ 3.4519, -4.0009],\n",
            "        [ 3.5676, -4.1339],\n",
            "        [ 3.6269, -4.1180],\n",
            "        [ 3.5028, -3.9738],\n",
            "        [-3.4842,  3.6764],\n",
            "        [ 3.7323, -4.2083],\n",
            "        [-3.4682,  3.7190],\n",
            "        [ 3.4771, -4.0477],\n",
            "        [-3.4737,  3.6994]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.6057, -4.1053],\n",
            "        [-3.4482,  3.7142],\n",
            "        [ 3.6530, -4.1285],\n",
            "        [ 3.2032, -3.6968],\n",
            "        [ 3.4394, -4.0506],\n",
            "        [ 3.5137, -4.0124],\n",
            "        [-3.4994,  3.6565],\n",
            "        [ 3.5832, -4.1078],\n",
            "        [ 3.6267, -4.0838],\n",
            "        [ 3.4884, -4.0607],\n",
            "        [ 3.5215, -4.1045],\n",
            "        [ 3.5020, -4.0683],\n",
            "        [ 2.2146, -2.9300],\n",
            "        [ 3.3884, -3.9784],\n",
            "        [ 3.6734, -4.1484],\n",
            "        [ 2.1493, -2.8315]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.4741,  3.7103],\n",
            "        [ 3.0518, -3.6153],\n",
            "        [ 3.3475, -3.6288],\n",
            "        [ 3.4497, -3.7108],\n",
            "        [ 2.5263, -3.2535],\n",
            "        [ 3.5644, -4.0996],\n",
            "        [ 3.6575, -4.2032],\n",
            "        [-3.4764,  3.6819],\n",
            "        [ 3.5762, -4.1090],\n",
            "        [ 2.9022, -3.5461],\n",
            "        [ 3.6977, -4.1895],\n",
            "        [ 3.5009, -3.9849],\n",
            "        [ 3.4706, -3.9698],\n",
            "        [ 3.6341, -4.1161],\n",
            "        [ 2.9190, -3.6147],\n",
            "        [ 3.3682, -3.8680]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.6372, -4.1420],\n",
            "        [ 0.9343, -1.7516],\n",
            "        [ 2.0405, -2.6782],\n",
            "        [ 3.7460, -4.2339],\n",
            "        [ 3.5989, -4.0267],\n",
            "        [-3.4850,  3.7029],\n",
            "        [ 2.4640, -3.1728],\n",
            "        [ 3.5712, -4.0632],\n",
            "        [ 2.8404, -3.6409],\n",
            "        [-3.5125,  3.7296],\n",
            "        [ 3.3285, -3.8007],\n",
            "        [-3.5054,  3.6863],\n",
            "        [ 3.8107, -4.2276],\n",
            "        [-3.5160,  3.6667],\n",
            "        [-3.5479,  3.6889],\n",
            "        [ 3.8235, -4.2439]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8175, -4.2082],\n",
            "        [ 3.6563, -4.1523],\n",
            "        [ 3.6848, -4.1801],\n",
            "        [ 3.5255, -4.0195],\n",
            "        [ 3.7630, -4.2443],\n",
            "        [ 3.4716, -4.0020],\n",
            "        [ 3.6360, -4.0614],\n",
            "        [ 2.9717, -3.5027],\n",
            "        [ 3.3002, -3.7913],\n",
            "        [ 3.5439, -4.0705],\n",
            "        [ 3.8029, -4.2310],\n",
            "        [ 3.7211, -4.2255],\n",
            "        [ 3.4357, -3.9552],\n",
            "        [ 3.6837, -4.2157],\n",
            "        [ 3.4505, -3.9163],\n",
            "        [ 3.6970, -4.2166]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.4650, -3.9382],\n",
            "        [ 3.3463, -3.9481],\n",
            "        [ 3.5702, -4.0934],\n",
            "        [ 3.7494, -4.2326],\n",
            "        [ 3.6796, -4.1237],\n",
            "        [ 3.4803, -3.9572],\n",
            "        [ 3.7073, -4.2016],\n",
            "        [ 3.6301, -4.1077],\n",
            "        [ 3.4546, -3.9875],\n",
            "        [ 3.6956, -4.2084],\n",
            "        [ 3.6448, -4.1702],\n",
            "        [ 3.6674, -4.0989],\n",
            "        [-3.4764,  3.6779],\n",
            "        [-3.4980,  3.7288],\n",
            "        [ 3.6447, -4.1177],\n",
            "        [ 3.6457, -4.1564]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.5941, -4.0715],\n",
            "        [ 3.7847, -4.2363],\n",
            "        [ 3.7145, -4.1592],\n",
            "        [ 3.7067, -4.1736],\n",
            "        [ 3.7066, -4.1908],\n",
            "        [-3.4786,  3.7274],\n",
            "        [ 3.6746, -4.1770],\n",
            "        [ 3.7659, -4.2036],\n",
            "        [ 3.4410, -4.0432],\n",
            "        [ 3.4082, -3.8213],\n",
            "        [ 0.6510, -1.2522],\n",
            "        [ 3.5571, -4.1296],\n",
            "        [ 3.0953, -3.6798],\n",
            "        [-3.5763,  3.7150],\n",
            "        [ 3.7429, -4.1739],\n",
            "        [ 3.7361, -4.2044]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.6166, -4.0531],\n",
            "        [ 3.6082, -4.0995],\n",
            "        [ 3.4157, -4.0265],\n",
            "        [ 3.2756, -3.7914],\n",
            "        [ 3.2852, -3.7818],\n",
            "        [ 3.6184, -4.1513],\n",
            "        [ 3.2492, -3.8804],\n",
            "        [-3.4525,  3.7677],\n",
            "        [ 3.8379, -4.2581],\n",
            "        [ 3.6728, -4.1916],\n",
            "        [ 3.8482, -4.2539],\n",
            "        [ 3.6540, -4.1568],\n",
            "        [ 3.6463, -4.1823],\n",
            "        [ 3.3292, -3.7801],\n",
            "        [ 2.9743, -3.6655],\n",
            "        [-3.5230,  3.7202]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.5294, -4.1059],\n",
            "        [ 3.6940, -4.1929],\n",
            "        [ 3.4886, -3.9538],\n",
            "        [ 3.7073, -4.1784],\n",
            "        [ 3.8157, -4.2780],\n",
            "        [ 2.7004, -3.2123],\n",
            "        [ 0.8107, -1.4550],\n",
            "        [ 3.5725, -4.0961],\n",
            "        [ 3.7348, -4.2174],\n",
            "        [ 2.8812, -3.4960],\n",
            "        [ 3.4480, -3.9829],\n",
            "        [-3.5130,  3.6882],\n",
            "        [ 3.7461, -4.2158],\n",
            "        [ 3.5770, -4.0890],\n",
            "        [ 3.7524, -4.1692],\n",
            "        [ 3.6647, -4.1451]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.5152,  3.7128],\n",
            "        [ 3.7416, -4.1844],\n",
            "        [-3.5368,  3.7200],\n",
            "        [ 3.6850, -4.1853],\n",
            "        [ 3.5718, -4.1265],\n",
            "        [ 3.4886, -4.0213],\n",
            "        [-3.5063,  3.7513],\n",
            "        [ 3.3484, -3.9266],\n",
            "        [ 3.7028, -4.1938],\n",
            "        [-3.5044,  3.7281],\n",
            "        [ 3.6483, -4.1233],\n",
            "        [ 3.5497, -4.1165],\n",
            "        [ 3.6190, -4.1583],\n",
            "        [-3.5229,  3.7606],\n",
            "        [ 3.6143, -4.1710],\n",
            "        [ 3.6678, -4.1848]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.7070, -4.2221],\n",
            "        [ 3.6101, -4.1606],\n",
            "        [ 3.8382, -4.2928],\n",
            "        [ 3.8672, -4.2836],\n",
            "        [-3.4901,  3.7735],\n",
            "        [-3.4991,  3.7210],\n",
            "        [ 3.6902, -4.2287],\n",
            "        [ 3.6404, -4.1905],\n",
            "        [ 3.7145, -4.2548],\n",
            "        [ 3.6985, -4.1948],\n",
            "        [ 3.7768, -4.2360],\n",
            "        [ 3.7408, -4.1794],\n",
            "        [ 3.8102, -4.2612],\n",
            "        [ 3.7592, -4.2096],\n",
            "        [-3.4865,  3.6769],\n",
            "        [ 3.7559, -4.2112]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.5051,  3.6815],\n",
            "        [ 3.4489, -4.0077],\n",
            "        [ 3.2259, -3.9119],\n",
            "        [ 3.8302, -4.1943],\n",
            "        [-3.5065,  3.7568],\n",
            "        [ 3.5884, -4.1820],\n",
            "        [-3.5121,  3.7388],\n",
            "        [ 3.8451, -4.2723],\n",
            "        [-3.5203,  3.7022],\n",
            "        [-3.5064,  3.7392],\n",
            "        [ 3.6288, -4.1725],\n",
            "        [ 3.5315, -4.0564],\n",
            "        [ 3.7978, -4.2172],\n",
            "        [ 3.6270, -4.1076],\n",
            "        [ 3.4755, -3.9739],\n",
            "        [ 3.3053, -3.8744]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.6872, -4.2133],\n",
            "        [ 3.4366, -4.0202],\n",
            "        [ 3.8635, -4.2963],\n",
            "        [ 3.7004, -4.1647],\n",
            "        [-3.5613,  3.7228],\n",
            "        [ 3.7962, -4.2785],\n",
            "        [ 3.8222, -4.2522],\n",
            "        [-3.5500,  3.7090],\n",
            "        [ 3.6508, -4.1746],\n",
            "        [ 3.8080, -4.2729],\n",
            "        [ 3.5615, -4.1099],\n",
            "        [ 3.8410, -4.2915],\n",
            "        [ 3.7689, -4.2566],\n",
            "        [ 3.7440, -4.1953],\n",
            "        [ 3.6714, -4.1730],\n",
            "        [ 3.7935, -4.2583]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8216, -4.3029],\n",
            "        [ 1.0784, -1.8422],\n",
            "        [ 3.7590, -4.2945],\n",
            "        [ 3.3368, -3.9283],\n",
            "        [ 3.8611, -4.2390],\n",
            "        [ 3.7879, -4.2916],\n",
            "        [ 3.6875, -4.0266],\n",
            "        [ 2.9526, -3.6182],\n",
            "        [ 3.7234, -4.2694],\n",
            "        [-3.5165,  3.7489],\n",
            "        [-3.5089,  3.7107],\n",
            "        [ 3.6089, -4.1290],\n",
            "        [ 3.8246, -4.2863],\n",
            "        [ 3.7472, -4.1940],\n",
            "        [ 3.8071, -4.2558],\n",
            "        [ 3.3521, -3.7313]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.5146,  3.7433],\n",
            "        [-3.5427,  3.7519],\n",
            "        [ 3.9182, -4.3255],\n",
            "        [ 3.7719, -4.1184],\n",
            "        [ 3.7010, -4.2315],\n",
            "        [ 3.5064, -4.0615],\n",
            "        [ 3.8272, -4.2494],\n",
            "        [ 3.4011, -4.0051],\n",
            "        [ 2.7590, -3.4822],\n",
            "        [ 3.6669, -4.1245],\n",
            "        [ 3.7015, -4.2304],\n",
            "        [ 3.7454, -4.2233],\n",
            "        [ 3.8032, -4.1797],\n",
            "        [ 3.6955, -4.1715],\n",
            "        [ 3.6923, -4.1955],\n",
            "        [ 3.7642, -4.2740]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8368, -4.2913],\n",
            "        [-3.6044,  3.7247],\n",
            "        [ 3.7368, -4.2375],\n",
            "        [ 3.9373, -4.3018],\n",
            "        [ 3.6650, -4.2218],\n",
            "        [ 3.6204, -4.1763],\n",
            "        [-3.4936,  3.7705],\n",
            "        [ 3.6892, -4.2196],\n",
            "        [ 3.9658, -4.3044],\n",
            "        [ 3.8481, -4.3114],\n",
            "        [ 3.7775, -4.2735],\n",
            "        [ 3.7740, -4.2466],\n",
            "        [ 3.7630, -4.2206],\n",
            "        [ 3.7789, -4.2946],\n",
            "        [ 3.6491, -4.1969],\n",
            "        [ 3.8277, -4.2992]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8876, -4.3193],\n",
            "        [ 3.6563, -4.2003],\n",
            "        [-3.5680,  3.7182],\n",
            "        [ 3.5434, -4.1213],\n",
            "        [ 3.5447, -4.1212],\n",
            "        [ 3.9341, -4.3231],\n",
            "        [ 3.9282, -4.3145],\n",
            "        [ 3.7800, -4.2637],\n",
            "        [-3.5636,  3.7436],\n",
            "        [-3.5619,  3.7629],\n",
            "        [ 3.7620, -4.2718],\n",
            "        [ 3.6395, -4.1934],\n",
            "        [ 3.9018, -4.3304],\n",
            "        [ 3.7057, -4.2575],\n",
            "        [ 3.7332, -4.2225],\n",
            "        [ 3.6821, -4.2076]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.7583, -4.2149],\n",
            "        [ 3.8262, -4.2596],\n",
            "        [-3.4839,  3.7662],\n",
            "        [ 3.7298, -4.2452],\n",
            "        [ 3.6866, -4.2311],\n",
            "        [ 3.8727, -4.3019],\n",
            "        [-3.5352,  3.7802],\n",
            "        [-3.5273,  3.6429],\n",
            "        [ 3.9030, -4.3035],\n",
            "        [-3.5826,  3.7573],\n",
            "        [ 3.8227, -4.2878],\n",
            "        [ 3.7697, -4.2596],\n",
            "        [ 3.5273, -3.9908],\n",
            "        [ 3.8665, -4.3001],\n",
            "        [ 3.5688, -4.1122],\n",
            "        [ 3.8285, -4.2362]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9759, -4.3188],\n",
            "        [ 3.7111, -4.2496],\n",
            "        [ 3.7959, -4.2564],\n",
            "        [ 3.8758, -4.3071],\n",
            "        [ 3.9611, -4.3413],\n",
            "        [-3.5121,  3.7612],\n",
            "        [ 3.8101, -4.2654],\n",
            "        [ 3.8321, -4.2728],\n",
            "        [ 3.7454, -4.2716],\n",
            "        [ 3.6971, -4.2251],\n",
            "        [ 3.8536, -4.2920],\n",
            "        [-3.5019,  3.6943],\n",
            "        [ 3.8285, -4.3100],\n",
            "        [ 3.6696, -4.1673],\n",
            "        [ 3.1790, -3.6985],\n",
            "        [ 3.8738, -4.3283]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8978, -4.3197],\n",
            "        [ 3.7944, -4.2713],\n",
            "        [-3.5540,  3.7249],\n",
            "        [ 3.7359, -4.2300],\n",
            "        [ 3.9979, -4.3313],\n",
            "        [ 3.8977, -4.3228],\n",
            "        [ 3.8512, -4.3119],\n",
            "        [ 3.8023, -4.3228],\n",
            "        [ 3.8283, -4.2769],\n",
            "        [ 3.8612, -4.2655],\n",
            "        [ 3.6981, -4.2296],\n",
            "        [ 3.8953, -4.2925],\n",
            "        [ 3.3079, -3.9479],\n",
            "        [ 3.7573, -4.2926],\n",
            "        [-3.5969,  3.7417],\n",
            "        [ 3.7957, -4.1908]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9187, -4.3468],\n",
            "        [ 3.6658, -4.1522],\n",
            "        [ 3.7619, -4.3241],\n",
            "        [-3.5174,  3.7847],\n",
            "        [-3.5155,  3.7956],\n",
            "        [ 3.7902, -4.2099],\n",
            "        [ 3.6721, -4.2252],\n",
            "        [-3.5202,  3.7360],\n",
            "        [ 3.4748, -3.9583],\n",
            "        [ 3.7747, -4.3350],\n",
            "        [-3.5814,  3.7911],\n",
            "        [ 3.8643, -4.3128],\n",
            "        [ 3.7221, -4.2401],\n",
            "        [ 3.8494, -4.2833],\n",
            "        [ 3.9128, -4.3309],\n",
            "        [ 3.8046, -4.2366]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8376, -4.2876],\n",
            "        [ 3.7257, -4.3016],\n",
            "        [ 3.8478, -4.2950],\n",
            "        [ 3.8876, -4.3065],\n",
            "        [ 3.7759, -4.2699],\n",
            "        [ 3.8075, -4.2742],\n",
            "        [ 3.7128, -4.2520],\n",
            "        [ 3.7366, -4.2394],\n",
            "        [ 3.7254, -4.3067],\n",
            "        [-3.3249,  3.3298],\n",
            "        [ 3.7861, -4.1840],\n",
            "        [ 3.8674, -4.2971],\n",
            "        [ 3.9375, -4.3137],\n",
            "        [ 3.7464, -4.2460],\n",
            "        [ 3.8876, -4.3568],\n",
            "        [ 3.8697, -4.3255]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.7835, -4.2864],\n",
            "        [ 3.9570, -4.3320],\n",
            "        [ 3.8062, -4.3166],\n",
            "        [ 3.7779, -4.2032],\n",
            "        [ 3.9655, -4.3237],\n",
            "        [-3.5500,  3.7723],\n",
            "        [ 3.9343, -4.3451],\n",
            "        [ 3.7192, -4.2501],\n",
            "        [ 3.7975, -4.2978],\n",
            "        [ 3.9837, -4.3267],\n",
            "        [ 3.8891, -4.2441],\n",
            "        [ 3.8586, -4.2659],\n",
            "        [ 3.5913, -4.1635],\n",
            "        [-1.9958,  2.1947],\n",
            "        [ 3.6047, -4.1765],\n",
            "        [ 3.8528, -4.3283]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8449, -4.3589],\n",
            "        [ 3.9798, -4.3383],\n",
            "        [ 3.8975, -4.3087],\n",
            "        [ 3.7783, -4.1704],\n",
            "        [ 3.5474, -4.1283],\n",
            "        [-2.3623,  2.4893],\n",
            "        [ 3.9097, -4.3363],\n",
            "        [ 3.9018, -4.3093],\n",
            "        [ 3.8841, -4.3006],\n",
            "        [ 3.8052, -4.3329],\n",
            "        [ 3.7875, -4.2492],\n",
            "        [ 3.8690, -4.2896],\n",
            "        [-3.5551,  3.7388],\n",
            "        [ 3.8215, -4.3190],\n",
            "        [ 3.7111, -4.2369],\n",
            "        [-3.5898,  3.7638]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9287, -4.2986],\n",
            "        [ 3.6887, -4.2388],\n",
            "        [ 3.9826, -4.3384],\n",
            "        [ 3.8555, -4.2997],\n",
            "        [ 3.7244, -4.2320],\n",
            "        [ 3.9610, -4.3559],\n",
            "        [ 3.7651, -4.2547],\n",
            "        [ 3.7362, -4.2653],\n",
            "        [-3.3328,  3.7296],\n",
            "        [ 3.9804, -4.3607],\n",
            "        [ 3.8211, -4.3092],\n",
            "        [ 3.7966, -4.2746],\n",
            "        [ 3.9470, -4.3638],\n",
            "        [ 3.9311, -4.3337],\n",
            "        [ 3.6941, -4.2071],\n",
            "        [ 3.9739, -4.3510]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8764, -4.2841],\n",
            "        [ 3.7795, -4.3088],\n",
            "        [ 3.8198, -4.2789],\n",
            "        [ 3.8687, -4.2964],\n",
            "        [ 3.8962, -4.3624],\n",
            "        [-3.5577,  3.8083],\n",
            "        [ 3.9400, -4.3470],\n",
            "        [ 3.9177, -4.3244],\n",
            "        [ 3.7644, -4.2998],\n",
            "        [ 3.8369, -4.2544],\n",
            "        [ 3.8709, -4.2595],\n",
            "        [ 3.8589, -4.2800],\n",
            "        [ 3.9414, -4.2855],\n",
            "        [ 3.9633, -4.3666],\n",
            "        [-3.5456,  3.7345],\n",
            "        [ 3.8769, -4.2426]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9149, -4.3485],\n",
            "        [-3.5990,  3.7947],\n",
            "        [ 3.9529, -4.3249],\n",
            "        [ 3.8205, -4.3349],\n",
            "        [ 3.9283, -4.3192],\n",
            "        [ 3.6546, -4.1968],\n",
            "        [ 3.9376, -4.3436],\n",
            "        [ 3.8305, -4.3115],\n",
            "        [ 3.6482, -4.2214],\n",
            "        [-3.6006,  3.7503],\n",
            "        [ 3.7119, -4.2547],\n",
            "        [ 3.9024, -4.2279],\n",
            "        [ 3.7217, -4.2363],\n",
            "        [ 3.9990, -4.3599],\n",
            "        [ 3.9454, -4.3260],\n",
            "        [-3.5010,  3.7977]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9285, -4.3553],\n",
            "        [ 3.4706, -4.0984],\n",
            "        [ 3.8598, -4.3241],\n",
            "        [ 3.8367, -4.2990],\n",
            "        [ 3.9956, -4.3196],\n",
            "        [ 3.9565, -4.3319],\n",
            "        [ 3.9615, -4.3708],\n",
            "        [-3.6022,  3.7745],\n",
            "        [ 3.9701, -4.3538],\n",
            "        [ 3.9023, -4.3116],\n",
            "        [ 3.7997, -4.2803],\n",
            "        [ 3.9363, -4.3738],\n",
            "        [ 3.9680, -4.3547],\n",
            "        [-3.5873,  3.7944],\n",
            "        [ 4.0328, -4.3072],\n",
            "        [ 3.7624, -4.2664]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8806, -4.3501],\n",
            "        [ 3.9208, -4.2967],\n",
            "        [ 3.9007, -4.2761],\n",
            "        [ 3.9230, -4.3400],\n",
            "        [ 3.8982, -4.3515],\n",
            "        [ 3.9919, -4.3786],\n",
            "        [ 3.8039, -4.3059],\n",
            "        [-3.2340,  3.4143],\n",
            "        [ 3.8286, -4.2283],\n",
            "        [ 3.7964, -4.2928],\n",
            "        [ 3.2129, -3.8206],\n",
            "        [-3.5344,  3.7816],\n",
            "        [ 3.7787, -4.2848],\n",
            "        [ 3.9794, -4.3643],\n",
            "        [ 3.4019, -3.9835],\n",
            "        [ 3.7113, -4.2113]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9822, -4.3570],\n",
            "        [ 3.7606, -4.3131],\n",
            "        [-3.5400,  3.8140],\n",
            "        [ 3.7963, -4.3204],\n",
            "        [ 3.7758, -4.2809],\n",
            "        [-3.5861,  3.8101],\n",
            "        [ 3.6232, -4.1777],\n",
            "        [ 3.7805, -4.3159],\n",
            "        [ 3.6402, -4.1224],\n",
            "        [ 3.9380, -4.3096],\n",
            "        [ 3.8608, -4.3283],\n",
            "        [ 3.9219, -4.2485],\n",
            "        [ 3.8698, -4.3788],\n",
            "        [-3.5891,  3.8334],\n",
            "        [ 3.8469, -4.3894],\n",
            "        [ 3.9986, -4.3893]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8445, -4.3466],\n",
            "        [ 3.6818, -4.1561],\n",
            "        [ 4.0061, -4.3511],\n",
            "        [-3.5780,  3.7935],\n",
            "        [ 3.7506, -4.3013],\n",
            "        [ 3.7110, -4.2778],\n",
            "        [ 3.7862, -4.3206],\n",
            "        [-3.5832,  3.7620],\n",
            "        [ 3.5401, -4.1200],\n",
            "        [ 3.8017, -4.2633],\n",
            "        [ 3.8645, -4.3050],\n",
            "        [ 3.6665, -4.2416],\n",
            "        [ 3.9074, -4.3119],\n",
            "        [-3.5641,  3.8037],\n",
            "        [ 3.6941, -4.2059],\n",
            "        [ 3.9051, -4.3791]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9216, -4.2269],\n",
            "        [ 3.8651, -4.3117],\n",
            "        [ 3.9436, -4.3629],\n",
            "        [-3.6407,  3.7897],\n",
            "        [ 3.9963, -4.3017],\n",
            "        [ 3.7253, -4.2753],\n",
            "        [ 3.8711, -4.3381],\n",
            "        [ 3.9899, -4.3719],\n",
            "        [ 3.8287, -4.1956],\n",
            "        [-3.5963,  3.7850],\n",
            "        [ 3.8187, -4.3363],\n",
            "        [-3.6199,  3.7726],\n",
            "        [ 3.9616, -4.3884],\n",
            "        [ 3.7018, -4.2465],\n",
            "        [ 3.8510, -4.3086],\n",
            "        [ 3.9234, -4.3608]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.7216, -4.2617],\n",
            "        [ 3.9364, -4.3430],\n",
            "        [ 3.9304, -4.3810],\n",
            "        [ 3.9523, -4.3626],\n",
            "        [ 3.7392, -4.2685],\n",
            "        [-3.5839,  3.8260],\n",
            "        [ 3.9842, -4.3546],\n",
            "        [ 3.7947, -4.2923],\n",
            "        [ 3.9987, -4.3792],\n",
            "        [ 3.9059, -4.3634],\n",
            "        [ 3.7657, -4.3029],\n",
            "        [ 3.9801, -4.3612],\n",
            "        [ 4.0123, -4.3616],\n",
            "        [ 3.9895, -4.3789],\n",
            "        [ 3.8491, -4.3434],\n",
            "        [ 3.6038, -4.1483]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.7686, -4.2695],\n",
            "        [ 3.9395, -4.2614],\n",
            "        [-3.6470,  3.7654],\n",
            "        [-3.5726,  3.8101],\n",
            "        [ 3.7290, -4.2331],\n",
            "        [ 3.7314, -4.2886],\n",
            "        [ 4.0103, -4.3924],\n",
            "        [ 3.6570, -4.2317],\n",
            "        [ 3.8453, -4.3339],\n",
            "        [ 3.6195, -4.2214],\n",
            "        [ 3.7577, -4.2737],\n",
            "        [ 3.9824, -4.2890],\n",
            "        [ 3.7139, -4.2568],\n",
            "        [ 3.7279, -4.2663],\n",
            "        [ 4.0291, -4.3866],\n",
            "        [ 4.0332, -4.3883]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8732, -4.3686],\n",
            "        [ 3.7857, -4.2940],\n",
            "        [ 4.0138, -4.3906],\n",
            "        [ 3.9688, -4.3440],\n",
            "        [ 3.9370, -4.3454],\n",
            "        [ 3.8701, -4.3436],\n",
            "        [ 3.9442, -4.3850],\n",
            "        [ 3.9866, -4.3700],\n",
            "        [ 3.9902, -4.3661],\n",
            "        [-3.5663,  3.8086],\n",
            "        [-3.6573,  3.8150],\n",
            "        [ 3.8328, -4.3248],\n",
            "        [-3.6202,  3.7970],\n",
            "        [ 3.7243, -4.2633],\n",
            "        [ 3.8003, -4.3035],\n",
            "        [ 3.9650, -4.3067]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9565, -4.3938],\n",
            "        [ 3.9704, -4.3597],\n",
            "        [ 3.8438, -4.3657],\n",
            "        [ 4.0005, -4.3892],\n",
            "        [ 3.9652, -4.3567],\n",
            "        [ 3.9689, -4.3958],\n",
            "        [ 3.9321, -4.3364],\n",
            "        [-3.6195,  3.7916],\n",
            "        [ 3.9890, -4.3445],\n",
            "        [ 3.6620, -4.2544],\n",
            "        [ 3.9217, -4.3625],\n",
            "        [-3.6201,  3.8009],\n",
            "        [ 3.8513, -4.3220],\n",
            "        [ 3.8354, -4.3427],\n",
            "        [ 3.9008, -4.3741],\n",
            "        [ 3.9417, -4.3040]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.7560, -4.3466],\n",
            "        [ 3.9599, -4.3270],\n",
            "        [ 3.9001, -4.3279],\n",
            "        [ 3.9119, -4.3012],\n",
            "        [ 3.8851, -4.2973],\n",
            "        [ 3.9296, -4.3624],\n",
            "        [ 3.7859, -4.2970],\n",
            "        [ 3.9155, -4.3576],\n",
            "        [ 3.8510, -4.3350],\n",
            "        [ 3.8342, -4.3277],\n",
            "        [ 4.0092, -4.3713],\n",
            "        [ 3.9978, -4.3797],\n",
            "        [ 3.9557, -4.3261],\n",
            "        [ 3.9221, -4.3141],\n",
            "        [ 3.7558, -4.3032],\n",
            "        [ 3.9619, -4.3442]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0742, -4.3302],\n",
            "        [ 3.7893, -4.2534],\n",
            "        [-3.6203,  3.7803],\n",
            "        [ 3.9676, -4.3899],\n",
            "        [-3.6141,  3.7803],\n",
            "        [ 3.8509, -4.2925],\n",
            "        [ 4.0494, -4.3934],\n",
            "        [ 4.0564, -4.3863],\n",
            "        [ 3.8574, -4.3660],\n",
            "        [ 3.9175, -4.3444],\n",
            "        [ 3.8538, -4.3741],\n",
            "        [ 3.9205, -4.3775],\n",
            "        [-3.6388,  3.8560],\n",
            "        [ 3.7600, -4.3144],\n",
            "        [ 3.9420, -4.3635],\n",
            "        [ 3.9158, -4.3747]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9171, -4.3498],\n",
            "        [ 3.7958, -4.2939],\n",
            "        [ 4.0529, -4.3767],\n",
            "        [ 3.9247, -4.2824],\n",
            "        [ 3.9328, -4.3848],\n",
            "        [-3.5758,  3.8290],\n",
            "        [ 3.7588, -4.2933],\n",
            "        [ 3.9536, -4.3692],\n",
            "        [ 3.6737, -4.1978],\n",
            "        [-3.6249,  3.8190],\n",
            "        [ 4.0405, -4.3736],\n",
            "        [ 3.9999, -4.3380],\n",
            "        [ 4.0387, -4.3478],\n",
            "        [ 3.8299, -4.2878],\n",
            "        [-3.6183,  3.8225],\n",
            "        [ 3.9649, -4.2405]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.7980, -4.3166],\n",
            "        [ 3.9367, -4.4219],\n",
            "        [ 4.0381, -4.4195],\n",
            "        [-3.4603,  3.7380],\n",
            "        [ 3.9123, -4.3629],\n",
            "        [ 4.0147, -4.3482],\n",
            "        [ 3.9468, -4.3535],\n",
            "        [ 4.0446, -4.4103],\n",
            "        [ 3.8726, -4.3612],\n",
            "        [ 3.9202, -4.3486],\n",
            "        [ 4.0291, -4.4007],\n",
            "        [ 3.8307, -4.3338],\n",
            "        [ 3.7895, -4.2961],\n",
            "        [ 4.0207, -4.4087],\n",
            "        [ 4.0131, -4.4218],\n",
            "        [ 3.9130, -4.3516]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8810, -4.2933],\n",
            "        [ 3.5864, -4.1866],\n",
            "        [ 3.9621, -4.2890],\n",
            "        [ 3.9459, -4.3866],\n",
            "        [ 3.5960, -4.1961],\n",
            "        [ 3.9064, -4.3483],\n",
            "        [ 3.8880, -4.1956],\n",
            "        [ 3.7945, -4.2934],\n",
            "        [ 3.9704, -4.3970],\n",
            "        [ 3.9972, -4.3684],\n",
            "        [ 3.9595, -4.3506],\n",
            "        [ 3.9358, -4.3773],\n",
            "        [ 4.0401, -4.3354],\n",
            "        [ 4.0670, -4.3962],\n",
            "        [ 3.9207, -4.3660],\n",
            "        [-3.3871,  3.7399]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0733, -4.4040],\n",
            "        [-3.3068,  3.4877],\n",
            "        [ 3.3343, -3.9255],\n",
            "        [ 3.9321, -4.3913],\n",
            "        [ 3.9604, -4.4038],\n",
            "        [ 3.8931, -4.2722],\n",
            "        [ 3.7918, -4.3202],\n",
            "        [ 3.7389, -4.2735],\n",
            "        [ 3.9708, -4.4017],\n",
            "        [ 3.9189, -4.3140],\n",
            "        [ 3.9297, -4.3451],\n",
            "        [ 4.0264, -4.3741],\n",
            "        [ 3.9538, -4.3325],\n",
            "        [ 3.9747, -4.2466],\n",
            "        [ 3.8158, -4.3140],\n",
            "        [ 3.8611, -4.3473]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0080, -4.3479],\n",
            "        [-3.6346,  3.7875],\n",
            "        [-3.6375,  3.8400],\n",
            "        [ 3.8717, -4.3979],\n",
            "        [ 3.9451, -4.3669],\n",
            "        [ 3.8930, -4.3433],\n",
            "        [ 3.9701, -4.3899],\n",
            "        [ 3.9456, -4.3641],\n",
            "        [ 3.8742, -4.3082],\n",
            "        [ 4.0616, -4.3802],\n",
            "        [ 3.9715, -4.3839],\n",
            "        [ 4.0372, -4.4270],\n",
            "        [-3.6458,  3.8464],\n",
            "        [ 3.9718, -4.3903],\n",
            "        [ 3.9193, -4.3710],\n",
            "        [ 4.0012, -4.3483]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9566, -4.3740],\n",
            "        [ 3.9993, -4.4187],\n",
            "        [-3.6209,  3.8397],\n",
            "        [ 3.9739, -4.3564],\n",
            "        [ 3.8499, -4.3410],\n",
            "        [ 3.9398, -4.3424],\n",
            "        [ 3.9263, -4.3270],\n",
            "        [-3.5931,  3.8050],\n",
            "        [-3.5279,  3.8275],\n",
            "        [ 3.9285, -4.3522],\n",
            "        [ 3.9464, -4.3642],\n",
            "        [ 3.9207, -4.4217],\n",
            "        [ 3.9319, -4.3762],\n",
            "        [ 3.8971, -4.3180],\n",
            "        [ 3.8281, -4.3226],\n",
            "        [ 3.9728, -4.4162]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9839, -4.2525],\n",
            "        [ 3.9602, -4.3651],\n",
            "        [ 3.9692, -4.4032],\n",
            "        [ 3.9900, -4.4235],\n",
            "        [-3.6502,  3.8307],\n",
            "        [ 3.8683, -4.3641],\n",
            "        [ 3.6262, -4.2139],\n",
            "        [ 3.7376, -4.2643],\n",
            "        [ 3.9929, -4.3711],\n",
            "        [ 3.8826, -4.3725],\n",
            "        [ 4.0865, -4.3856],\n",
            "        [ 3.9080, -4.2936],\n",
            "        [ 3.7732, -4.2569],\n",
            "        [ 3.9873, -4.3547],\n",
            "        [ 4.0996, -4.3658],\n",
            "        [ 3.9173, -4.3417]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9419, -4.3305],\n",
            "        [ 3.9084, -4.3754],\n",
            "        [ 3.6893, -4.1767],\n",
            "        [ 3.9388, -4.2963],\n",
            "        [ 3.9087, -4.3855],\n",
            "        [ 3.9709, -4.3661],\n",
            "        [ 4.0017, -4.4257],\n",
            "        [-3.6684,  3.8286],\n",
            "        [ 3.9909, -4.3590],\n",
            "        [-3.6422,  3.8423],\n",
            "        [ 3.8181, -4.3384],\n",
            "        [ 3.9868, -4.3702],\n",
            "        [ 3.8566, -4.3392],\n",
            "        [ 3.9845, -4.4015],\n",
            "        [ 3.9766, -4.3907],\n",
            "        [-3.5457,  3.8240]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9780, -4.3795],\n",
            "        [ 3.8382, -4.3372],\n",
            "        [ 4.0013, -4.3826],\n",
            "        [ 4.0798, -4.4135],\n",
            "        [ 3.8659, -4.3768],\n",
            "        [ 3.8422, -4.3534],\n",
            "        [-3.6403,  3.8619],\n",
            "        [ 3.7708, -4.3054],\n",
            "        [ 3.9897, -4.2562],\n",
            "        [ 3.7997, -4.3196],\n",
            "        [-3.6355,  3.7635],\n",
            "        [ 3.8991, -4.3689],\n",
            "        [ 3.7801, -4.2698],\n",
            "        [ 4.0101, -4.3844],\n",
            "        [ 3.9626, -4.4086],\n",
            "        [ 4.0554, -4.3793]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0828, -4.4089],\n",
            "        [ 4.0804, -4.4155],\n",
            "        [ 4.0118, -4.3125],\n",
            "        [-3.6035,  3.8551],\n",
            "        [ 3.9168, -4.3584],\n",
            "        [ 3.8710, -4.3627],\n",
            "        [-3.6310,  3.8118],\n",
            "        [ 3.9528, -4.3561],\n",
            "        [ 3.8094, -4.3287],\n",
            "        [ 3.9478, -4.3660],\n",
            "        [ 3.9357, -4.4178],\n",
            "        [ 4.0149, -4.4396],\n",
            "        [ 3.9285, -4.3738],\n",
            "        [ 3.8151, -4.2606],\n",
            "        [ 3.7851, -4.3039],\n",
            "        [ 4.0727, -4.4190]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9812, -4.4170],\n",
            "        [ 3.9774, -4.3926],\n",
            "        [ 4.0344, -4.4564],\n",
            "        [ 3.9779, -4.3783],\n",
            "        [ 4.0554, -4.4062],\n",
            "        [ 3.8971, -4.3922],\n",
            "        [ 3.8132, -4.2481],\n",
            "        [ 3.9747, -4.4022],\n",
            "        [ 3.9689, -4.3143],\n",
            "        [ 4.0031, -4.3888],\n",
            "        [-3.6486,  3.8291],\n",
            "        [ 4.0024, -4.3566],\n",
            "        [ 4.0501, -4.4116],\n",
            "        [-3.6276,  3.8675],\n",
            "        [ 3.9703, -4.3702],\n",
            "        [ 3.9466, -4.4356]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9554, -4.3974],\n",
            "        [ 3.8891, -4.3788],\n",
            "        [ 4.0340, -4.3971],\n",
            "        [ 4.0127, -4.4022],\n",
            "        [ 3.8029, -4.2951],\n",
            "        [ 3.9718, -4.3925],\n",
            "        [ 3.9149, -4.3975],\n",
            "        [ 3.8655, -4.3580],\n",
            "        [ 3.7968, -4.2762],\n",
            "        [ 3.7954, -4.2989],\n",
            "        [ 3.0512, -3.7517],\n",
            "        [ 4.0146, -4.4077],\n",
            "        [ 3.8980, -4.3719],\n",
            "        [ 3.9532, -4.3854],\n",
            "        [-3.6430,  3.7912],\n",
            "        [ 3.9208, -4.2595]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0412, -4.4140],\n",
            "        [ 4.0320, -4.4107],\n",
            "        [ 3.9691, -4.4342],\n",
            "        [ 3.8546, -4.3514],\n",
            "        [ 3.9094, -4.2948],\n",
            "        [-3.6521,  3.8022],\n",
            "        [ 3.9615, -4.4206],\n",
            "        [ 3.8508, -4.3016],\n",
            "        [ 4.0352, -4.4400],\n",
            "        [ 3.9351, -4.3516],\n",
            "        [ 3.7674, -4.2751],\n",
            "        [ 4.1069, -4.3515],\n",
            "        [ 4.0648, -4.3932],\n",
            "        [ 3.9796, -4.4463],\n",
            "        [ 4.0616, -4.3526],\n",
            "        [ 4.0218, -4.4476]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0055, -4.4176],\n",
            "        [ 4.0491, -4.4101],\n",
            "        [ 3.9124, -4.3365],\n",
            "        [ 3.8765, -4.3559],\n",
            "        [ 3.9863, -4.4083],\n",
            "        [-3.5752,  3.8436],\n",
            "        [ 3.9378, -4.4364],\n",
            "        [ 3.9642, -4.3507],\n",
            "        [ 4.0762, -4.4222],\n",
            "        [-3.6092,  3.8741],\n",
            "        [ 4.0752, -4.4390],\n",
            "        [ 3.9727, -4.3307],\n",
            "        [-3.6682,  3.8196],\n",
            "        [ 4.0753, -4.4222],\n",
            "        [ 3.8538, -4.3646],\n",
            "        [ 4.0233, -4.4269]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9630, -4.2757],\n",
            "        [ 4.0724, -4.4711],\n",
            "        [ 4.0161, -4.4150],\n",
            "        [-3.6610,  3.8132],\n",
            "        [ 4.0938, -4.4294],\n",
            "        [ 3.9668, -4.3902],\n",
            "        [-1.8349,  1.9665],\n",
            "        [ 4.0365, -4.4350],\n",
            "        [ 4.0985, -4.4189],\n",
            "        [ 4.0185, -4.3324],\n",
            "        [ 4.0480, -4.3793],\n",
            "        [-3.6506,  3.8701],\n",
            "        [ 4.0213, -4.2483],\n",
            "        [ 3.7784, -4.3229],\n",
            "        [ 3.8335, -4.3471],\n",
            "        [ 3.9618, -4.3814]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1019, -4.4154],\n",
            "        [-3.7171,  3.7915],\n",
            "        [ 3.9438, -4.3829],\n",
            "        [ 3.9397, -4.3650],\n",
            "        [ 4.0652, -4.4581],\n",
            "        [ 3.5055, -4.0841],\n",
            "        [ 3.9034, -4.3332],\n",
            "        [ 4.0110, -4.4044],\n",
            "        [ 3.8180, -4.2665],\n",
            "        [ 4.0764, -4.4554],\n",
            "        [ 3.8935, -4.3860],\n",
            "        [ 3.9514, -4.3518],\n",
            "        [ 3.9392, -4.3992],\n",
            "        [ 4.0589, -4.4639],\n",
            "        [-3.6795,  3.7813],\n",
            "        [ 4.0951, -4.4281]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0783, -4.4405],\n",
            "        [-3.6489,  3.8419],\n",
            "        [ 4.1176, -4.4198],\n",
            "        [-3.6841,  3.8608],\n",
            "        [ 3.9550, -4.3598],\n",
            "        [ 3.9421, -4.3762],\n",
            "        [ 3.9305, -4.3835],\n",
            "        [ 4.0565, -4.4238],\n",
            "        [ 4.0399, -4.4153],\n",
            "        [-3.5842,  3.8714],\n",
            "        [ 4.0112, -4.2707],\n",
            "        [ 3.9815, -4.3781],\n",
            "        [ 3.9886, -4.4499],\n",
            "        [ 3.9108, -4.3929],\n",
            "        [ 3.8843, -4.3110],\n",
            "        [ 4.0769, -4.4478]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.6796,  3.7870],\n",
            "        [ 4.0475, -4.4284],\n",
            "        [ 4.0288, -4.4239],\n",
            "        [ 3.8684, -4.2766],\n",
            "        [ 4.0708, -4.4077],\n",
            "        [ 4.0819, -4.4384],\n",
            "        [ 3.9056, -4.3916],\n",
            "        [-3.6471,  3.8613],\n",
            "        [ 3.9097, -4.3795],\n",
            "        [-3.6398,  3.8548],\n",
            "        [ 3.9517, -4.4059],\n",
            "        [ 4.0866, -4.4552],\n",
            "        [ 3.9551, -4.4064],\n",
            "        [ 3.9720, -4.3794],\n",
            "        [-3.6953,  3.8490],\n",
            "        [-3.6550,  3.7206]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0808, -4.4201],\n",
            "        [ 3.9460, -4.4325],\n",
            "        [-3.6488,  3.8501],\n",
            "        [-3.7100,  3.8209],\n",
            "        [ 3.9253, -4.3292],\n",
            "        [-3.6532,  3.7878],\n",
            "        [ 3.9964, -4.3942],\n",
            "        [ 3.5237, -4.1181],\n",
            "        [-3.6645,  3.8534],\n",
            "        [ 3.8096, -4.3371],\n",
            "        [ 3.9306, -4.4118],\n",
            "        [ 4.1257, -4.4045],\n",
            "        [ 3.7867, -4.2989],\n",
            "        [ 4.1153, -4.4477],\n",
            "        [ 4.0664, -4.4707],\n",
            "        [ 4.1336, -4.3776]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9823, -4.3862],\n",
            "        [ 4.0974, -4.4538],\n",
            "        [ 3.9896, -4.4617],\n",
            "        [ 4.1181, -4.4481],\n",
            "        [-3.6182,  3.8638],\n",
            "        [ 3.9911, -4.4155],\n",
            "        [-3.6757,  3.7885],\n",
            "        [ 4.0758, -4.4832],\n",
            "        [ 4.1184, -4.4283],\n",
            "        [ 4.1038, -4.3942],\n",
            "        [ 4.1086, -4.4295],\n",
            "        [ 3.9998, -4.4553],\n",
            "        [ 4.0278, -4.4229],\n",
            "        [ 3.8971, -4.3561],\n",
            "        [ 4.1296, -4.4261],\n",
            "        [-3.7008,  3.8695]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0552, -4.4355],\n",
            "        [ 4.0319, -4.3887],\n",
            "        [ 3.9849, -4.3904],\n",
            "        [ 3.7320, -4.1728],\n",
            "        [ 3.9293, -4.3823],\n",
            "        [ 4.0410, -4.4666],\n",
            "        [ 4.0072, -4.3920],\n",
            "        [ 3.9815, -4.3785],\n",
            "        [-3.6101,  3.7727],\n",
            "        [ 4.0503, -4.3966],\n",
            "        [ 4.0941, -4.4507],\n",
            "        [ 4.0669, -4.4500],\n",
            "        [-3.6795,  3.8698],\n",
            "        [ 4.0819, -4.4117],\n",
            "        [ 3.9916, -4.4586],\n",
            "        [ 3.8969, -4.3376]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0815, -4.4115],\n",
            "        [ 3.9785, -4.4059],\n",
            "        [-3.5562,  3.8392],\n",
            "        [ 3.8421, -4.2960],\n",
            "        [ 4.1188, -4.4272],\n",
            "        [ 3.9722, -4.4172],\n",
            "        [ 4.0668, -4.4624],\n",
            "        [ 3.9242, -4.3978],\n",
            "        [-3.6197,  3.8431],\n",
            "        [ 3.9823, -4.3805],\n",
            "        [-3.6455,  3.8775],\n",
            "        [ 4.0350, -4.4284],\n",
            "        [ 3.8799, -4.3738],\n",
            "        [ 3.9346, -4.3814],\n",
            "        [-3.6965,  3.8231],\n",
            "        [ 4.0729, -4.4411]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1330, -4.4420],\n",
            "        [ 4.1272, -4.4297],\n",
            "        [ 4.1247, -4.4450],\n",
            "        [ 3.9693, -4.4208],\n",
            "        [ 4.1017, -4.4507],\n",
            "        [ 3.9536, -4.4042],\n",
            "        [ 3.9973, -4.4100],\n",
            "        [ 4.0670, -4.4421],\n",
            "        [ 3.9951, -4.4538],\n",
            "        [ 4.1381, -4.4557],\n",
            "        [-3.6767,  3.8569],\n",
            "        [ 3.8124, -4.3119],\n",
            "        [ 4.0358, -4.4078],\n",
            "        [ 4.0447, -4.3836],\n",
            "        [ 4.0480, -4.3391],\n",
            "        [ 4.0289, -4.4877]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9787, -4.4222],\n",
            "        [ 4.0231, -4.4506],\n",
            "        [-3.6919,  3.9019],\n",
            "        [ 4.0481, -4.4124],\n",
            "        [ 4.0924, -4.4453],\n",
            "        [ 4.0449, -4.4710],\n",
            "        [ 4.0993, -4.4517],\n",
            "        [ 4.0434, -4.4047],\n",
            "        [-3.6811,  3.8784],\n",
            "        [ 4.0587, -4.3392],\n",
            "        [ 3.8567, -4.3998],\n",
            "        [-3.6252,  3.8932],\n",
            "        [ 4.0741, -4.4143],\n",
            "        [ 4.0021, -4.4057],\n",
            "        [ 4.0487, -4.4533],\n",
            "        [ 4.0301, -4.4041]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0066, -4.3976],\n",
            "        [ 4.0647, -4.4228],\n",
            "        [ 3.8489, -4.3382],\n",
            "        [-3.3468,  3.5214],\n",
            "        [ 4.1369, -4.4404],\n",
            "        [ 4.0462, -4.4223],\n",
            "        [ 4.0237, -4.4420],\n",
            "        [ 4.0696, -4.4278],\n",
            "        [ 4.1194, -4.4110],\n",
            "        [-3.7191,  3.8548],\n",
            "        [ 3.9895, -4.3311],\n",
            "        [-3.6969,  3.8662],\n",
            "        [ 4.1145, -4.4540],\n",
            "        [ 4.0063, -4.4606],\n",
            "        [ 4.0177, -4.4830],\n",
            "        [ 4.0543, -4.3479]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8683, -4.3910],\n",
            "        [ 4.0522, -4.4755],\n",
            "        [ 4.0735, -4.4470],\n",
            "        [ 4.1149, -4.4357],\n",
            "        [ 4.0533, -4.4634],\n",
            "        [-3.7039,  3.8245],\n",
            "        [ 3.7753, -4.2572],\n",
            "        [-3.7088,  3.8504],\n",
            "        [ 3.9780, -4.4226],\n",
            "        [ 4.0922, -4.4699],\n",
            "        [ 4.0112, -4.4161],\n",
            "        [-3.2364,  3.4059],\n",
            "        [ 4.0823, -4.3998],\n",
            "        [-3.6951,  3.8686],\n",
            "        [ 4.0384, -4.4191],\n",
            "        [ 4.1310, -4.4512]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.3885,  3.7272],\n",
            "        [ 3.8737, -4.3369],\n",
            "        [-3.4947,  3.5289],\n",
            "        [ 4.0918, -4.4253],\n",
            "        [ 4.0731, -4.4708],\n",
            "        [ 3.9927, -4.4571],\n",
            "        [ 4.1111, -4.4463],\n",
            "        [ 4.0509, -4.4432],\n",
            "        [-3.6524,  3.8823],\n",
            "        [ 3.9773, -4.4105],\n",
            "        [ 3.6668, -4.2577],\n",
            "        [ 4.1221, -4.4818],\n",
            "        [ 4.0215, -4.4128],\n",
            "        [ 4.0300, -4.4362],\n",
            "        [ 4.0919, -4.4806],\n",
            "        [ 3.9538, -4.4235]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9995, -4.4182],\n",
            "        [ 4.0757, -4.4545],\n",
            "        [ 4.0394, -4.4360],\n",
            "        [ 3.9880, -4.4020],\n",
            "        [ 3.8492, -4.2770],\n",
            "        [ 4.0268, -4.4495],\n",
            "        [ 3.9883, -4.3884],\n",
            "        [ 4.1112, -4.4235],\n",
            "        [ 4.0368, -4.4507],\n",
            "        [-3.7063,  3.8747],\n",
            "        [ 4.1084, -4.4408],\n",
            "        [ 4.0471, -4.4083],\n",
            "        [ 4.0749, -4.4626],\n",
            "        [ 3.9645, -4.3751],\n",
            "        [ 3.8813, -4.3693],\n",
            "        [ 4.0152, -4.4476]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1417, -4.4581],\n",
            "        [ 4.0314, -4.4516],\n",
            "        [ 4.0812, -4.5017],\n",
            "        [ 3.9974, -4.4199],\n",
            "        [-3.6030,  3.8698],\n",
            "        [ 3.9486, -4.4359],\n",
            "        [ 3.8856, -4.4058],\n",
            "        [ 4.0312, -4.4570],\n",
            "        [ 4.0598, -4.4484],\n",
            "        [ 3.9964, -4.4330],\n",
            "        [ 4.1542, -4.4288],\n",
            "        [-3.7136,  3.8973],\n",
            "        [ 4.0571, -4.4722],\n",
            "        [ 4.0194, -4.4172],\n",
            "        [ 4.1426, -4.4589],\n",
            "        [ 4.0024, -4.3305]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1209, -4.4274],\n",
            "        [ 4.0633, -4.4866],\n",
            "        [-3.6542,  3.9010],\n",
            "        [ 3.9940, -4.3841],\n",
            "        [-3.7398,  3.8632],\n",
            "        [ 3.8325, -4.3757],\n",
            "        [ 3.6880, -4.2777],\n",
            "        [-3.6747,  3.9095],\n",
            "        [-3.7043,  3.8983],\n",
            "        [-3.7383,  3.8562],\n",
            "        [ 3.9862, -4.4248],\n",
            "        [ 4.1261, -4.4443],\n",
            "        [ 4.1044, -4.4519],\n",
            "        [-3.7147,  3.8665],\n",
            "        [ 4.0446, -4.4261],\n",
            "        [ 4.0332, -4.4513]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0224, -4.4196],\n",
            "        [ 3.8565, -4.3354],\n",
            "        [ 4.1421, -4.4778],\n",
            "        [ 4.0051, -4.4467],\n",
            "        [-3.7053,  3.8553],\n",
            "        [ 4.1042, -4.4653],\n",
            "        [ 3.9981, -4.4617],\n",
            "        [ 4.0814, -4.4189],\n",
            "        [ 4.1356, -4.4805],\n",
            "        [ 4.0567, -4.4705],\n",
            "        [ 3.9664, -4.4268],\n",
            "        [ 3.9640, -4.4220],\n",
            "        [ 3.9846, -4.4462],\n",
            "        [ 3.9263, -4.4173],\n",
            "        [ 4.1117, -4.4416],\n",
            "        [ 4.1050, -4.4855]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0781, -4.5111],\n",
            "        [ 4.0123, -4.4581],\n",
            "        [ 3.9977, -4.4126],\n",
            "        [ 4.0641, -4.4345],\n",
            "        [ 3.9793, -4.4329],\n",
            "        [ 4.0565, -4.4328],\n",
            "        [ 4.0386, -4.2892],\n",
            "        [ 4.0618, -4.4568],\n",
            "        [ 4.0485, -4.4198],\n",
            "        [ 4.1087, -4.4299],\n",
            "        [ 4.0874, -4.4921],\n",
            "        [ 3.9905, -4.3834],\n",
            "        [ 4.0008, -4.4487],\n",
            "        [-3.7438,  3.8613],\n",
            "        [ 4.1057, -4.4637],\n",
            "        [ 4.0427, -4.4728]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8280, -4.2907],\n",
            "        [ 4.0424, -4.4390],\n",
            "        [ 4.1346, -4.4680],\n",
            "        [ 4.0481, -4.2994],\n",
            "        [ 4.0413, -4.4713],\n",
            "        [ 4.1080, -4.4522],\n",
            "        [-2.1793,  2.3200],\n",
            "        [-3.6874,  3.8891],\n",
            "        [ 4.0208, -4.4463],\n",
            "        [ 4.1489, -4.4523],\n",
            "        [ 4.1445, -4.4683],\n",
            "        [ 4.1271, -4.4535],\n",
            "        [ 4.0853, -4.4050],\n",
            "        [ 4.0775, -4.4495],\n",
            "        [ 3.8013, -4.3139],\n",
            "        [ 4.0420, -4.4713]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1466, -4.4548],\n",
            "        [-3.7395,  3.8997],\n",
            "        [ 4.0532, -4.4961],\n",
            "        [ 4.0156, -4.4877],\n",
            "        [ 3.9248, -4.3027],\n",
            "        [ 4.0481, -4.4186],\n",
            "        [ 3.9858, -4.3961],\n",
            "        [ 4.0782, -4.3499],\n",
            "        [-3.7198,  3.8594],\n",
            "        [ 4.1235, -4.4640],\n",
            "        [ 3.7992, -4.2421],\n",
            "        [ 4.0723, -4.5029],\n",
            "        [ 3.8535, -4.3505],\n",
            "        [ 4.0040, -4.4500],\n",
            "        [-3.6447,  3.9053],\n",
            "        [ 4.0507, -4.3978]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0646, -4.4052],\n",
            "        [ 4.0514, -4.4471],\n",
            "        [ 4.1537, -4.4358],\n",
            "        [ 3.6189, -4.2077],\n",
            "        [ 4.0483, -4.4746],\n",
            "        [ 3.7951, -4.3536],\n",
            "        [ 3.9710, -4.2828],\n",
            "        [ 4.1503, -4.4020],\n",
            "        [ 4.0855, -4.5042],\n",
            "        [-3.6686,  3.8855],\n",
            "        [-3.7137,  3.8397],\n",
            "        [ 4.1528, -4.4638],\n",
            "        [-3.6872,  3.8948],\n",
            "        [ 4.1234, -4.4861],\n",
            "        [ 4.0926, -4.4090],\n",
            "        [ 3.9750, -4.4341]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0629, -4.4212],\n",
            "        [ 3.8391, -4.2651],\n",
            "        [ 3.9496, -4.4280],\n",
            "        [ 4.0934, -4.4243],\n",
            "        [ 3.9978, -4.4312],\n",
            "        [ 4.0839, -4.3971],\n",
            "        [ 3.7793, -4.3261],\n",
            "        [-3.7212,  3.8754],\n",
            "        [-3.0015,  3.1461],\n",
            "        [ 4.0061, -4.4489],\n",
            "        [ 3.8564, -4.4087],\n",
            "        [ 4.0291, -4.4215],\n",
            "        [ 4.1500, -4.4223],\n",
            "        [-3.7260,  3.8851],\n",
            "        [ 4.1666, -4.4647],\n",
            "        [ 4.0743, -4.4047]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1122, -4.4991],\n",
            "        [ 4.0965, -4.4514],\n",
            "        [ 3.9906, -4.4572],\n",
            "        [ 3.9564, -4.4177],\n",
            "        [ 4.1372, -4.4752],\n",
            "        [ 4.1734, -4.4643],\n",
            "        [-3.6815,  3.9092],\n",
            "        [ 3.9892, -4.3747],\n",
            "        [ 4.0467, -4.4437],\n",
            "        [-3.7012,  3.8507],\n",
            "        [ 4.0983, -4.4563],\n",
            "        [ 3.9016, -4.3949],\n",
            "        [ 4.1234, -4.4686],\n",
            "        [ 4.0323, -4.4269],\n",
            "        [ 4.0643, -4.4638],\n",
            "        [ 4.1062, -4.5095]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9867, -4.4947],\n",
            "        [ 4.0623, -4.4738],\n",
            "        [-3.6989,  3.9150],\n",
            "        [ 4.1462, -4.4989],\n",
            "        [ 3.8275, -4.3350],\n",
            "        [ 4.0859, -4.4798],\n",
            "        [ 4.1374, -4.5072],\n",
            "        [ 4.0999, -4.4689],\n",
            "        [-3.6907,  3.9170],\n",
            "        [ 4.0997, -4.4722],\n",
            "        [ 4.1545, -4.4892],\n",
            "        [ 4.1302, -4.4534],\n",
            "        [ 4.0921, -4.4492],\n",
            "        [ 4.1294, -4.4658],\n",
            "        [ 4.1134, -4.4878],\n",
            "        [ 4.1577, -4.4936]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.7294,  3.8590],\n",
            "        [ 4.0236, -4.5128],\n",
            "        [ 4.1127, -4.4158],\n",
            "        [ 4.1371, -4.5113],\n",
            "        [ 4.0170, -4.4698],\n",
            "        [ 4.0900, -4.4823],\n",
            "        [ 4.0208, -4.4390],\n",
            "        [ 4.0721, -4.4902],\n",
            "        [-3.7378,  3.9046],\n",
            "        [ 4.0396, -4.4789],\n",
            "        [ 4.0200, -4.4327],\n",
            "        [ 4.0875, -4.4281],\n",
            "        [ 4.0455, -4.4225],\n",
            "        [-3.7381,  3.9026],\n",
            "        [ 3.9189, -4.3278],\n",
            "        [ 4.0611, -4.4771]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1343, -4.4703],\n",
            "        [ 4.1525, -4.4660],\n",
            "        [ 3.8998, -4.3937],\n",
            "        [ 3.9874, -4.4017],\n",
            "        [ 4.1786, -4.4713],\n",
            "        [ 4.0198, -4.4828],\n",
            "        [ 4.0022, -4.3988],\n",
            "        [ 3.6916, -4.3025],\n",
            "        [ 3.9851, -4.3660],\n",
            "        [ 4.1443, -4.4892],\n",
            "        [ 4.1827, -4.4378],\n",
            "        [ 3.7618, -4.3146],\n",
            "        [ 4.1676, -4.4129],\n",
            "        [ 4.0850, -4.4512],\n",
            "        [ 4.0079, -4.4111],\n",
            "        [ 3.6312, -4.1793]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.7951, -4.2988],\n",
            "        [ 4.0451, -4.4422],\n",
            "        [ 4.1589, -4.4171],\n",
            "        [ 4.1195, -4.4955],\n",
            "        [ 4.1284, -4.4618],\n",
            "        [ 4.1345, -4.3961],\n",
            "        [ 4.0280, -4.4607],\n",
            "        [ 4.1209, -4.4444],\n",
            "        [ 3.8994, -4.3923],\n",
            "        [-3.7606,  3.9039],\n",
            "        [ 4.1014, -4.4994],\n",
            "        [ 4.0449, -4.4787],\n",
            "        [-3.7311,  3.9062],\n",
            "        [ 4.1586, -4.4920],\n",
            "        [-3.7373,  3.8771],\n",
            "        [ 4.1202, -4.4754]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.7487,  3.9110],\n",
            "        [ 4.0542, -4.4841],\n",
            "        [ 4.1481, -4.5027],\n",
            "        [ 4.0313, -4.4633],\n",
            "        [ 4.0678, -4.4533],\n",
            "        [ 4.0671, -4.3154],\n",
            "        [ 3.8697, -4.4091],\n",
            "        [ 4.1532, -4.4580],\n",
            "        [ 4.0220, -4.3808],\n",
            "        [ 4.0811, -4.4856],\n",
            "        [ 4.1280, -4.4740],\n",
            "        [ 4.0043, -4.4555],\n",
            "        [ 4.0253, -4.5020],\n",
            "        [ 4.1773, -4.4921],\n",
            "        [ 4.0960, -4.5384],\n",
            "        [ 4.0945, -4.4451]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0813, -4.4833],\n",
            "        [ 4.0360, -4.4202],\n",
            "        [ 4.1108, -4.3732],\n",
            "        [ 3.7797, -4.2692],\n",
            "        [ 4.1298, -4.4379],\n",
            "        [ 4.1369, -4.5072],\n",
            "        [ 4.0548, -4.4912],\n",
            "        [ 4.0934, -4.4994],\n",
            "        [ 4.0090, -4.4987],\n",
            "        [ 4.1111, -4.5197],\n",
            "        [ 4.0183, -4.4602],\n",
            "        [ 4.1564, -4.5051],\n",
            "        [-3.7516,  3.9173],\n",
            "        [ 4.1418, -4.4822],\n",
            "        [ 3.9505, -4.4271],\n",
            "        [-3.7336,  3.9104]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1337, -4.5242],\n",
            "        [ 4.0216, -4.4329],\n",
            "        [ 4.0887, -4.4695],\n",
            "        [ 3.9605, -4.4563],\n",
            "        [ 4.1024, -4.4826],\n",
            "        [ 4.1079, -4.5115],\n",
            "        [-3.7416,  3.8927],\n",
            "        [ 3.9807, -4.4225],\n",
            "        [ 4.0626, -4.4567],\n",
            "        [ 4.1348, -4.4945],\n",
            "        [ 4.0859, -4.4505],\n",
            "        [ 4.1715, -4.5029],\n",
            "        [ 4.0702, -4.4259],\n",
            "        [-3.7131,  3.9054],\n",
            "        [ 3.9107, -4.4156],\n",
            "        [ 4.0979, -4.5057]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1599, -4.5149],\n",
            "        [ 4.1917, -4.4585],\n",
            "        [ 4.1461, -4.5034],\n",
            "        [ 3.7509, -4.2789],\n",
            "        [ 4.1129, -4.4552],\n",
            "        [ 3.9418, -4.4406],\n",
            "        [ 4.1747, -4.4731],\n",
            "        [ 3.9088, -4.4566],\n",
            "        [ 4.1317, -4.5132],\n",
            "        [ 3.8114, -4.3122],\n",
            "        [ 4.1276, -4.4848],\n",
            "        [ 4.0186, -4.4930],\n",
            "        [ 4.0972, -4.4707],\n",
            "        [ 4.1744, -4.5071],\n",
            "        [ 4.1551, -4.4642],\n",
            "        [ 4.0551, -4.4595]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.7872,  3.8816],\n",
            "        [ 4.0650, -4.3290],\n",
            "        [ 3.3276, -3.9915],\n",
            "        [ 4.1179, -4.4763],\n",
            "        [ 4.1802, -4.4801],\n",
            "        [ 4.1875, -4.4855],\n",
            "        [-3.7490,  3.9310],\n",
            "        [ 4.1549, -4.4821],\n",
            "        [ 4.0316, -4.4738],\n",
            "        [-3.6912,  3.8758],\n",
            "        [ 3.9480, -4.4397],\n",
            "        [ 4.1425, -4.4672],\n",
            "        [ 3.9743, -4.4469],\n",
            "        [ 4.1030, -4.4945],\n",
            "        [ 3.9662, -4.4180],\n",
            "        [ 3.9508, -4.3650]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0883, -4.4901],\n",
            "        [ 3.9687, -4.4182],\n",
            "        [ 3.5379, -4.1406],\n",
            "        [ 4.1488, -4.5057],\n",
            "        [ 4.1385, -4.5262],\n",
            "        [ 4.1265, -4.5091],\n",
            "        [ 4.0448, -4.3319],\n",
            "        [ 4.0060, -4.4946],\n",
            "        [-3.7521,  3.8812],\n",
            "        [ 4.1213, -4.4031],\n",
            "        [ 4.1806, -4.4886],\n",
            "        [ 4.0991, -4.4857],\n",
            "        [ 4.1725, -4.5322],\n",
            "        [ 3.9899, -4.4816],\n",
            "        [ 4.1438, -4.5365],\n",
            "        [ 4.1017, -4.4660]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.7188,  3.9456],\n",
            "        [-3.7783,  3.8941],\n",
            "        [ 4.0680, -4.5042],\n",
            "        [ 3.9968, -4.4822],\n",
            "        [ 4.1568, -4.4917],\n",
            "        [ 4.0290, -4.5103],\n",
            "        [ 4.1694, -4.5121],\n",
            "        [ 4.0504, -4.4765],\n",
            "        [ 4.0982, -4.4778],\n",
            "        [ 4.1051, -4.4800],\n",
            "        [ 4.0355, -4.3550],\n",
            "        [-3.7584,  3.9001],\n",
            "        [ 4.0485, -4.4455],\n",
            "        [ 1.4563, -2.2186],\n",
            "        [-3.6813,  3.9279],\n",
            "        [ 4.1547, -4.4844]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9863, -4.4567],\n",
            "        [ 4.1637, -4.5253],\n",
            "        [ 4.1183, -4.5349],\n",
            "        [ 4.2048, -4.4661],\n",
            "        [ 4.1997, -4.4390],\n",
            "        [ 4.1520, -4.4510],\n",
            "        [ 4.1314, -4.4952],\n",
            "        [ 4.1410, -4.4928],\n",
            "        [-3.7360,  3.9007],\n",
            "        [ 4.1013, -4.5074],\n",
            "        [ 4.0677, -4.5159],\n",
            "        [ 4.1159, -4.4609],\n",
            "        [-3.7805,  3.8960],\n",
            "        [ 4.1242, -4.4945],\n",
            "        [ 4.1180, -4.4945],\n",
            "        [ 4.1403, -4.4638]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1726, -4.4807],\n",
            "        [ 4.0874, -4.5218],\n",
            "        [-3.7855,  3.8832],\n",
            "        [ 4.0354, -4.4152],\n",
            "        [ 4.0979, -4.5187],\n",
            "        [ 4.1535, -4.4512],\n",
            "        [ 4.1564, -4.4997],\n",
            "        [ 4.0642, -4.5284],\n",
            "        [ 4.1447, -4.4960],\n",
            "        [-3.6262,  3.9122],\n",
            "        [-3.7132,  3.7251],\n",
            "        [ 3.9832, -4.3852],\n",
            "        [ 4.0762, -4.4716],\n",
            "        [-3.7461,  3.9542],\n",
            "        [ 4.1366, -4.5147],\n",
            "        [ 4.1648, -4.4374]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.7732,  3.8915],\n",
            "        [ 3.9894, -4.4634],\n",
            "        [ 4.1084, -4.4832],\n",
            "        [ 4.0330, -4.4961],\n",
            "        [ 4.0213, -4.3975],\n",
            "        [-3.8019,  3.9215],\n",
            "        [-3.7686,  3.9258],\n",
            "        [ 3.9733, -4.4867],\n",
            "        [-3.7478,  3.9228],\n",
            "        [ 4.0482, -4.5046],\n",
            "        [ 3.8848, -4.3802],\n",
            "        [ 4.0717, -4.4489],\n",
            "        [ 4.1084, -4.4832],\n",
            "        [ 4.1951, -4.5039],\n",
            "        [ 4.1027, -4.5241],\n",
            "        [ 4.1159, -4.5269]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0463, -4.4880],\n",
            "        [ 4.1199, -4.4977],\n",
            "        [ 4.1383, -4.5121],\n",
            "        [ 4.0781, -4.4977],\n",
            "        [ 4.0555, -4.5129],\n",
            "        [ 3.3941, -3.9096],\n",
            "        [ 4.0402, -4.4822],\n",
            "        [ 4.0620, -4.4968],\n",
            "        [-3.7523,  3.9346],\n",
            "        [ 4.0711, -4.4554],\n",
            "        [ 3.8023, -4.3509],\n",
            "        [ 4.0825, -4.5115],\n",
            "        [ 4.0722, -4.4803],\n",
            "        [ 4.0594, -4.4660],\n",
            "        [ 4.1934, -4.5170],\n",
            "        [-3.7226,  3.9329]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9092, -4.4143],\n",
            "        [ 4.1676, -4.4927],\n",
            "        [ 4.0189, -4.4826],\n",
            "        [ 4.0363, -4.4148],\n",
            "        [ 4.1554, -4.5033],\n",
            "        [ 4.2100, -4.4705],\n",
            "        [-3.7905,  3.8928],\n",
            "        [ 4.1111, -4.4453],\n",
            "        [ 4.1456, -4.5094],\n",
            "        [ 4.1257, -4.5072],\n",
            "        [ 3.9626, -4.4405],\n",
            "        [ 4.1141, -4.5158],\n",
            "        [ 4.0798, -4.4944],\n",
            "        [ 4.0689, -4.4697],\n",
            "        [ 4.0640, -4.4766],\n",
            "        [ 4.1676, -4.5004]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1461, -4.4787],\n",
            "        [ 4.1166, -4.5041],\n",
            "        [ 4.0061, -4.4577],\n",
            "        [ 4.0266, -4.4591],\n",
            "        [ 4.1378, -4.5199],\n",
            "        [ 4.1471, -4.5399],\n",
            "        [-3.7756,  3.8868],\n",
            "        [ 3.9939, -4.4523],\n",
            "        [-3.7330,  3.8901],\n",
            "        [ 3.9182, -4.4184],\n",
            "        [ 4.0872, -4.4363],\n",
            "        [ 4.0524, -4.4645],\n",
            "        [ 4.0230, -4.4504],\n",
            "        [ 4.1877, -4.5163],\n",
            "        [ 4.1008, -4.4958],\n",
            "        [ 4.1043, -4.5016]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9500, -4.4507],\n",
            "        [ 4.0456, -4.5141],\n",
            "        [ 4.1156, -4.5213],\n",
            "        [ 4.1736, -4.4269],\n",
            "        [ 4.1691, -4.4923],\n",
            "        [-3.7579,  3.9300],\n",
            "        [ 4.1095, -4.3957],\n",
            "        [ 4.0674, -4.4185],\n",
            "        [ 4.1956, -4.5108],\n",
            "        [ 4.1016, -4.4474],\n",
            "        [-3.7327,  3.9571],\n",
            "        [ 4.1351, -4.5075],\n",
            "        [ 4.1482, -4.5076],\n",
            "        [ 4.0535, -4.4510],\n",
            "        [ 4.0842, -4.5059],\n",
            "        [ 4.0954, -4.3390]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0394, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9713, -4.4569],\n",
            "        [ 4.0557, -4.5011],\n",
            "        [ 4.1793, -4.5025],\n",
            "        [ 4.1414, -4.5287],\n",
            "        [ 3.9710, -4.4394],\n",
            "        [-0.6231,  0.5574],\n",
            "        [ 4.0976, -4.3408],\n",
            "        [ 3.9472, -4.4118],\n",
            "        [ 3.9320, -4.4234],\n",
            "        [ 4.1230, -4.4812],\n",
            "        [-0.3336,  0.5014],\n",
            "        [ 4.1155, -4.4878],\n",
            "        [ 4.1273, -4.5262],\n",
            "        [ 3.9489, -4.4693],\n",
            "        [ 4.0424, -4.4810],\n",
            "        [ 4.1834, -4.5086]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1727, -4.5536],\n",
            "        [ 4.1213, -4.4854],\n",
            "        [-3.7103,  3.9076],\n",
            "        [-3.6713,  3.9565],\n",
            "        [ 4.1781, -4.5355],\n",
            "        [ 4.1177, -4.5036],\n",
            "        [ 4.0330, -4.3458],\n",
            "        [ 4.0924, -4.5306],\n",
            "        [ 4.2168, -4.4762],\n",
            "        [ 4.1914, -4.5265],\n",
            "        [ 4.0277, -4.5047],\n",
            "        [ 3.9692, -4.4449],\n",
            "        [ 3.6917, -4.3144],\n",
            "        [ 4.1026, -4.5131],\n",
            "        [-3.7596,  3.9582],\n",
            "        [ 4.1874, -4.5086]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0104, -4.4762],\n",
            "        [ 4.0785, -4.5452],\n",
            "        [ 4.0683, -4.5370],\n",
            "        [ 4.0838, -4.4670],\n",
            "        [ 4.1115, -4.5447],\n",
            "        [-3.8154,  3.9276],\n",
            "        [ 4.1239, -4.4737],\n",
            "        [ 3.6999, -4.2035],\n",
            "        [ 3.9550, -4.4317],\n",
            "        [ 4.1964, -4.5121],\n",
            "        [ 4.0730, -4.5174],\n",
            "        [ 4.1855, -4.5407],\n",
            "        [ 4.2206, -4.5284],\n",
            "        [ 4.1287, -4.5455],\n",
            "        [ 4.1952, -4.4976],\n",
            "        [ 4.0581, -4.5116]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1861, -4.4855],\n",
            "        [ 4.1541, -4.5020],\n",
            "        [ 4.1626, -4.5265],\n",
            "        [ 4.1208, -4.5119],\n",
            "        [ 4.1436, -4.5582],\n",
            "        [ 4.1888, -4.5638],\n",
            "        [ 4.1376, -4.5431],\n",
            "        [ 4.1871, -4.5083],\n",
            "        [-3.7998,  3.9687],\n",
            "        [ 4.1850, -4.4963],\n",
            "        [ 4.2023, -4.4836],\n",
            "        [ 4.0244, -4.4694],\n",
            "        [-3.8259,  3.8970],\n",
            "        [ 4.1491, -4.4454],\n",
            "        [ 4.1896, -4.5364],\n",
            "        [ 4.1414, -4.5038]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.8327,  3.9654],\n",
            "        [ 4.0856, -4.4954],\n",
            "        [ 4.1069, -4.5020],\n",
            "        [ 4.0121, -4.4918],\n",
            "        [ 4.0779, -4.5376],\n",
            "        [ 4.0668, -4.4429],\n",
            "        [ 4.1757, -4.4977],\n",
            "        [ 3.8091, -4.3604],\n",
            "        [ 4.0744, -4.4190],\n",
            "        [ 4.1722, -4.5022],\n",
            "        [ 4.2025, -4.5307],\n",
            "        [ 4.1081, -4.5066],\n",
            "        [ 4.0623, -4.5060],\n",
            "        [ 4.1126, -4.4736],\n",
            "        [ 4.1810, -4.5300],\n",
            "        [ 4.1114, -4.5104]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2125, -4.4934],\n",
            "        [ 3.9887, -4.3990],\n",
            "        [ 3.9602, -4.2843],\n",
            "        [ 4.0053, -4.3698],\n",
            "        [ 4.0110, -4.4660],\n",
            "        [ 4.0987, -4.4842],\n",
            "        [ 4.0955, -4.5139],\n",
            "        [ 4.1459, -4.4808],\n",
            "        [ 4.0636, -4.4818],\n",
            "        [ 4.1867, -4.5240],\n",
            "        [ 4.0002, -4.4682],\n",
            "        [ 3.9585, -4.4408],\n",
            "        [ 4.0772, -4.4752],\n",
            "        [ 4.0072, -4.4350],\n",
            "        [ 4.1833, -4.4722],\n",
            "        [ 4.0515, -4.3167]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0996, -4.5251],\n",
            "        [ 4.2187, -4.4883],\n",
            "        [ 4.2125, -4.5334],\n",
            "        [ 4.2165, -4.4824],\n",
            "        [ 4.1822, -4.4550],\n",
            "        [-3.7982,  3.9768],\n",
            "        [ 4.1954, -4.4781],\n",
            "        [ 4.0868, -4.2984],\n",
            "        [ 4.2196, -4.5284],\n",
            "        [-3.7530,  3.9982],\n",
            "        [-3.8177,  3.9530],\n",
            "        [ 4.0976, -4.4952],\n",
            "        [ 4.2089, -4.5246],\n",
            "        [ 4.1867, -4.4980],\n",
            "        [ 3.7890, -4.2183],\n",
            "        [ 4.0991, -4.5042]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1105, -4.5389],\n",
            "        [-3.8441,  3.9527],\n",
            "        [ 4.2050, -4.5018],\n",
            "        [ 4.2266, -4.5236],\n",
            "        [ 4.1862, -4.4850],\n",
            "        [ 4.0737, -4.4737],\n",
            "        [-3.7560,  3.9773],\n",
            "        [-3.7231,  3.9954],\n",
            "        [ 4.0896, -4.4705],\n",
            "        [-3.8258,  3.9835],\n",
            "        [ 4.1855, -4.5416],\n",
            "        [ 4.1648, -4.3823],\n",
            "        [ 4.1398, -4.5186],\n",
            "        [ 4.0709, -4.3662],\n",
            "        [ 4.2170, -4.4963],\n",
            "        [ 4.1830, -4.5297]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1464, -4.5931],\n",
            "        [ 3.9240, -4.4446],\n",
            "        [ 4.0576, -4.4579],\n",
            "        [ 4.1822, -4.5024],\n",
            "        [ 4.0315, -4.4759],\n",
            "        [ 4.1259, -4.4750],\n",
            "        [ 4.2211, -4.5480],\n",
            "        [ 4.1716, -4.5647],\n",
            "        [ 4.0755, -4.5183],\n",
            "        [ 4.2196, -4.5351],\n",
            "        [ 3.9696, -4.4487],\n",
            "        [-3.8353,  3.9883],\n",
            "        [-3.7852,  4.0083],\n",
            "        [ 4.1409, -4.5270],\n",
            "        [ 4.1328, -4.5238],\n",
            "        [ 4.0835, -4.2887]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2036, -4.5033],\n",
            "        [ 4.2046, -4.5188],\n",
            "        [ 4.2369, -4.4607],\n",
            "        [ 4.1760, -4.5474],\n",
            "        [ 4.0593, -4.4846],\n",
            "        [ 3.7235, -4.1957],\n",
            "        [ 4.1951, -4.5012],\n",
            "        [ 4.1678, -4.4927],\n",
            "        [-3.8550,  3.9805],\n",
            "        [ 4.1339, -4.5035],\n",
            "        [ 4.0821, -4.2846],\n",
            "        [ 4.1966, -4.5582],\n",
            "        [ 4.1030, -4.5617],\n",
            "        [ 4.1616, -4.5254],\n",
            "        [ 4.0159, -4.5162],\n",
            "        [-3.7951,  3.9988]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1848, -4.5635],\n",
            "        [ 4.2012, -4.5358],\n",
            "        [ 4.1155, -4.5260],\n",
            "        [-3.8531,  4.0002],\n",
            "        [ 4.1571, -4.4782],\n",
            "        [-3.8111,  4.0095],\n",
            "        [ 4.1947, -4.5232],\n",
            "        [ 3.9581, -4.4190],\n",
            "        [ 4.2291, -4.5324],\n",
            "        [ 4.2172, -4.4674],\n",
            "        [ 4.0758, -4.5229],\n",
            "        [ 4.2190, -4.5268],\n",
            "        [ 4.2357, -4.5140],\n",
            "        [ 3.6465, -4.1752],\n",
            "        [ 3.9837, -4.3790],\n",
            "        [ 4.1983, -4.4977]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2105, -4.5319],\n",
            "        [-3.8590,  3.9835],\n",
            "        [ 3.9788, -4.4630],\n",
            "        [ 4.2226, -4.5211],\n",
            "        [ 4.0789, -4.4691],\n",
            "        [ 4.1449, -4.4073],\n",
            "        [ 4.1439, -4.5226],\n",
            "        [ 4.2061, -4.5910],\n",
            "        [ 4.1390, -4.4718],\n",
            "        [ 4.2091, -4.5369],\n",
            "        [-3.6210,  3.8950],\n",
            "        [ 4.2409, -4.5187],\n",
            "        [ 4.1270, -4.3989],\n",
            "        [ 4.2107, -4.5053],\n",
            "        [ 4.0960, -4.4925],\n",
            "        [ 4.1462, -4.5251]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1944, -4.5234],\n",
            "        [-3.8719,  4.0073],\n",
            "        [ 4.1699, -4.5303],\n",
            "        [-3.8559,  3.9846],\n",
            "        [ 4.1246, -4.5351],\n",
            "        [-3.7670,  3.9891],\n",
            "        [-3.8424,  3.9655],\n",
            "        [ 4.2257, -4.5112],\n",
            "        [-3.8674,  3.9933],\n",
            "        [-3.8049,  4.0194],\n",
            "        [ 4.1656, -4.4756],\n",
            "        [-3.8552,  3.9973],\n",
            "        [ 4.2262, -4.5663],\n",
            "        [ 4.0465, -4.4603],\n",
            "        [ 4.2044, -4.5508],\n",
            "        [ 4.2329, -4.5425]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.7677,  4.0117],\n",
            "        [ 4.1696, -4.4689],\n",
            "        [ 4.1972, -4.5659],\n",
            "        [ 4.0295, -4.4247],\n",
            "        [ 4.1492, -4.4125],\n",
            "        [ 4.2384, -4.5270],\n",
            "        [ 4.0470, -4.3391],\n",
            "        [ 4.0397, -4.4834],\n",
            "        [ 4.2258, -4.5119],\n",
            "        [ 4.1150, -4.5703],\n",
            "        [ 3.9947, -4.2641],\n",
            "        [-3.7739,  4.0102],\n",
            "        [ 4.2055, -4.5004],\n",
            "        [ 4.1511, -4.5169],\n",
            "        [ 4.1678, -4.5328],\n",
            "        [ 4.1983, -4.4522]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2065, -4.5114],\n",
            "        [ 4.1798, -4.5143],\n",
            "        [ 4.1463, -4.5277],\n",
            "        [ 3.9463, -4.3733],\n",
            "        [ 4.0328, -4.2979],\n",
            "        [ 4.2052, -4.4983],\n",
            "        [ 4.1521, -4.3603],\n",
            "        [ 4.2514, -4.5109],\n",
            "        [ 4.1044, -4.4775],\n",
            "        [ 4.0134, -4.3883],\n",
            "        [ 4.1766, -4.5081],\n",
            "        [ 4.1381, -4.5324],\n",
            "        [ 4.1036, -4.3922],\n",
            "        [ 4.2322, -4.5402],\n",
            "        [-3.8639,  3.9909],\n",
            "        [ 4.2339, -4.5191]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1086, -4.4580],\n",
            "        [ 4.1508, -4.4811],\n",
            "        [ 4.0677, -4.4670],\n",
            "        [-3.7736,  3.9839],\n",
            "        [-3.7624,  3.9852],\n",
            "        [ 3.6706, -4.0953],\n",
            "        [ 4.1540, -4.5442],\n",
            "        [-3.6514,  3.9382],\n",
            "        [ 3.8979, -4.3943],\n",
            "        [ 4.1767, -4.4403],\n",
            "        [ 4.0927, -4.5272],\n",
            "        [ 4.1987, -4.5349],\n",
            "        [-3.8535,  4.0007],\n",
            "        [ 4.1505, -4.5963],\n",
            "        [ 4.1874, -4.5689],\n",
            "        [ 4.2347, -4.4674]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1992, -4.4666],\n",
            "        [ 4.1645, -4.5709],\n",
            "        [ 4.0813, -4.4563],\n",
            "        [ 4.1155, -4.5075],\n",
            "        [-3.8186,  4.0301],\n",
            "        [ 4.2518, -4.5156],\n",
            "        [ 4.0229, -4.5047],\n",
            "        [ 4.0442, -4.5054],\n",
            "        [ 4.1452, -4.4483],\n",
            "        [ 4.2292, -4.5444],\n",
            "        [ 4.1614, -4.5520],\n",
            "        [ 4.2522, -4.5251],\n",
            "        [ 4.0588, -4.3992],\n",
            "        [ 4.2265, -4.5122],\n",
            "        [ 4.1234, -4.5063],\n",
            "        [ 4.2144, -4.5137]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2035, -4.5035],\n",
            "        [ 4.1063, -4.4827],\n",
            "        [ 4.2447, -4.5494],\n",
            "        [ 4.0587, -4.2489],\n",
            "        [ 4.2100, -4.5542],\n",
            "        [ 4.2128, -4.5411],\n",
            "        [ 4.2482, -4.5261],\n",
            "        [ 4.2510, -4.5574],\n",
            "        [-3.6803,  3.9861],\n",
            "        [ 4.2250, -4.5225],\n",
            "        [ 4.0713, -4.4794],\n",
            "        [ 4.1686, -4.5056],\n",
            "        [ 4.0997, -4.4617],\n",
            "        [ 4.2245, -4.4850],\n",
            "        [ 3.8226, -4.2602],\n",
            "        [ 4.0191, -4.3236]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2525, -4.5456],\n",
            "        [ 4.0787, -4.2691],\n",
            "        [ 4.2388, -4.5369],\n",
            "        [ 3.7516, -4.2774],\n",
            "        [ 4.1735, -4.4718],\n",
            "        [ 4.2119, -4.5578],\n",
            "        [ 4.1336, -4.5371],\n",
            "        [ 4.1542, -4.5293],\n",
            "        [ 4.1735, -4.5162],\n",
            "        [ 4.1295, -4.6083],\n",
            "        [ 4.1392, -4.5496],\n",
            "        [-3.7957,  4.0126],\n",
            "        [ 4.0317, -4.5338],\n",
            "        [ 4.1496, -4.5072],\n",
            "        [ 4.1925, -4.5443],\n",
            "        [ 3.9591, -4.4105]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9560, -4.4389],\n",
            "        [ 4.1825, -4.5009],\n",
            "        [-3.8978,  3.9906],\n",
            "        [ 4.2450, -4.5167],\n",
            "        [ 4.2111, -4.5524],\n",
            "        [-3.8642,  4.0208],\n",
            "        [ 3.8583, -4.3700],\n",
            "        [ 4.0898, -4.2860],\n",
            "        [ 4.2388, -4.5095],\n",
            "        [ 4.2132, -4.4906],\n",
            "        [ 4.2566, -4.5152],\n",
            "        [ 4.2238, -4.5334],\n",
            "        [ 4.1674, -4.5277],\n",
            "        [ 4.2276, -4.5646],\n",
            "        [ 4.2495, -4.5423],\n",
            "        [-3.8845,  3.9847]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.8027,  4.0315],\n",
            "        [ 4.1525, -4.4533],\n",
            "        [ 4.0926, -4.4837],\n",
            "        [ 4.2092, -4.4744],\n",
            "        [ 4.2595, -4.5568],\n",
            "        [ 4.2372, -4.5403],\n",
            "        [ 4.2345, -4.4991],\n",
            "        [ 4.2422, -4.5387],\n",
            "        [ 4.2293, -4.5621],\n",
            "        [ 4.2411, -4.4569],\n",
            "        [-3.8851,  3.9935],\n",
            "        [ 4.0553, -4.4959],\n",
            "        [ 4.2309, -4.5271],\n",
            "        [-3.8494,  4.0315],\n",
            "        [-3.8715,  4.0307],\n",
            "        [ 4.1654, -4.5625]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1029, -4.4831],\n",
            "        [ 4.2146, -4.5416],\n",
            "        [ 4.2007, -4.5862],\n",
            "        [ 4.1774, -4.4846],\n",
            "        [ 4.0549, -4.4067],\n",
            "        [ 4.0866, -4.4429],\n",
            "        [ 4.1140, -4.5981],\n",
            "        [ 4.2401, -4.5156],\n",
            "        [-3.8969,  4.0097],\n",
            "        [ 4.1320, -4.5076],\n",
            "        [ 4.1536, -4.4912],\n",
            "        [ 4.0493, -4.4908],\n",
            "        [ 4.2336, -4.5617],\n",
            "        [ 4.2435, -4.4849],\n",
            "        [ 4.0600, -4.5113],\n",
            "        [ 4.1268, -4.5394]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1959, -4.5180],\n",
            "        [ 4.2487, -4.5433],\n",
            "        [ 4.0389, -4.4621],\n",
            "        [ 3.9753, -4.4152],\n",
            "        [ 4.1297, -4.4946],\n",
            "        [-3.8655,  4.0374],\n",
            "        [ 4.2335, -4.5891],\n",
            "        [ 4.1174, -4.5181],\n",
            "        [ 4.2667, -4.5409],\n",
            "        [ 4.2084, -4.5199],\n",
            "        [ 4.2126, -4.4528],\n",
            "        [-3.7872,  4.0369],\n",
            "        [ 4.2503, -4.5162],\n",
            "        [ 4.0835, -4.3800],\n",
            "        [ 3.8575, -4.3849],\n",
            "        [ 4.1389, -4.5545]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.5402,  3.8005],\n",
            "        [ 4.1595, -4.4140],\n",
            "        [ 4.0339, -4.5039],\n",
            "        [ 4.0227, -4.5544],\n",
            "        [ 4.0165, -4.4675],\n",
            "        [ 4.2082, -4.5774],\n",
            "        [ 4.2456, -4.4620],\n",
            "        [ 3.9721, -4.3439],\n",
            "        [ 4.2597, -4.5276],\n",
            "        [ 4.2095, -4.5096],\n",
            "        [ 4.2293, -4.5677],\n",
            "        [ 4.1718, -4.5328],\n",
            "        [ 4.1270, -4.5086],\n",
            "        [ 4.1924, -4.4739],\n",
            "        [-3.8997,  4.0080],\n",
            "        [ 4.2333, -4.5373]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.3278, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1426, -4.5496],\n",
            "        [ 4.1857, -4.5396],\n",
            "        [ 4.2260, -4.5443],\n",
            "        [ 4.2272, -4.5249],\n",
            "        [ 4.1492, -4.5353],\n",
            "        [ 4.1024, -4.5328],\n",
            "        [ 4.1707, -4.5466],\n",
            "        [ 4.2058, -4.5680],\n",
            "        [ 4.1305, -4.4536],\n",
            "        [ 4.0200, -4.4344],\n",
            "        [ 4.2529, -4.4977],\n",
            "        [ 4.1953, -4.4884],\n",
            "        [ 4.1113, -4.5440],\n",
            "        [ 4.1910, -4.5479],\n",
            "        [-2.5590,  2.6786],\n",
            "        [ 4.1833, -4.5127]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1674, -4.5253],\n",
            "        [ 4.2113, -4.5647],\n",
            "        [ 4.1244, -4.3740],\n",
            "        [ 3.9530, -4.4003],\n",
            "        [ 4.2065, -4.5385],\n",
            "        [-3.8005,  3.8193],\n",
            "        [-3.7988,  3.8500],\n",
            "        [ 4.1104, -4.5124],\n",
            "        [-3.7929,  3.8163],\n",
            "        [ 4.0982, -4.5561],\n",
            "        [ 3.9131, -4.2313],\n",
            "        [ 4.2000, -4.5740],\n",
            "        [ 4.2544, -4.4644],\n",
            "        [-3.7657,  3.7481],\n",
            "        [-3.8149,  3.8521],\n",
            "        [ 4.0537, -4.5140]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2246, -4.5196],\n",
            "        [ 4.1774, -4.5676],\n",
            "        [ 4.1559, -4.5441],\n",
            "        [ 4.1232, -4.4102],\n",
            "        [-3.1172,  3.0939],\n",
            "        [ 4.1192, -4.5444],\n",
            "        [ 4.1908, -4.5042],\n",
            "        [ 4.2206, -4.5378],\n",
            "        [ 4.2229, -4.5124],\n",
            "        [ 4.1430, -4.3313],\n",
            "        [ 4.1070, -4.3306],\n",
            "        [ 4.2366, -4.5224],\n",
            "        [ 4.1946, -4.5809],\n",
            "        [ 4.1245, -4.5253],\n",
            "        [ 4.1422, -4.5085],\n",
            "        [ 4.1703, -4.4940]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0258, -4.4917],\n",
            "        [ 4.2227, -4.4911],\n",
            "        [ 4.1585, -4.5315],\n",
            "        [ 3.9709, -4.4402],\n",
            "        [ 4.1927, -4.5111],\n",
            "        [ 4.1945, -4.4823],\n",
            "        [ 4.1538, -4.5197],\n",
            "        [ 4.2227, -4.5210],\n",
            "        [ 4.1474, -4.5007],\n",
            "        [ 4.2086, -4.5702],\n",
            "        [ 4.1209, -4.5649],\n",
            "        [ 4.1970, -4.5362],\n",
            "        [ 4.1587, -4.4876],\n",
            "        [ 4.1445, -4.4488],\n",
            "        [ 3.9962, -4.4192],\n",
            "        [ 3.9699, -4.2694]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8531, -4.3903],\n",
            "        [-1.7496,  1.8727],\n",
            "        [ 4.2027, -4.5138],\n",
            "        [-2.2219,  2.3409],\n",
            "        [ 3.9143, -4.2979],\n",
            "        [-2.0249,  2.1827],\n",
            "        [ 3.6860, -4.1617],\n",
            "        [ 4.2142, -4.5327],\n",
            "        [ 4.0285, -4.4537],\n",
            "        [ 3.9925, -4.4078],\n",
            "        [ 4.1502, -4.5359],\n",
            "        [ 4.1835, -4.5789],\n",
            "        [ 4.1076, -4.4679],\n",
            "        [ 4.1970, -4.5127],\n",
            "        [ 4.0740, -4.4815],\n",
            "        [ 3.9248, -4.4155]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0346, -4.3356],\n",
            "        [-1.8740,  1.9703],\n",
            "        [ 4.0685, -4.5546],\n",
            "        [ 4.1514, -4.5177],\n",
            "        [ 3.9988, -4.5141],\n",
            "        [ 3.8977, -4.3908],\n",
            "        [ 4.1239, -4.5436],\n",
            "        [ 4.1940, -4.5561],\n",
            "        [ 4.1005, -4.5023],\n",
            "        [ 4.1819, -4.5570],\n",
            "        [ 4.1110, -4.5408],\n",
            "        [ 4.1145, -4.4655],\n",
            "        [ 4.2036, -4.5067],\n",
            "        [-1.8348,  1.9368],\n",
            "        [ 4.1014, -4.5711],\n",
            "        [ 4.1673, -4.5379]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1690, -4.4870],\n",
            "        [ 4.0072, -4.4521],\n",
            "        [ 4.0053, -4.4575],\n",
            "        [ 4.0589, -4.4686],\n",
            "        [ 4.1700, -4.4921],\n",
            "        [ 4.0378, -4.4096],\n",
            "        [ 4.1697, -4.4713],\n",
            "        [ 4.2030, -4.5195],\n",
            "        [ 4.0876, -4.4762],\n",
            "        [ 4.0032, -4.2881],\n",
            "        [ 4.1421, -4.5337],\n",
            "        [ 4.1463, -4.5356],\n",
            "        [ 4.2029, -4.5329],\n",
            "        [-1.6593,  1.8171],\n",
            "        [ 4.1692, -4.4526],\n",
            "        [ 3.9133, -4.3033]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1516, -4.4357],\n",
            "        [ 4.1952, -4.4566],\n",
            "        [-1.5685,  1.6316],\n",
            "        [ 4.1658, -4.5146],\n",
            "        [-1.4637,  1.6282],\n",
            "        [ 4.0654, -4.3067],\n",
            "        [ 4.1960, -4.5192],\n",
            "        [-1.6104,  1.6721],\n",
            "        [ 3.9481, -4.3828],\n",
            "        [ 4.1467, -4.5294],\n",
            "        [ 4.1143, -4.5209],\n",
            "        [ 4.2038, -4.5097],\n",
            "        [ 4.1065, -4.4014],\n",
            "        [ 4.1905, -4.4930],\n",
            "        [ 4.0658, -4.5052],\n",
            "        [ 4.1406, -4.5043]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1205, -4.4421],\n",
            "        [ 4.0796, -4.4864],\n",
            "        [ 4.1983, -4.4491],\n",
            "        [ 4.0691, -4.4949],\n",
            "        [ 4.1133, -4.5034],\n",
            "        [ 4.1895, -4.5013],\n",
            "        [ 4.1488, -4.5501],\n",
            "        [ 4.1642, -4.4697],\n",
            "        [ 4.0429, -4.5004],\n",
            "        [ 4.1121, -4.5099],\n",
            "        [-1.1997,  1.3350],\n",
            "        [ 4.0264, -4.4618],\n",
            "        [ 4.0802, -4.4135],\n",
            "        [ 4.1542, -4.4986],\n",
            "        [ 4.0698, -4.4922],\n",
            "        [ 4.1802, -4.4490]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1610, -4.5077],\n",
            "        [ 4.2037, -4.4598],\n",
            "        [ 4.0897, -4.4904],\n",
            "        [-1.4958,  1.5047],\n",
            "        [ 3.9161, -4.4089],\n",
            "        [ 4.0671, -4.5402],\n",
            "        [ 3.9958, -4.4500],\n",
            "        [ 4.1620, -4.5058],\n",
            "        [ 4.1310, -4.5056],\n",
            "        [-1.5234,  1.6741],\n",
            "        [ 3.9352, -4.4091],\n",
            "        [ 3.9749, -4.4850],\n",
            "        [ 4.1515, -4.5003],\n",
            "        [ 4.0156, -4.4701],\n",
            "        [ 4.1492, -4.4988],\n",
            "        [ 3.9769, -4.4161]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0183, -4.3638],\n",
            "        [ 1.8520, -2.5629],\n",
            "        [ 4.1237, -4.4771],\n",
            "        [ 4.1667, -4.4554],\n",
            "        [ 4.1834, -4.5158],\n",
            "        [ 4.1874, -4.4849],\n",
            "        [ 4.1446, -4.4387],\n",
            "        [ 4.1377, -4.4981],\n",
            "        [ 4.1538, -4.5130],\n",
            "        [ 3.8783, -4.2787],\n",
            "        [ 4.0932, -4.5567],\n",
            "        [ 4.0599, -4.4359],\n",
            "        [ 4.1093, -4.5029],\n",
            "        [ 4.1651, -4.5012],\n",
            "        [ 4.0183, -4.3172],\n",
            "        [ 4.0853, -4.4728]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1531, -4.5634],\n",
            "        [ 4.1543, -4.5290],\n",
            "        [ 4.1519, -4.5292],\n",
            "        [ 4.1891, -4.4791],\n",
            "        [-1.4949,  1.6630],\n",
            "        [ 4.2049, -4.4807],\n",
            "        [ 4.0929, -4.5503],\n",
            "        [ 4.0948, -4.5278],\n",
            "        [-1.2104,  1.2310],\n",
            "        [ 4.1723, -4.4722],\n",
            "        [ 4.1644, -4.5184],\n",
            "        [-1.2602,  1.3135],\n",
            "        [ 4.1521, -4.4757],\n",
            "        [ 3.9907, -4.4363],\n",
            "        [ 4.0445, -4.3194],\n",
            "        [ 4.1928, -4.4792]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.4931, -3.9163],\n",
            "        [ 4.1172, -4.5107],\n",
            "        [ 4.1949, -4.3959],\n",
            "        [ 4.1501, -4.5374],\n",
            "        [ 4.1931, -4.4780],\n",
            "        [ 4.1042, -4.5651],\n",
            "        [ 4.1355, -4.5485],\n",
            "        [ 4.0630, -4.4411],\n",
            "        [ 4.1018, -4.5096],\n",
            "        [ 4.1722, -4.4907],\n",
            "        [ 4.1219, -4.5056],\n",
            "        [ 4.1916, -4.5165],\n",
            "        [-1.3551,  1.4618],\n",
            "        [ 4.0735, -4.5083],\n",
            "        [ 3.9282, -4.4487],\n",
            "        [-1.5987,  1.8575]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.5743,  1.7463],\n",
            "        [ 4.1069, -4.5223],\n",
            "        [ 4.1648, -4.4852],\n",
            "        [ 4.1888, -4.4565],\n",
            "        [ 4.0441, -4.3890],\n",
            "        [ 4.0512, -4.4689],\n",
            "        [ 4.2049, -4.4399],\n",
            "        [ 4.0607, -4.5007],\n",
            "        [-1.4751,  1.6871],\n",
            "        [ 4.0070, -4.4480],\n",
            "        [ 4.0526, -4.2528],\n",
            "        [ 4.0585, -4.5250],\n",
            "        [ 4.1773, -4.5262],\n",
            "        [ 4.1089, -4.4980],\n",
            "        [ 4.1545, -4.4237],\n",
            "        [ 4.0600, -4.3975]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0433, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-0.0742, -0.0683],\n",
            "        [ 4.1739, -4.4455],\n",
            "        [ 4.1891, -4.4823],\n",
            "        [ 3.9428, -4.1872],\n",
            "        [ 4.1813, -4.5143],\n",
            "        [ 4.1867, -4.5043],\n",
            "        [ 4.1754, -4.4609],\n",
            "        [ 4.2045, -4.5149],\n",
            "        [ 3.9863, -4.4188],\n",
            "        [ 4.1463, -4.5226],\n",
            "        [ 4.1017, -4.5239],\n",
            "        [ 3.6649, -4.1716],\n",
            "        [ 4.0611, -4.4833],\n",
            "        [ 4.1140, -4.4798],\n",
            "        [ 4.0877, -4.4192],\n",
            "        [ 4.1909, -4.5287]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9839, -4.4582],\n",
            "        [ 4.1935, -4.4810],\n",
            "        [ 4.0499, -4.4903],\n",
            "        [ 4.0181, -4.4891],\n",
            "        [ 4.0862, -4.4997],\n",
            "        [ 3.9548, -4.4074],\n",
            "        [-1.7362,  2.0085],\n",
            "        [ 4.0084, -4.5293],\n",
            "        [ 4.2026, -4.5310],\n",
            "        [-1.7540,  1.9487],\n",
            "        [ 4.2085, -4.5332],\n",
            "        [ 4.0716, -4.5389],\n",
            "        [ 4.0861, -4.5171],\n",
            "        [-1.4436,  1.7750],\n",
            "        [ 4.1525, -4.5186],\n",
            "        [ 4.1506, -4.5110]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0684, -4.5350],\n",
            "        [ 3.8625, -4.4049],\n",
            "        [ 3.9716, -4.4740],\n",
            "        [ 4.0275, -4.3737],\n",
            "        [ 4.1714, -4.5274],\n",
            "        [ 4.2024, -4.5343],\n",
            "        [ 4.1865, -4.4909],\n",
            "        [-1.8140,  2.0552],\n",
            "        [ 4.1643, -4.4895],\n",
            "        [ 4.0802, -4.4903],\n",
            "        [ 3.9401, -4.4402],\n",
            "        [ 4.1159, -4.4813],\n",
            "        [ 4.0980, -4.5120],\n",
            "        [ 4.0798, -4.4985],\n",
            "        [ 3.9522, -4.4288],\n",
            "        [ 4.0906, -4.5443]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0811, -4.4433],\n",
            "        [ 4.1739, -4.5295],\n",
            "        [ 4.0459, -4.2587],\n",
            "        [ 4.1685, -4.5268],\n",
            "        [ 4.0459, -4.5093],\n",
            "        [ 4.1510, -4.4386],\n",
            "        [ 4.0198, -4.4439],\n",
            "        [ 3.8895, -4.4124],\n",
            "        [-1.7183,  1.9627],\n",
            "        [ 4.1055, -4.5225],\n",
            "        [ 3.2371, -3.6158],\n",
            "        [ 4.1339, -4.5619],\n",
            "        [-1.9698,  2.1943],\n",
            "        [ 4.0953, -4.5087],\n",
            "        [ 4.1584, -4.5569],\n",
            "        [ 4.1274, -4.5192]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0051, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-1.9868,  2.2211],\n",
            "        [ 4.1412, -4.5584],\n",
            "        [ 4.1313, -4.5255],\n",
            "        [ 4.1199, -4.5062],\n",
            "        [ 3.7500, -4.2169],\n",
            "        [ 4.1028, -4.4707],\n",
            "        [-1.5961,  1.9176],\n",
            "        [ 4.2173, -4.5102],\n",
            "        [ 3.9641, -4.3681],\n",
            "        [ 3.9365, -4.2824],\n",
            "        [ 4.1029, -4.4769],\n",
            "        [ 4.1349, -4.5596],\n",
            "        [ 4.1103, -4.5278],\n",
            "        [ 4.1735, -4.5644],\n",
            "        [-1.8210,  2.0651],\n",
            "        [-1.9431,  2.2148]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9437, -4.4659],\n",
            "        [ 4.0206, -4.4698],\n",
            "        [ 4.0721, -4.5481],\n",
            "        [-2.1031,  2.3191],\n",
            "        [ 4.1085, -4.5240],\n",
            "        [ 4.1834, -4.5579],\n",
            "        [ 4.0903, -4.4933],\n",
            "        [ 4.1401, -4.5781],\n",
            "        [-1.6612,  1.9157],\n",
            "        [ 3.9543, -4.4784],\n",
            "        [ 4.0209, -4.4616],\n",
            "        [ 4.1172, -4.4264],\n",
            "        [ 3.5717, -3.9925],\n",
            "        [ 4.1765, -4.5873],\n",
            "        [ 4.1893, -4.5487],\n",
            "        [ 3.6219, -4.1196]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1026, -4.5295],\n",
            "        [ 4.1204, -4.4707],\n",
            "        [ 4.0378, -4.4252],\n",
            "        [ 4.0432, -4.4856],\n",
            "        [ 3.4040, -3.8085],\n",
            "        [-2.0952,  2.2840],\n",
            "        [-2.1484,  2.3601],\n",
            "        [ 4.0187, -4.4808],\n",
            "        [ 4.0971, -4.4802],\n",
            "        [ 4.0679, -4.4702],\n",
            "        [ 4.0815, -4.4823],\n",
            "        [ 4.1827, -4.5567],\n",
            "        [ 4.0270, -4.4720],\n",
            "        [ 3.7686, -4.1583],\n",
            "        [ 4.1499, -4.5302],\n",
            "        [ 3.9597, -4.4450]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2220, -4.5387],\n",
            "        [ 4.0453, -4.5238],\n",
            "        [ 3.9077, -4.3908],\n",
            "        [ 3.9689, -4.4557],\n",
            "        [ 3.7262, -4.1933],\n",
            "        [ 4.1882, -4.5160],\n",
            "        [ 3.4950, -3.9271],\n",
            "        [ 4.1288, -4.5245],\n",
            "        [ 4.0758, -4.3285],\n",
            "        [ 4.1685, -4.5245],\n",
            "        [ 4.0092, -4.4492],\n",
            "        [ 4.2120, -4.5641],\n",
            "        [ 3.9904, -4.5219],\n",
            "        [ 3.9740, -4.4205],\n",
            "        [ 4.1638, -4.5598],\n",
            "        [ 3.7978, -4.3176]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1692, -4.5576],\n",
            "        [ 4.2149, -4.5501],\n",
            "        [ 3.3483, -3.8051],\n",
            "        [ 3.6140, -4.2316],\n",
            "        [-2.1707,  2.3719],\n",
            "        [ 3.7073, -4.2674],\n",
            "        [ 4.1595, -4.4966],\n",
            "        [-2.1878,  2.3922],\n",
            "        [ 4.0698, -4.5049],\n",
            "        [ 4.1094, -4.3057],\n",
            "        [ 4.1156, -4.4614],\n",
            "        [-2.0544,  2.3051],\n",
            "        [ 3.7089, -4.2332],\n",
            "        [ 4.0693, -4.5131],\n",
            "        [ 4.2272, -4.5385],\n",
            "        [ 3.5247, -3.9676]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0180, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1390, -4.5641],\n",
            "        [ 4.0591, -4.4720],\n",
            "        [-2.2054,  2.3929],\n",
            "        [-2.1782,  2.3756],\n",
            "        [ 4.0753, -4.4674],\n",
            "        [ 3.7370, -4.1245],\n",
            "        [ 0.2988, -0.9441],\n",
            "        [ 4.1886, -4.5378],\n",
            "        [ 3.8649, -4.1813],\n",
            "        [ 4.1807, -4.5501],\n",
            "        [ 3.9233, -4.4291],\n",
            "        [ 4.0534, -4.4293],\n",
            "        [ 3.8174, -4.3408],\n",
            "        [ 4.1390, -4.5641],\n",
            "        [ 4.0792, -4.5240],\n",
            "        [ 1.9301, -2.5127]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1847, -4.5813],\n",
            "        [ 4.0937, -4.4526],\n",
            "        [ 3.9189, -4.4248],\n",
            "        [ 3.9155, -4.2922],\n",
            "        [ 3.8940, -4.2990],\n",
            "        [ 3.3873, -3.8460],\n",
            "        [-2.2751,  2.4743],\n",
            "        [ 4.0750, -4.5558],\n",
            "        [ 4.1333, -4.5878],\n",
            "        [ 4.2106, -4.4848],\n",
            "        [ 4.0430, -4.5192],\n",
            "        [ 4.2094, -4.5716],\n",
            "        [ 4.0609, -4.3998],\n",
            "        [ 3.8533, -4.2579],\n",
            "        [ 4.1879, -4.4575],\n",
            "        [ 4.1953, -4.5882]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0222, -4.5263],\n",
            "        [ 3.9669, -4.4035],\n",
            "        [ 3.6899, -4.1026],\n",
            "        [ 4.0170, -4.4689],\n",
            "        [ 3.8228, -4.2674],\n",
            "        [ 4.0653, -4.4186],\n",
            "        [ 4.1499, -4.6085],\n",
            "        [ 3.5745, -4.1768],\n",
            "        [ 4.0170, -4.4689],\n",
            "        [ 4.1348, -4.5497],\n",
            "        [ 4.2403, -4.5284],\n",
            "        [ 4.0684, -4.3462],\n",
            "        [ 4.2254, -4.5690],\n",
            "        [ 4.1550, -4.5397],\n",
            "        [ 4.0322, -4.5114],\n",
            "        [ 4.0276, -4.5579]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.2445, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.4176,  2.5368],\n",
            "        [-2.4164,  2.5300],\n",
            "        [ 3.9114, -4.3625],\n",
            "        [ 3.8451, -4.3724],\n",
            "        [ 4.1374, -4.4482],\n",
            "        [ 4.1051, -4.5052],\n",
            "        [ 4.1186, -4.3722],\n",
            "        [ 3.7811, -4.3925],\n",
            "        [ 3.8541, -4.3274],\n",
            "        [ 3.7816, -4.2936],\n",
            "        [-2.4556,  2.5738],\n",
            "        [ 4.0140, -4.3395],\n",
            "        [ 4.1510, -4.5035],\n",
            "        [ 4.1935, -4.5778],\n",
            "        [-2.2683,  2.4714],\n",
            "        [-1.8040,  2.0546]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.3159,  2.5183],\n",
            "        [ 3.7367, -4.2100],\n",
            "        [ 4.1732, -4.5185],\n",
            "        [-2.3129,  2.4780],\n",
            "        [ 4.0363, -4.5040],\n",
            "        [ 3.9402, -4.3866],\n",
            "        [ 4.1112, -4.4737],\n",
            "        [ 4.2174, -4.5238],\n",
            "        [ 4.0214, -4.4743],\n",
            "        [ 4.1264, -4.4988],\n",
            "        [ 3.7612, -4.2098],\n",
            "        [ 4.2448, -4.5594],\n",
            "        [ 3.7310, -4.2852],\n",
            "        [ 4.0031, -4.3667],\n",
            "        [ 4.0939, -4.3379],\n",
            "        [ 3.3878, -3.7190]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8851, -4.3933],\n",
            "        [ 4.0421, -4.4077],\n",
            "        [ 4.0507, -4.4378],\n",
            "        [ 3.9495, -4.4199],\n",
            "        [-2.2897,  2.4971],\n",
            "        [ 3.8934, -4.2792],\n",
            "        [ 3.9435, -4.4075],\n",
            "        [ 4.0597, -4.4430],\n",
            "        [ 4.1033, -4.5056],\n",
            "        [ 4.1710, -4.6034],\n",
            "        [ 4.1620, -4.5980],\n",
            "        [ 4.1246, -4.4624],\n",
            "        [-2.2870,  2.4875],\n",
            "        [ 4.1022, -4.5630],\n",
            "        [ 0.9331, -1.6878],\n",
            "        [ 4.2191, -4.5676]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1209, -4.5762],\n",
            "        [ 4.0975, -4.4835],\n",
            "        [ 4.1550, -4.5085],\n",
            "        [-2.3804,  2.4798],\n",
            "        [ 4.0610, -4.5412],\n",
            "        [ 4.1289, -4.5829],\n",
            "        [ 3.9476, -4.4903],\n",
            "        [ 3.9974, -4.4470],\n",
            "        [-2.2829,  2.4029],\n",
            "        [ 4.2079, -4.5624],\n",
            "        [ 4.0440, -4.4358],\n",
            "        [ 4.2135, -4.5736],\n",
            "        [ 4.1601, -4.5164],\n",
            "        [ 4.1450, -4.5867],\n",
            "        [ 4.0311, -4.5202],\n",
            "        [ 4.1847, -4.5540]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1747, -4.5565],\n",
            "        [ 4.0279, -4.5356],\n",
            "        [ 4.1752, -4.5879],\n",
            "        [ 4.0896, -4.5356],\n",
            "        [ 4.0657, -4.4422],\n",
            "        [ 4.1582, -4.5097],\n",
            "        [ 4.1568, -4.6234],\n",
            "        [-2.2566,  2.4233],\n",
            "        [ 4.1400, -4.5339],\n",
            "        [ 4.1381, -4.5369],\n",
            "        [ 4.2046, -4.5781],\n",
            "        [ 4.0955, -4.4705],\n",
            "        [ 4.0721, -4.3079],\n",
            "        [ 3.8888, -4.4014],\n",
            "        [ 4.0330, -4.4226],\n",
            "        [ 4.1461, -4.5448]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1189, -4.5019],\n",
            "        [ 4.1826, -4.5747],\n",
            "        [ 4.1049, -4.5653],\n",
            "        [ 4.1549, -4.5236],\n",
            "        [ 4.1283, -4.5678],\n",
            "        [ 4.2184, -4.5417],\n",
            "        [ 3.9503, -4.4555],\n",
            "        [ 4.0921, -4.5648],\n",
            "        [ 4.2252, -4.5061],\n",
            "        [ 4.1244, -4.5864],\n",
            "        [ 4.0246, -4.4403],\n",
            "        [-2.2071,  2.4209],\n",
            "        [ 4.1951, -4.5344],\n",
            "        [ 4.2228, -4.5214],\n",
            "        [ 3.9839, -4.4862],\n",
            "        [ 4.0400, -4.4127]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.1237,  2.4079],\n",
            "        [ 4.1633, -4.5629],\n",
            "        [ 4.2224, -4.5329],\n",
            "        [-1.7105,  2.0751],\n",
            "        [ 4.1731, -4.5521],\n",
            "        [-2.0259,  2.2562],\n",
            "        [ 4.0542, -4.5387],\n",
            "        [ 4.1861, -4.4478],\n",
            "        [ 4.0011, -4.4803],\n",
            "        [ 4.1481, -4.5276],\n",
            "        [ 4.1663, -4.5196],\n",
            "        [ 4.1909, -4.5725],\n",
            "        [ 4.1485, -4.5173],\n",
            "        [ 3.9826, -4.4881],\n",
            "        [ 4.0221, -4.5039],\n",
            "        [-1.8342,  2.1640]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1880, -4.5740],\n",
            "        [ 4.1515, -4.5231],\n",
            "        [ 4.1574, -4.5442],\n",
            "        [ 4.0581, -4.3174],\n",
            "        [ 1.5349, -2.1682],\n",
            "        [ 3.3003, -3.8591],\n",
            "        [ 4.1320, -4.5344],\n",
            "        [ 3.1206, -3.5773],\n",
            "        [ 4.0784, -4.3156],\n",
            "        [ 4.1749, -4.5250],\n",
            "        [ 3.8835, -4.4088],\n",
            "        [ 4.1153, -4.4750],\n",
            "        [ 4.0737, -4.5637],\n",
            "        [ 4.1340, -4.5980],\n",
            "        [ 4.2311, -4.5744],\n",
            "        [ 4.1558, -4.5511]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9962, -4.4485],\n",
            "        [ 4.0524, -4.5020],\n",
            "        [ 3.7775, -4.3698],\n",
            "        [ 3.6925, -4.2269],\n",
            "        [ 3.9234, -4.3755],\n",
            "        [ 4.1831, -4.5219],\n",
            "        [ 4.0447, -4.5044],\n",
            "        [ 3.9251, -4.3777],\n",
            "        [ 4.1348, -4.5755],\n",
            "        [ 3.7114, -4.2388],\n",
            "        [ 3.9930, -4.5048],\n",
            "        [ 4.0011, -4.4884],\n",
            "        [ 4.1611, -4.5447],\n",
            "        [ 4.1657, -4.5476],\n",
            "        [-2.0912,  2.3847],\n",
            "        [ 4.1747, -4.4804]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1068, -4.5039],\n",
            "        [ 4.1738, -4.5632],\n",
            "        [ 4.1623, -4.5415],\n",
            "        [-2.1049,  2.3584],\n",
            "        [ 4.1643, -4.4677],\n",
            "        [ 4.0516, -4.4874],\n",
            "        [ 4.1701, -4.5819],\n",
            "        [ 3.9690, -4.2986],\n",
            "        [ 4.1661, -4.6093],\n",
            "        [-1.7601,  2.1284],\n",
            "        [ 3.3690, -3.8375],\n",
            "        [ 4.1373, -4.5635],\n",
            "        [ 4.1008, -4.4164],\n",
            "        [ 4.1683, -4.5775],\n",
            "        [ 4.0986, -4.4998],\n",
            "        [ 4.1762, -4.4630]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8913, -4.2899],\n",
            "        [-1.8660,  2.1855],\n",
            "        [ 4.2367, -4.5543],\n",
            "        [ 4.1766, -4.5939],\n",
            "        [ 4.2229, -4.5382],\n",
            "        [ 4.2211, -4.4767],\n",
            "        [ 4.0700, -4.4884],\n",
            "        [ 3.8557, -4.3755],\n",
            "        [ 4.1250, -4.5899],\n",
            "        [ 4.0911, -4.3286],\n",
            "        [ 4.1981, -4.5779],\n",
            "        [ 4.0192, -4.4082],\n",
            "        [ 4.1163, -4.5283],\n",
            "        [ 4.2427, -4.5372],\n",
            "        [ 4.1741, -4.5839],\n",
            "        [-1.7232,  2.0859]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0985, -4.4210],\n",
            "        [ 3.6117, -4.1627],\n",
            "        [-1.6887,  2.0192],\n",
            "        [ 4.2145, -4.6001],\n",
            "        [ 3.9963, -4.3723],\n",
            "        [ 3.9216, -4.3984],\n",
            "        [ 2.6556, -3.3660],\n",
            "        [-1.7882,  2.1145],\n",
            "        [ 4.0968, -4.5071],\n",
            "        [ 4.1231, -4.4948],\n",
            "        [ 4.0118, -4.5127],\n",
            "        [ 4.1704, -4.5057],\n",
            "        [ 4.2038, -4.5767],\n",
            "        [ 4.2130, -4.5113],\n",
            "        [ 4.1272, -4.5799],\n",
            "        [ 4.0761, -4.4998]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0145, -4.4783],\n",
            "        [ 3.9901, -4.4083],\n",
            "        [ 4.1032, -4.5609],\n",
            "        [ 4.1805, -4.6163],\n",
            "        [ 4.2093, -4.5838],\n",
            "        [-1.6859,  2.0473],\n",
            "        [ 4.0493, -4.4419],\n",
            "        [ 3.9382, -4.4336],\n",
            "        [ 4.1613, -4.5118],\n",
            "        [ 4.1313, -4.5376],\n",
            "        [ 4.2056, -4.5026],\n",
            "        [ 4.2054, -4.5711],\n",
            "        [ 4.2114, -4.4931],\n",
            "        [ 4.1282, -4.5057],\n",
            "        [ 4.1427, -4.5912],\n",
            "        [ 4.1274, -4.5526]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1117, -4.5089],\n",
            "        [-1.5972,  1.9324],\n",
            "        [ 4.1178, -4.5240],\n",
            "        [ 4.2355, -4.5736],\n",
            "        [ 3.9497, -4.5069],\n",
            "        [ 4.0401, -4.4522],\n",
            "        [ 4.2136, -4.5034],\n",
            "        [ 4.1810, -4.5761],\n",
            "        [ 4.0996, -4.4644],\n",
            "        [ 4.1281, -4.6297],\n",
            "        [-1.8121,  2.1780],\n",
            "        [-1.5301,  1.9087],\n",
            "        [ 4.1848, -4.5213],\n",
            "        [ 4.0890, -4.4229],\n",
            "        [ 4.2133, -4.5373],\n",
            "        [-2.0908,  2.3643]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.8126, -4.3785],\n",
            "        [ 4.0319, -4.4284],\n",
            "        [ 4.0961, -4.5619],\n",
            "        [ 4.1986, -4.5803],\n",
            "        [ 4.0813, -4.5197],\n",
            "        [ 4.1865, -4.5433],\n",
            "        [-1.7355,  2.1036],\n",
            "        [ 4.1579, -4.6081],\n",
            "        [ 4.2262, -4.5344],\n",
            "        [ 4.2080, -4.5479],\n",
            "        [ 4.1633, -4.5527],\n",
            "        [ 4.2360, -4.6005],\n",
            "        [ 4.1350, -4.6003],\n",
            "        [ 4.1359, -4.5426],\n",
            "        [ 4.0362, -4.5002],\n",
            "        [-1.9720,  2.3131]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.9079, -4.4725],\n",
            "        [-1.8010,  2.1469],\n",
            "        [ 4.1539, -4.5044],\n",
            "        [-1.7743,  2.1232],\n",
            "        [ 3.9475, -4.4653],\n",
            "        [ 4.1155, -4.4337],\n",
            "        [ 4.1701, -4.4429],\n",
            "        [ 4.2251, -4.5393],\n",
            "        [-1.5423,  1.9253],\n",
            "        [ 4.1560, -4.5387],\n",
            "        [ 4.0833, -4.3941],\n",
            "        [ 4.0445, -4.5747],\n",
            "        [ 4.1186, -4.4843],\n",
            "        [ 4.0747, -4.5525],\n",
            "        [-2.0370,  2.3926],\n",
            "        [ 4.0710, -4.5627]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1193, -4.5031],\n",
            "        [-1.8516,  2.2407],\n",
            "        [ 4.2119, -4.5218],\n",
            "        [ 4.1165, -4.5020],\n",
            "        [ 3.9121, -4.3841],\n",
            "        [-2.2794,  2.5341],\n",
            "        [ 4.0124, -4.4838],\n",
            "        [ 4.1923, -4.5439],\n",
            "        [-1.4890,  1.9041],\n",
            "        [ 4.2116, -4.5708],\n",
            "        [ 4.1603, -4.5775],\n",
            "        [ 4.0565, -4.5708],\n",
            "        [ 3.8957, -4.4723],\n",
            "        [ 4.1895, -4.4730],\n",
            "        [ 4.2259, -4.6131],\n",
            "        [ 4.1480, -4.5792]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 3.1339, -3.6685],\n",
            "        [ 4.2348, -4.5575],\n",
            "        [ 4.1786, -4.5351],\n",
            "        [ 4.1191, -4.4465],\n",
            "        [ 3.9748, -4.4858],\n",
            "        [ 4.0361, -4.5526],\n",
            "        [ 4.1837, -4.4401],\n",
            "        [ 4.1134, -4.5747],\n",
            "        [-1.6286,  2.0236],\n",
            "        [ 4.1141, -4.5970],\n",
            "        [ 4.1564, -4.4831],\n",
            "        [ 4.1851, -4.4191],\n",
            "        [ 4.2550, -4.6020],\n",
            "        [ 4.2500, -4.5705],\n",
            "        [ 4.2362, -4.5661],\n",
            "        [-1.9351,  2.3583]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0018, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2515, -4.5550],\n",
            "        [ 4.1934, -4.5901],\n",
            "        [ 4.1560, -4.4649],\n",
            "        [ 4.0434, -4.5264],\n",
            "        [ 4.2623, -4.5921],\n",
            "        [ 4.0651, -4.5575],\n",
            "        [-2.5040,  2.6891],\n",
            "        [ 3.8277, -4.3593],\n",
            "        [ 4.2627, -4.6031],\n",
            "        [-1.7319,  2.1430],\n",
            "        [ 3.0794, -3.7978],\n",
            "        [ 3.9889, -4.4037],\n",
            "        [ 4.1697, -4.5864],\n",
            "        [ 4.1666, -4.6018],\n",
            "        [ 4.2329, -4.5913],\n",
            "        [ 3.9619, -4.4333]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0881, -4.6277],\n",
            "        [-2.2243,  2.5134],\n",
            "        [ 4.1031, -4.5876],\n",
            "        [ 4.1706, -4.6265],\n",
            "        [-2.3419,  2.6378],\n",
            "        [ 4.1084, -4.4376],\n",
            "        [ 3.8511, -4.4682],\n",
            "        [ 4.1453, -4.5519],\n",
            "        [ 4.2411, -4.5684],\n",
            "        [-2.8035,  2.9765],\n",
            "        [ 4.2423, -4.5780],\n",
            "        [ 4.0869, -4.5354],\n",
            "        [ 4.2235, -4.6243],\n",
            "        [-1.8871,  2.2895],\n",
            "        [ 4.1391, -4.3763],\n",
            "        [ 4.0444, -4.4072]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1998, -4.6099],\n",
            "        [ 4.1206, -4.5361],\n",
            "        [ 4.1199, -4.4922],\n",
            "        [-2.2207,  2.5248],\n",
            "        [ 4.2152, -4.5894],\n",
            "        [-2.4216,  2.7676],\n",
            "        [-2.1841,  2.4890],\n",
            "        [-2.4770,  2.8070],\n",
            "        [ 4.1008, -4.4752],\n",
            "        [-2.3589,  2.5898],\n",
            "        [ 4.2180, -4.6192],\n",
            "        [ 4.1240, -4.4307],\n",
            "        [ 4.1270, -4.4858],\n",
            "        [ 4.0889, -4.4766],\n",
            "        [ 4.1332, -4.6189],\n",
            "        [ 4.2243, -4.5612]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0017, -4.5067],\n",
            "        [ 4.0878, -4.5595],\n",
            "        [ 4.2207, -4.5465],\n",
            "        [ 4.1544, -4.6081],\n",
            "        [ 4.1288, -4.5956],\n",
            "        [ 3.9535, -4.4006],\n",
            "        [ 4.1456, -4.5889],\n",
            "        [ 4.0849, -4.4973],\n",
            "        [ 3.8576, -4.3926],\n",
            "        [ 4.1151, -4.5035],\n",
            "        [ 4.1910, -4.5608],\n",
            "        [ 4.1015, -4.5110],\n",
            "        [ 4.1485, -4.5445],\n",
            "        [ 4.0889, -4.5244],\n",
            "        [ 4.2751, -4.6054],\n",
            "        [ 4.2357, -4.5875]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.0207,  3.1460],\n",
            "        [ 4.2226, -4.5694],\n",
            "        [ 4.1644, -4.5420],\n",
            "        [ 4.2691, -4.6233],\n",
            "        [-2.4177,  2.7729],\n",
            "        [ 4.1393, -4.5268],\n",
            "        [ 4.1253, -4.5213],\n",
            "        [ 3.8254, -4.1974],\n",
            "        [ 4.1761, -4.6178],\n",
            "        [ 4.0581, -4.5418],\n",
            "        [ 3.6194, -4.2281],\n",
            "        [ 4.0504, -4.4815],\n",
            "        [ 4.0663, -4.3756],\n",
            "        [ 4.2440, -4.5601],\n",
            "        [ 4.2935, -4.5713],\n",
            "        [ 4.1541, -4.5766]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2790, -4.6406],\n",
            "        [ 4.1800, -4.6418],\n",
            "        [-2.4379,  2.7890],\n",
            "        [ 4.0077, -4.5300],\n",
            "        [ 4.1873, -4.5794],\n",
            "        [ 4.2603, -4.6001],\n",
            "        [ 4.1258, -4.5791],\n",
            "        [ 4.2244, -4.5682],\n",
            "        [ 4.0724, -4.5005],\n",
            "        [ 4.2869, -4.5289],\n",
            "        [-2.5129,  2.7669],\n",
            "        [ 4.1414, -4.5926],\n",
            "        [-1.9286,  2.3328],\n",
            "        [ 4.2737, -4.6203],\n",
            "        [-2.0258,  2.3915],\n",
            "        [ 4.1357, -4.5213]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.5100,  3.5861],\n",
            "        [-3.2856,  3.4213],\n",
            "        [ 4.2323, -4.5821],\n",
            "        [ 4.2266, -4.6185],\n",
            "        [ 4.2869, -4.5932],\n",
            "        [ 4.1771, -4.5633],\n",
            "        [ 3.8300, -4.4027],\n",
            "        [ 4.2588, -4.6120],\n",
            "        [ 4.1027, -4.4903],\n",
            "        [ 4.2222, -4.6527],\n",
            "        [ 4.1159, -4.5466],\n",
            "        [-2.3963,  2.7302],\n",
            "        [ 4.1607, -4.5489],\n",
            "        [ 4.2507, -4.5925],\n",
            "        [ 4.2312, -4.5915],\n",
            "        [-2.4348,  2.7374]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2644, -4.5937],\n",
            "        [ 4.2816, -4.6391],\n",
            "        [-3.1031,  3.2518],\n",
            "        [ 4.2356, -4.5216],\n",
            "        [-3.5142,  3.6928],\n",
            "        [ 3.9777, -4.5275],\n",
            "        [ 3.9776, -4.3916],\n",
            "        [ 4.2420, -4.6475],\n",
            "        [ 4.2790, -4.6113],\n",
            "        [ 4.0394, -4.3403],\n",
            "        [-3.1226,  3.2379],\n",
            "        [ 4.2396, -4.5844],\n",
            "        [ 4.1063, -4.6039],\n",
            "        [ 4.1992, -4.5835],\n",
            "        [ 4.2862, -4.5578],\n",
            "        [ 4.2561, -4.6382]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.1583,  2.5251],\n",
            "        [ 4.2197, -4.6614],\n",
            "        [ 4.0507, -4.5468],\n",
            "        [ 4.1188, -4.5268],\n",
            "        [ 4.2317, -4.5411],\n",
            "        [ 4.2427, -4.5994],\n",
            "        [ 4.2684, -4.6045],\n",
            "        [ 4.2686, -4.6091],\n",
            "        [-1.2037,  1.5871],\n",
            "        [ 4.2275, -4.5798],\n",
            "        [ 4.1598, -4.5709],\n",
            "        [ 4.1844, -4.5534],\n",
            "        [ 4.1170, -4.4562],\n",
            "        [ 4.2973, -4.6153],\n",
            "        [ 4.2609, -4.5290],\n",
            "        [ 4.2818, -4.6365]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1396, -4.6230],\n",
            "        [-2.9268,  3.2509],\n",
            "        [ 4.1834, -4.6022],\n",
            "        [ 4.2007, -4.6264],\n",
            "        [ 4.0721, -4.5956],\n",
            "        [ 4.1940, -4.6060],\n",
            "        [ 4.2496, -4.5507],\n",
            "        [-2.9834,  3.2273],\n",
            "        [ 4.1253, -4.6015],\n",
            "        [ 4.1695, -4.5006],\n",
            "        [ 4.2977, -4.6607],\n",
            "        [ 4.1176, -4.4705],\n",
            "        [-3.1425,  3.4227],\n",
            "        [ 4.3138, -4.5909],\n",
            "        [-3.4891,  3.6285],\n",
            "        [ 4.1048, -4.4667]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1230, -4.5596],\n",
            "        [ 3.9675, -4.4096],\n",
            "        [ 4.2985, -4.6153],\n",
            "        [ 4.1346, -4.6342],\n",
            "        [ 4.2207, -4.5752],\n",
            "        [ 4.0938, -4.4939],\n",
            "        [ 4.0821, -4.5699],\n",
            "        [ 4.0904, -4.4803],\n",
            "        [ 4.2322, -4.6690],\n",
            "        [ 4.2143, -4.5800],\n",
            "        [ 4.2367, -4.5657],\n",
            "        [ 4.2667, -4.6274],\n",
            "        [ 4.0529, -4.5417],\n",
            "        [ 4.2777, -4.5505],\n",
            "        [ 4.1814, -4.6596],\n",
            "        [ 3.9492, -4.4571]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1125, -4.6058],\n",
            "        [ 4.1627, -4.5327],\n",
            "        [ 4.2226, -4.6561],\n",
            "        [ 4.2222, -4.5458],\n",
            "        [-3.5910,  3.7749],\n",
            "        [-3.5475,  3.8182],\n",
            "        [ 4.2464, -4.6060],\n",
            "        [ 4.2313, -4.6101],\n",
            "        [-3.7305,  3.8964],\n",
            "        [ 4.2688, -4.6506],\n",
            "        [ 4.0887, -4.5761],\n",
            "        [ 3.8754, -4.4134],\n",
            "        [ 4.1432, -4.5506],\n",
            "        [ 4.1651, -4.5756],\n",
            "        [ 4.1623, -4.6044],\n",
            "        [ 4.2983, -4.6787]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.3546,  3.5897],\n",
            "        [-3.7117,  3.9341],\n",
            "        [ 4.2751, -4.6527],\n",
            "        [ 4.3017, -4.5989],\n",
            "        [ 4.1790, -4.6317],\n",
            "        [ 4.3085, -4.6497],\n",
            "        [ 4.2190, -4.5280],\n",
            "        [ 4.0281, -4.5098],\n",
            "        [-3.1882,  3.4257],\n",
            "        [ 4.2971, -4.6555],\n",
            "        [ 4.2858, -4.6699],\n",
            "        [ 3.8238, -4.2022],\n",
            "        [-3.3915,  3.5988],\n",
            "        [ 4.1283, -4.5018],\n",
            "        [-3.7771,  3.9024],\n",
            "        [ 4.1776, -4.6466]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2448, -4.6140],\n",
            "        [ 4.2329, -4.6729],\n",
            "        [ 4.2129, -4.4734],\n",
            "        [ 4.1929, -4.5886],\n",
            "        [ 4.1521, -4.4825],\n",
            "        [ 4.2083, -4.5578],\n",
            "        [ 4.1126, -4.6206],\n",
            "        [ 4.3014, -4.6735],\n",
            "        [ 4.2644, -4.6341],\n",
            "        [ 4.0764, -4.5181],\n",
            "        [ 4.1775, -4.6074],\n",
            "        [ 4.1272, -4.5715],\n",
            "        [ 4.2632, -4.6304],\n",
            "        [ 4.2261, -4.5941],\n",
            "        [-3.3233,  3.5728],\n",
            "        [ 4.0375, -4.5380]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2830, -4.6827],\n",
            "        [ 4.2888, -4.6977],\n",
            "        [ 4.1627, -4.6076],\n",
            "        [-2.5403,  2.8807],\n",
            "        [ 4.2758, -4.6411],\n",
            "        [ 4.2064, -4.6112],\n",
            "        [ 4.2424, -4.5772],\n",
            "        [ 4.2633, -4.6054],\n",
            "        [ 4.2783, -4.6566],\n",
            "        [-3.6178,  3.8670],\n",
            "        [ 4.2035, -4.6616],\n",
            "        [ 4.2495, -4.6406],\n",
            "        [ 4.2272, -4.6889],\n",
            "        [ 4.1502, -4.6669],\n",
            "        [ 4.1938, -4.5625],\n",
            "        [ 4.2400, -4.6326]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2084, -4.4507],\n",
            "        [ 4.2915, -4.6730],\n",
            "        [ 4.3184, -4.6430],\n",
            "        [ 4.3355, -4.6128],\n",
            "        [ 4.1575, -4.5692],\n",
            "        [ 4.1568, -4.4676],\n",
            "        [-3.5937,  3.8624],\n",
            "        [ 3.6290, -4.1174],\n",
            "        [ 4.1961, -4.5957],\n",
            "        [ 4.3317, -4.6457],\n",
            "        [ 4.2727, -4.6653],\n",
            "        [ 4.1009, -4.5595],\n",
            "        [ 4.0629, -4.6044],\n",
            "        [ 4.2436, -4.6287],\n",
            "        [-3.4360,  3.8507],\n",
            "        [ 4.2215, -4.5566]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1735, -4.6206],\n",
            "        [ 4.3358, -4.6017],\n",
            "        [-3.3758,  3.7278],\n",
            "        [ 4.1726, -4.6284],\n",
            "        [ 4.2941, -4.6679],\n",
            "        [ 4.2510, -4.6123],\n",
            "        [ 4.2214, -4.6531],\n",
            "        [ 4.1916, -4.4547],\n",
            "        [-3.5855,  3.9428],\n",
            "        [ 4.1688, -4.5261],\n",
            "        [-3.7999,  3.9312],\n",
            "        [ 4.3142, -4.6670],\n",
            "        [ 3.7834, -4.3881],\n",
            "        [-3.5081,  3.8595],\n",
            "        [-3.5358,  3.9285],\n",
            "        [ 3.9638, -4.4672]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1212, -4.4543],\n",
            "        [ 4.3295, -4.6818],\n",
            "        [ 4.2126, -4.6044],\n",
            "        [ 4.2384, -4.7045],\n",
            "        [ 4.3317, -4.6854],\n",
            "        [ 4.1376, -4.4699],\n",
            "        [-2.4898,  2.8415],\n",
            "        [ 4.1285, -4.5888],\n",
            "        [-3.1781,  3.4908],\n",
            "        [ 4.2096, -4.4895],\n",
            "        [ 4.2492, -4.6179],\n",
            "        [ 4.0660, -4.5687],\n",
            "        [ 4.2534, -4.6138],\n",
            "        [ 4.0523, -4.5044],\n",
            "        [ 4.1409, -4.5925],\n",
            "        [ 3.9300, -4.4784]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-2.9757,  3.3280],\n",
            "        [ 4.2855, -4.6612],\n",
            "        [ 4.2953, -4.5853],\n",
            "        [-3.6701,  3.9640],\n",
            "        [ 4.2609, -4.5443],\n",
            "        [ 4.1928, -4.5560],\n",
            "        [ 4.2498, -4.6460],\n",
            "        [ 4.1335, -4.5279],\n",
            "        [ 4.2463, -4.5090],\n",
            "        [ 4.2092, -4.6635],\n",
            "        [ 4.2757, -4.6627],\n",
            "        [ 4.1617, -4.5783],\n",
            "        [ 4.1586, -4.4909],\n",
            "        [ 4.2713, -4.5925],\n",
            "        [ 4.2351, -4.6115],\n",
            "        [ 4.1559, -4.5262]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2950, -4.6678],\n",
            "        [ 4.3411, -4.6962],\n",
            "        [ 4.0543, -4.5472],\n",
            "        [ 4.3011, -4.7004],\n",
            "        [ 4.3185, -4.6247],\n",
            "        [ 4.3038, -4.6644],\n",
            "        [-3.7137,  3.9697],\n",
            "        [-3.7551,  3.9671],\n",
            "        [ 4.1690, -4.6298],\n",
            "        [ 4.0213, -4.4403],\n",
            "        [ 4.2212, -4.5874],\n",
            "        [ 4.1664, -4.6063],\n",
            "        [-3.6916,  3.9832],\n",
            "        [ 4.2500, -4.5331],\n",
            "        [ 4.2799, -4.6760],\n",
            "        [-3.4922,  3.8892]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2233, -4.4587],\n",
            "        [ 4.1934, -4.5294],\n",
            "        [ 4.3271, -4.6829],\n",
            "        [ 4.2873, -4.6339],\n",
            "        [-3.5698,  3.9041],\n",
            "        [-3.5697,  3.9049],\n",
            "        [-1.8706,  2.1335],\n",
            "        [ 4.1340, -4.5645],\n",
            "        [ 4.2545, -4.6327],\n",
            "        [-3.6339,  3.9494],\n",
            "        [ 4.3197, -4.6913],\n",
            "        [ 4.2468, -4.6307],\n",
            "        [ 4.0731, -4.5522],\n",
            "        [-3.5356,  3.9209],\n",
            "        [ 4.2723, -4.6045],\n",
            "        [ 4.2039, -4.6003]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2154, -4.6178],\n",
            "        [ 4.2574, -4.6339],\n",
            "        [-3.4961,  3.9319],\n",
            "        [ 4.0922, -4.5175],\n",
            "        [ 4.2575, -4.6237],\n",
            "        [ 4.3066, -4.6531],\n",
            "        [ 4.1417, -4.6157],\n",
            "        [ 4.2187, -4.5509],\n",
            "        [-3.6545,  3.9749],\n",
            "        [-3.5617,  3.9402],\n",
            "        [-3.7220,  3.9805],\n",
            "        [-3.5820,  3.9527],\n",
            "        [ 4.3271, -4.6884],\n",
            "        [ 4.2711, -4.6063],\n",
            "        [ 4.0900, -4.6162],\n",
            "        [ 4.1772, -4.6087]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3399, -4.6679],\n",
            "        [ 4.3117, -4.6035],\n",
            "        [-3.5637,  3.9449],\n",
            "        [ 4.2744, -4.6989],\n",
            "        [ 4.1665, -4.6063],\n",
            "        [ 4.2579, -4.6256],\n",
            "        [ 4.3042, -4.7199],\n",
            "        [ 4.2846, -4.6534],\n",
            "        [ 4.3061, -4.6894],\n",
            "        [ 4.2833, -4.5928],\n",
            "        [ 4.3240, -4.6392],\n",
            "        [ 4.0275, -4.5633],\n",
            "        [ 4.3287, -4.6926],\n",
            "        [ 4.2752, -4.6001],\n",
            "        [ 4.1783, -4.5412],\n",
            "        [ 4.3196, -4.7002]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3033, -4.6390],\n",
            "        [ 4.2308, -4.6119],\n",
            "        [ 4.2913, -4.6969],\n",
            "        [ 4.3268, -4.6518],\n",
            "        [ 4.2866, -4.6854],\n",
            "        [ 4.2700, -4.6904],\n",
            "        [-3.3903,  3.8908],\n",
            "        [ 4.0702, -4.5087],\n",
            "        [ 4.3030, -4.6286],\n",
            "        [ 4.0241, -4.4930],\n",
            "        [ 4.2322, -4.6002],\n",
            "        [ 4.0244, -4.4978],\n",
            "        [ 4.3036, -4.7061],\n",
            "        [ 4.2191, -4.6514],\n",
            "        [-3.4672,  3.9149],\n",
            "        [ 4.1286, -4.5935]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2984, -4.6288],\n",
            "        [ 4.2389, -4.6357],\n",
            "        [ 4.1589, -4.6324],\n",
            "        [ 4.3094, -4.6824],\n",
            "        [ 2.2873, -2.8380],\n",
            "        [ 4.3126, -4.6803],\n",
            "        [-3.3889,  3.8810],\n",
            "        [ 4.1427, -4.4870],\n",
            "        [ 4.3443, -4.6771],\n",
            "        [ 3.8781, -4.4275],\n",
            "        [ 4.3311, -4.6903],\n",
            "        [ 4.2415, -4.6429],\n",
            "        [ 4.2879, -4.7185],\n",
            "        [ 4.0875, -4.5067],\n",
            "        [ 4.1868, -4.6101],\n",
            "        [ 4.3572, -4.6756]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1810, -4.5468],\n",
            "        [ 4.2182, -4.5927],\n",
            "        [ 4.3479, -4.6947],\n",
            "        [ 4.2787, -4.6854],\n",
            "        [ 4.2520, -4.5815],\n",
            "        [ 4.0245, -4.5183],\n",
            "        [ 4.3144, -4.6914],\n",
            "        [ 4.2174, -4.5451],\n",
            "        [ 4.0738, -4.5196],\n",
            "        [ 4.2713, -4.7203],\n",
            "        [-3.3040,  3.8151],\n",
            "        [ 4.2576, -4.6748],\n",
            "        [ 4.2243, -4.5919],\n",
            "        [ 4.2052, -4.6168],\n",
            "        [ 4.2360, -4.5077],\n",
            "        [ 4.2647, -4.7184]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1546, -4.4639],\n",
            "        [ 4.3273, -4.6588],\n",
            "        [-3.6036,  3.9586],\n",
            "        [ 4.2304, -4.6785],\n",
            "        [ 4.1262, -4.6592],\n",
            "        [-3.3573,  3.6626],\n",
            "        [ 4.3479, -4.6922],\n",
            "        [ 4.2013, -4.6885],\n",
            "        [ 4.0022, -4.5364],\n",
            "        [ 4.2500, -4.4716],\n",
            "        [ 4.3380, -4.6703],\n",
            "        [ 4.2994, -4.6830],\n",
            "        [ 4.1111, -4.5577],\n",
            "        [ 4.1183, -4.6323],\n",
            "        [-3.7180,  3.9877],\n",
            "        [ 4.0815, -4.4761]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.0810, -4.5754],\n",
            "        [-3.5633,  3.9624],\n",
            "        [ 4.2456, -4.6019],\n",
            "        [ 4.2309, -4.7014],\n",
            "        [-3.6361,  3.9797],\n",
            "        [ 4.3361, -4.6873],\n",
            "        [-3.4398,  3.9260],\n",
            "        [ 4.2195, -4.5893],\n",
            "        [ 4.3219, -4.5891],\n",
            "        [ 4.2508, -4.7165],\n",
            "        [ 4.2278, -4.6884],\n",
            "        [-2.9772,  3.3162],\n",
            "        [-0.9032,  1.1040],\n",
            "        [ 4.2447, -4.4764],\n",
            "        [ 4.3675, -4.6273],\n",
            "        [ 4.1925, -4.5842]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3344, -4.6307],\n",
            "        [ 4.2925, -4.6549],\n",
            "        [ 4.2752, -4.7106],\n",
            "        [ 4.1228, -4.6315],\n",
            "        [ 4.0775, -4.6063],\n",
            "        [ 4.2301, -4.5941],\n",
            "        [ 4.2764, -4.6530],\n",
            "        [ 4.2796, -4.6383],\n",
            "        [ 4.0386, -4.5601],\n",
            "        [ 4.2929, -4.7181],\n",
            "        [-3.4687,  3.9372],\n",
            "        [ 4.3175, -4.6708],\n",
            "        [ 4.3606, -4.7032],\n",
            "        [ 4.2526, -4.6309],\n",
            "        [ 3.9094, -4.5890],\n",
            "        [ 4.2264, -4.5873]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2317, -4.5215],\n",
            "        [ 3.6688, -4.2553],\n",
            "        [-3.5509,  3.9480],\n",
            "        [ 4.0091, -4.4869],\n",
            "        [ 2.5242, -3.1464],\n",
            "        [ 4.2614, -4.6445],\n",
            "        [ 4.3510, -4.6177],\n",
            "        [-3.3573,  3.8424],\n",
            "        [ 4.3213, -4.6885],\n",
            "        [-3.4950,  3.9526],\n",
            "        [ 4.3168, -4.6619],\n",
            "        [ 4.2351, -4.6664],\n",
            "        [ 4.3806, -4.6723],\n",
            "        [ 4.3715, -4.6805],\n",
            "        [ 4.2366, -4.5453],\n",
            "        [ 4.3271, -4.5938]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1413, -4.5257],\n",
            "        [-3.5202,  3.9300],\n",
            "        [ 4.3010, -4.5731],\n",
            "        [ 4.2718, -4.7243],\n",
            "        [ 4.2927, -4.6888],\n",
            "        [ 4.3080, -4.6953],\n",
            "        [ 4.1254, -4.5760],\n",
            "        [ 4.2264, -4.6892],\n",
            "        [ 4.3402, -4.7171],\n",
            "        [ 4.3205, -4.7057],\n",
            "        [ 4.1212, -4.5415],\n",
            "        [ 4.3649, -4.6727],\n",
            "        [ 4.3659, -4.6968],\n",
            "        [ 4.2913, -4.6481],\n",
            "        [ 4.2812, -4.5836],\n",
            "        [ 4.1883, -4.5872]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2786, -4.5964],\n",
            "        [ 4.3321, -4.7190],\n",
            "        [ 4.3294, -4.6488],\n",
            "        [ 4.3489, -4.6881],\n",
            "        [ 4.3464, -4.6623],\n",
            "        [ 4.3465, -4.6940],\n",
            "        [ 4.3503, -4.6914],\n",
            "        [ 4.2969, -4.6696],\n",
            "        [ 4.1972, -4.6583],\n",
            "        [ 4.1794, -4.5940],\n",
            "        [ 4.3087, -4.6889],\n",
            "        [ 4.3404, -4.7194],\n",
            "        [ 4.3502, -4.7098],\n",
            "        [ 4.3361, -4.6527],\n",
            "        [ 4.3820, -4.6509],\n",
            "        [ 4.3827, -4.6555]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3163, -4.7101],\n",
            "        [ 4.1732, -4.6423],\n",
            "        [ 4.3106, -4.7371],\n",
            "        [ 4.3075, -4.6722],\n",
            "        [ 4.3300, -4.7094],\n",
            "        [ 3.9410, -4.5423],\n",
            "        [ 4.3104, -4.6649],\n",
            "        [ 4.2548, -4.7240],\n",
            "        [ 4.3674, -4.6293],\n",
            "        [ 4.2400, -4.6045],\n",
            "        [ 4.3494, -4.6525],\n",
            "        [-3.3058,  3.6317],\n",
            "        [ 4.2571, -4.6565],\n",
            "        [ 4.1766, -4.4869],\n",
            "        [-3.2918,  3.6897],\n",
            "        [ 4.3321, -4.7272]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3777, -4.7258],\n",
            "        [ 4.1738, -4.6328],\n",
            "        [ 4.2975, -4.7170],\n",
            "        [-3.2118,  3.6757],\n",
            "        [ 4.3774, -4.6795],\n",
            "        [ 3.8952, -4.2872],\n",
            "        [ 4.3817, -4.6969],\n",
            "        [ 4.1436, -4.6169],\n",
            "        [ 4.3335, -4.7352],\n",
            "        [ 4.2002, -4.6398],\n",
            "        [ 4.3724, -4.6870],\n",
            "        [ 4.2241, -4.5365],\n",
            "        [ 4.3764, -4.6900],\n",
            "        [ 4.2636, -4.6980],\n",
            "        [ 4.2629, -4.6738],\n",
            "        [ 3.9682, -4.5380]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2900, -4.6738],\n",
            "        [ 4.2645, -4.5937],\n",
            "        [ 4.3256, -4.7476],\n",
            "        [-3.7190,  3.9903],\n",
            "        [ 4.3719, -4.7316],\n",
            "        [ 4.3494, -4.7030],\n",
            "        [ 4.2727, -4.6212],\n",
            "        [ 4.0788, -4.5097],\n",
            "        [ 4.3501, -4.6813],\n",
            "        [ 4.2529, -4.7001],\n",
            "        [ 4.3863, -4.6921],\n",
            "        [ 4.3581, -4.7282],\n",
            "        [ 4.2527, -4.5439],\n",
            "        [ 4.2719, -4.6933],\n",
            "        [-3.3973,  3.8250],\n",
            "        [-3.6749,  3.9785]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2457, -4.6001],\n",
            "        [ 4.1379, -4.5615],\n",
            "        [ 4.3879, -4.7128],\n",
            "        [ 4.3373, -4.6468],\n",
            "        [ 4.2050, -4.6383],\n",
            "        [ 4.1594, -4.6180],\n",
            "        [ 4.3041, -4.6718],\n",
            "        [ 4.2044, -4.6446],\n",
            "        [ 4.0715, -4.5574],\n",
            "        [ 4.2977, -4.7339],\n",
            "        [ 4.3476, -4.6931],\n",
            "        [ 4.3611, -4.5883],\n",
            "        [ 4.3530, -4.6534],\n",
            "        [ 4.2692, -4.6715],\n",
            "        [ 4.3582, -4.6015],\n",
            "        [ 4.1865, -4.5856]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1632, -4.5981],\n",
            "        [ 4.3177, -4.6638],\n",
            "        [-3.5792,  3.9717],\n",
            "        [ 4.1809, -4.5699],\n",
            "        [ 1.6511, -2.2303],\n",
            "        [ 4.2800, -4.5833],\n",
            "        [-3.6316,  4.0003],\n",
            "        [ 4.1169, -4.6161],\n",
            "        [ 4.3359, -4.7028],\n",
            "        [ 4.2671, -4.5857],\n",
            "        [ 4.3553, -4.6782],\n",
            "        [ 4.3745, -4.6805],\n",
            "        [ 4.3129, -4.6865],\n",
            "        [ 4.1044, -4.6263],\n",
            "        [-3.5130,  3.9655],\n",
            "        [ 4.3169, -4.7104]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2439, -4.5779],\n",
            "        [ 4.2693, -4.5017],\n",
            "        [ 4.1874, -4.5189],\n",
            "        [ 4.1550, -4.6516],\n",
            "        [ 4.2855, -4.5171],\n",
            "        [ 4.3530, -4.7243],\n",
            "        [ 4.2362, -4.7026],\n",
            "        [ 4.2447, -4.6504],\n",
            "        [ 4.3918, -4.6918],\n",
            "        [-3.6686,  3.9982],\n",
            "        [ 4.3380, -4.7170],\n",
            "        [-3.5116,  3.8441],\n",
            "        [ 4.0286, -4.5309],\n",
            "        [-3.5561,  3.9772],\n",
            "        [ 4.2080, -4.6460],\n",
            "        [ 4.0831, -4.6027]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2611, -4.6823],\n",
            "        [ 4.3581, -4.7267],\n",
            "        [ 4.3872, -4.6612],\n",
            "        [ 4.2691, -4.6519],\n",
            "        [-3.4748,  3.9569],\n",
            "        [ 4.2001, -4.6117],\n",
            "        [ 4.2616, -4.6702],\n",
            "        [-3.2594,  3.6814],\n",
            "        [ 4.3315, -4.7222],\n",
            "        [ 4.2685, -4.6580],\n",
            "        [ 4.2386, -4.5439],\n",
            "        [ 4.3294, -4.6641],\n",
            "        [ 4.2945, -4.7430],\n",
            "        [ 4.2686, -4.7148],\n",
            "        [ 4.1468, -4.5836],\n",
            "        [ 4.2118, -4.7160]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3800, -4.7421],\n",
            "        [ 4.2887, -4.6476],\n",
            "        [ 4.3264, -4.7224],\n",
            "        [-3.5810,  3.9826],\n",
            "        [-3.3769,  3.7728],\n",
            "        [ 4.2419, -4.6660],\n",
            "        [ 4.3295, -4.7167],\n",
            "        [ 4.3634, -4.7319],\n",
            "        [ 4.1884, -4.6438],\n",
            "        [ 4.3898, -4.6771],\n",
            "        [ 4.2804, -4.6285],\n",
            "        [ 4.2365, -4.6510],\n",
            "        [ 4.1826, -4.6649],\n",
            "        [ 4.3418, -4.5649],\n",
            "        [ 4.2645, -4.5371],\n",
            "        [ 4.1397, -4.5685]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3505, -4.7141],\n",
            "        [ 4.3621, -4.7608],\n",
            "        [-3.5693,  3.9840],\n",
            "        [-2.3428,  2.5556],\n",
            "        [ 4.3443, -4.6250],\n",
            "        [ 4.2799, -4.6409],\n",
            "        [ 4.3789, -4.7092],\n",
            "        [ 4.2802, -4.6857],\n",
            "        [ 4.3651, -4.7236],\n",
            "        [ 4.2765, -4.6535],\n",
            "        [ 4.0155, -4.5159],\n",
            "        [ 4.3329, -4.5842],\n",
            "        [ 4.2238, -4.5765],\n",
            "        [ 4.3688, -4.7172],\n",
            "        [ 4.2919, -4.7228],\n",
            "        [ 4.3759, -4.7338]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3119, -4.6639],\n",
            "        [ 4.3536, -4.7182],\n",
            "        [ 4.2695, -4.6075],\n",
            "        [ 4.1912, -4.6836],\n",
            "        [ 4.3774, -4.6811],\n",
            "        [ 4.3520, -4.7641],\n",
            "        [ 4.3316, -4.6418],\n",
            "        [ 4.3916, -4.7165],\n",
            "        [ 4.2065, -4.6224],\n",
            "        [ 4.1667, -4.5807],\n",
            "        [ 4.2822, -4.6734],\n",
            "        [ 4.3994, -4.7122],\n",
            "        [ 4.3344, -4.6953],\n",
            "        [ 4.4013, -4.7325],\n",
            "        [ 4.2775, -4.6868],\n",
            "        [ 4.2763, -4.6841]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3551, -4.7590],\n",
            "        [ 4.3915, -4.7010],\n",
            "        [ 4.3917, -4.7251],\n",
            "        [ 4.1637, -4.6489],\n",
            "        [ 4.3337, -4.6038],\n",
            "        [ 4.2270, -4.6255],\n",
            "        [ 4.4042, -4.7291],\n",
            "        [ 4.2936, -4.6927],\n",
            "        [ 4.1860, -4.6396],\n",
            "        [ 4.2312, -4.6476],\n",
            "        [ 4.1275, -4.4862],\n",
            "        [ 4.3847, -4.7106],\n",
            "        [ 4.3234, -4.6589],\n",
            "        [ 4.3766, -4.6753],\n",
            "        [ 4.1770, -4.6838],\n",
            "        [ 4.2557, -4.7175]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1205, -4.5649],\n",
            "        [ 4.3288, -4.6985],\n",
            "        [ 4.3177, -4.7701],\n",
            "        [ 4.2272, -4.5908],\n",
            "        [ 4.3997, -4.6738],\n",
            "        [ 4.3529, -4.7561],\n",
            "        [ 4.1252, -4.5509],\n",
            "        [ 4.0993, -4.5910],\n",
            "        [-3.3860,  3.7466],\n",
            "        [ 4.3199, -4.7404],\n",
            "        [ 4.3969, -4.6534],\n",
            "        [ 4.2294, -4.6113],\n",
            "        [ 4.1634, -4.6856],\n",
            "        [ 4.3103, -4.7424],\n",
            "        [ 4.2368, -4.6066],\n",
            "        [ 4.3625, -4.6956]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3515, -4.6630],\n",
            "        [ 4.0887, -4.5444],\n",
            "        [ 4.2412, -4.7459],\n",
            "        [ 4.3514, -4.6348],\n",
            "        [ 4.3552, -4.7559],\n",
            "        [ 4.3474, -4.7023],\n",
            "        [ 4.3684, -4.7047],\n",
            "        [ 4.2103, -4.6241],\n",
            "        [ 4.1344, -4.5113],\n",
            "        [ 4.3484, -4.7606],\n",
            "        [ 4.0919, -4.5400],\n",
            "        [ 4.2758, -4.6468],\n",
            "        [ 4.2033, -4.6958],\n",
            "        [ 4.3952, -4.7479],\n",
            "        [ 4.4009, -4.7163],\n",
            "        [ 4.3944, -4.7233]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.1254,  3.4379],\n",
            "        [ 4.2654, -4.7310],\n",
            "        [ 4.2976, -4.7024],\n",
            "        [ 4.3649, -4.6114],\n",
            "        [ 4.3163, -4.7017],\n",
            "        [ 4.3032, -4.6992],\n",
            "        [-3.3378,  3.7095],\n",
            "        [ 4.0678, -4.5688],\n",
            "        [-3.7050,  4.0377],\n",
            "        [ 4.1679, -4.6261],\n",
            "        [ 4.3403, -4.7018],\n",
            "        [ 4.3079, -4.6706],\n",
            "        [ 4.2288, -4.6711],\n",
            "        [ 4.3246, -4.6688],\n",
            "        [-3.5735,  3.9957],\n",
            "        [ 4.2492, -4.7073]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2907, -4.7439],\n",
            "        [ 4.2510, -4.6921],\n",
            "        [ 4.0061, -4.4989],\n",
            "        [ 4.2992, -4.6150],\n",
            "        [ 4.2911, -4.7429],\n",
            "        [ 4.3956, -4.7398],\n",
            "        [ 4.2497, -4.5788],\n",
            "        [ 4.3752, -4.6962],\n",
            "        [-3.0813,  3.3706],\n",
            "        [-3.2825,  3.7449],\n",
            "        [ 4.4017, -4.6714],\n",
            "        [ 4.1716, -4.6071],\n",
            "        [-3.5244,  3.9806],\n",
            "        [ 4.3236, -4.6639],\n",
            "        [ 4.2725, -4.6811],\n",
            "        [ 4.3019, -4.7066]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3024, -4.5994],\n",
            "        [-3.6039,  3.9957],\n",
            "        [-3.3532,  3.6964],\n",
            "        [ 4.3430, -4.7382],\n",
            "        [ 4.2328, -4.6894],\n",
            "        [ 4.2270, -4.6270],\n",
            "        [ 4.2949, -4.5268],\n",
            "        [-3.0525,  3.3047],\n",
            "        [ 4.2098, -4.6538],\n",
            "        [ 4.3735, -4.7383],\n",
            "        [ 4.2053, -4.6487],\n",
            "        [ 4.3272, -4.7256],\n",
            "        [ 4.3988, -4.6960],\n",
            "        [ 4.1976, -4.6794],\n",
            "        [ 4.1904, -4.6456],\n",
            "        [ 4.1389, -4.5907]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2989, -4.7373],\n",
            "        [-3.6733,  4.0155],\n",
            "        [ 4.2562, -4.6107],\n",
            "        [ 4.2181, -4.5662],\n",
            "        [ 4.2829, -4.6807],\n",
            "        [ 4.1782, -4.5598],\n",
            "        [ 4.2383, -4.6537],\n",
            "        [ 4.2963, -4.6887],\n",
            "        [ 4.2892, -4.6919],\n",
            "        [ 4.1871, -4.6639],\n",
            "        [ 4.1735, -4.6307],\n",
            "        [ 4.3675, -4.7561],\n",
            "        [-3.6756,  3.9796],\n",
            "        [ 4.3215, -4.6943],\n",
            "        [ 4.3438, -4.7247],\n",
            "        [ 4.4190, -4.7046]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2783, -4.7503],\n",
            "        [ 4.2955, -4.6859],\n",
            "        [ 3.8513, -4.4301],\n",
            "        [ 4.3393, -4.6721],\n",
            "        [-3.5922,  4.0193],\n",
            "        [-3.6044,  3.9901],\n",
            "        [ 4.2732, -4.7162],\n",
            "        [ 4.2546, -4.7063],\n",
            "        [ 4.1871, -4.6306],\n",
            "        [ 4.3445, -4.6912],\n",
            "        [ 4.2764, -4.6212],\n",
            "        [ 4.3790, -4.6706],\n",
            "        [ 4.3808, -4.6669],\n",
            "        [ 4.3629, -4.7162],\n",
            "        [ 4.2336, -4.6732],\n",
            "        [ 4.4144, -4.7178]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3757, -4.7299],\n",
            "        [ 4.3773, -4.7260],\n",
            "        [ 4.2479, -4.6961],\n",
            "        [ 4.2779, -4.6372],\n",
            "        [ 4.4176, -4.6867],\n",
            "        [ 4.3694, -4.6553],\n",
            "        [ 4.2414, -4.6308],\n",
            "        [ 4.2681, -4.6125],\n",
            "        [ 3.7642, -4.1454],\n",
            "        [ 4.3776, -4.7004],\n",
            "        [ 4.2818, -4.6634],\n",
            "        [ 4.4062, -4.7470],\n",
            "        [ 4.3083, -4.6885],\n",
            "        [ 4.4211, -4.7453],\n",
            "        [ 4.3544, -4.7407],\n",
            "        [ 4.3011, -4.5325]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.6495,  4.0327],\n",
            "        [-3.5581,  3.9962],\n",
            "        [ 3.9650, -4.6375],\n",
            "        [-3.5030,  3.9710],\n",
            "        [-3.5024,  3.9742],\n",
            "        [ 4.2087, -4.6279],\n",
            "        [ 4.3730, -4.6811],\n",
            "        [ 4.3575, -4.7548],\n",
            "        [ 4.1740, -4.6139],\n",
            "        [ 4.3063, -4.7618],\n",
            "        [ 4.1931, -4.5976],\n",
            "        [ 4.2687, -4.6934],\n",
            "        [ 4.2818, -4.7587],\n",
            "        [ 4.4156, -4.7104],\n",
            "        [ 4.2995, -4.6593],\n",
            "        [ 4.2045, -4.6312]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.1255, -4.5835],\n",
            "        [ 4.3160, -4.6738],\n",
            "        [ 4.3907, -4.7751],\n",
            "        [ 4.3737, -4.6882],\n",
            "        [ 4.3632, -4.7080],\n",
            "        [-3.4682,  3.9347],\n",
            "        [ 4.4010, -4.7674],\n",
            "        [ 4.4192, -4.7406],\n",
            "        [ 4.3533, -4.5213],\n",
            "        [ 4.2528, -4.6342],\n",
            "        [ 4.3816, -4.7000],\n",
            "        [ 4.3412, -4.7208],\n",
            "        [ 4.2679, -4.6727],\n",
            "        [ 4.3545, -4.6659],\n",
            "        [ 4.1658, -4.5560],\n",
            "        [ 4.2410, -4.6629]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.4042, -4.5910],\n",
            "        [ 4.4312, -4.7107],\n",
            "        [ 4.2321, -4.5242],\n",
            "        [ 4.3764, -4.6307],\n",
            "        [ 4.1442, -4.5684],\n",
            "        [ 4.3543, -4.7724],\n",
            "        [ 4.2470, -4.6605],\n",
            "        [ 4.3223, -4.6825],\n",
            "        [ 4.3030, -4.7089],\n",
            "        [-3.6026,  4.0039],\n",
            "        [ 4.2880, -4.5773],\n",
            "        [-3.6102,  4.0151],\n",
            "        [ 4.3679, -4.7152],\n",
            "        [ 4.3285, -4.7046],\n",
            "        [ 4.3901, -4.6850],\n",
            "        [ 4.2209, -4.7009]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3650, -4.7360],\n",
            "        [ 4.3652, -4.6642],\n",
            "        [-3.4808,  3.9135],\n",
            "        [ 4.2769, -4.5581],\n",
            "        [ 4.2119, -4.6485],\n",
            "        [ 4.0903, -4.6196],\n",
            "        [ 4.3919, -4.7568],\n",
            "        [ 4.3319, -4.6864],\n",
            "        [ 4.3667, -4.7328],\n",
            "        [ 4.3059, -4.6365],\n",
            "        [-3.7015,  4.0187],\n",
            "        [ 4.4020, -4.6913],\n",
            "        [-3.6082,  4.0173],\n",
            "        [-3.3680,  3.9180],\n",
            "        [ 4.3915, -4.7108],\n",
            "        [-3.4790,  3.9318]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.3520,  3.6260],\n",
            "        [-3.7100,  4.0430],\n",
            "        [-3.5493,  3.9952],\n",
            "        [ 4.2602, -4.6441],\n",
            "        [-3.4732,  3.9405],\n",
            "        [ 4.1164, -4.5529],\n",
            "        [ 4.2540, -4.6976],\n",
            "        [ 4.3978, -4.7452],\n",
            "        [ 4.4194, -4.7287],\n",
            "        [ 4.3147, -4.7083],\n",
            "        [ 4.3742, -4.6919],\n",
            "        [ 4.2935, -4.6853],\n",
            "        [ 4.3498, -4.6724],\n",
            "        [ 4.2155, -4.6465],\n",
            "        [ 4.3817, -4.7892],\n",
            "        [-3.5385,  3.9870]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2987, -4.7363],\n",
            "        [ 4.4017, -4.6940],\n",
            "        [ 4.3108, -4.6709],\n",
            "        [ 4.3501, -4.7665],\n",
            "        [ 4.4062, -4.7217],\n",
            "        [ 4.1760, -4.6191],\n",
            "        [ 4.4070, -4.7655],\n",
            "        [-3.7712,  4.0296],\n",
            "        [ 4.3844, -4.7182],\n",
            "        [ 4.3492, -4.7124],\n",
            "        [ 4.3460, -4.6952],\n",
            "        [-3.3182,  3.6789],\n",
            "        [ 4.3007, -4.7801],\n",
            "        [ 4.4078, -4.7610],\n",
            "        [ 4.3691, -4.7234],\n",
            "        [-3.4057,  3.9307]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2200, -4.6505],\n",
            "        [ 4.3574, -4.7564],\n",
            "        [-3.3132,  3.7404],\n",
            "        [ 4.3572, -4.7568],\n",
            "        [ 4.3649, -4.7459],\n",
            "        [ 4.4090, -4.7280],\n",
            "        [-3.6353,  4.0253],\n",
            "        [ 4.3631, -4.7579],\n",
            "        [ 4.2933, -4.7001],\n",
            "        [ 4.3890, -4.7378],\n",
            "        [ 4.1634, -4.5726],\n",
            "        [ 4.2993, -4.6792],\n",
            "        [ 4.1327, -4.6820],\n",
            "        [ 4.2199, -4.6864],\n",
            "        [-3.7664,  4.0630],\n",
            "        [ 4.3759, -4.7026]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.4182, -4.6831],\n",
            "        [ 4.3996, -4.7205],\n",
            "        [ 4.4182, -4.7523],\n",
            "        [ 4.2069, -4.5848],\n",
            "        [ 4.4171, -4.7284],\n",
            "        [ 4.1602, -4.6894],\n",
            "        [ 4.3751, -4.7136],\n",
            "        [ 4.3936, -4.7023],\n",
            "        [ 4.3601, -4.7457],\n",
            "        [ 4.1507, -4.6029],\n",
            "        [ 4.2461, -4.5038],\n",
            "        [ 4.1352, -4.4575],\n",
            "        [ 4.3034, -4.6380],\n",
            "        [ 4.3799, -4.7694],\n",
            "        [ 4.1508, -4.5943],\n",
            "        [ 4.3440, -4.6598]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.4241, -4.7148],\n",
            "        [-2.3758,  2.7344],\n",
            "        [ 4.2808, -4.6404],\n",
            "        [ 4.3310, -4.7731],\n",
            "        [ 4.3357, -4.7696],\n",
            "        [ 4.3706, -4.7807],\n",
            "        [ 4.4054, -4.6524],\n",
            "        [ 4.0921, -4.5497],\n",
            "        [ 4.2820, -4.6120],\n",
            "        [ 4.3172, -4.7402],\n",
            "        [-3.5782,  4.0031],\n",
            "        [ 4.3930, -4.6452],\n",
            "        [ 4.4406, -4.7556],\n",
            "        [ 4.4382, -4.6907],\n",
            "        [ 4.3483, -4.6852],\n",
            "        [ 4.4044, -4.7205]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2586, -4.6870],\n",
            "        [ 4.3441, -4.7090],\n",
            "        [ 4.4429, -4.7462],\n",
            "        [ 4.0309, -4.5372],\n",
            "        [ 4.4121, -4.7476],\n",
            "        [ 4.3761, -4.6843],\n",
            "        [ 4.3793, -4.7767],\n",
            "        [-3.7506,  4.0578],\n",
            "        [ 4.4137, -4.7898],\n",
            "        [-1.9877,  2.1058],\n",
            "        [-3.6268,  4.0032],\n",
            "        [ 4.3609, -4.7595],\n",
            "        [ 4.3552, -4.7454],\n",
            "        [ 4.3029, -4.7131],\n",
            "        [ 4.3591, -4.6956],\n",
            "        [ 4.3142, -4.5586]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2086, -4.6508],\n",
            "        [ 4.4119, -4.7624],\n",
            "        [ 4.3800, -4.7192],\n",
            "        [-3.6424,  4.0157],\n",
            "        [ 4.2970, -4.7271],\n",
            "        [-3.6607,  4.0282],\n",
            "        [ 4.3922, -4.7740],\n",
            "        [ 4.2578, -4.7016],\n",
            "        [ 4.4320, -4.7106],\n",
            "        [ 4.3205, -4.6905],\n",
            "        [ 4.4173, -4.7697],\n",
            "        [ 4.3805, -4.7534],\n",
            "        [ 4.3353, -4.6758],\n",
            "        [ 4.3447, -4.7169],\n",
            "        [ 4.3133, -4.7641],\n",
            "        [ 4.3513, -4.7349]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3518, -4.7422],\n",
            "        [-3.1447,  3.5135],\n",
            "        [-3.6202,  4.0103],\n",
            "        [-3.4210,  3.7892],\n",
            "        [ 4.3260, -4.7106],\n",
            "        [-3.7133,  4.0624],\n",
            "        [ 4.3365, -4.6747],\n",
            "        [ 4.4173, -4.6757],\n",
            "        [-3.6928,  3.9837],\n",
            "        [ 4.3704, -4.7656],\n",
            "        [ 4.3542, -4.7440],\n",
            "        [ 4.4041, -4.6989],\n",
            "        [ 4.3269, -4.6109],\n",
            "        [ 4.3628, -4.7299],\n",
            "        [ 4.3559, -4.6734],\n",
            "        [ 4.2866, -4.7112]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2193, -4.6488],\n",
            "        [ 4.4058, -4.6812],\n",
            "        [ 4.0493, -4.4892],\n",
            "        [ 4.3951, -4.7465],\n",
            "        [ 4.3699, -4.7172],\n",
            "        [ 4.4240, -4.6860],\n",
            "        [ 4.3583, -4.7739],\n",
            "        [ 4.3244, -4.7101],\n",
            "        [ 4.3306, -4.7096],\n",
            "        [ 4.3413, -4.7491],\n",
            "        [ 4.3421, -4.7158],\n",
            "        [ 4.2850, -4.7501],\n",
            "        [ 4.3347, -4.7377],\n",
            "        [ 4.3494, -4.7421],\n",
            "        [ 4.3881, -4.7642],\n",
            "        [-3.6934,  4.0421]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 0.1666, -0.7334],\n",
            "        [ 4.4219, -4.7748],\n",
            "        [ 4.2608, -4.6960],\n",
            "        [ 4.4398, -4.7459],\n",
            "        [ 4.2867, -4.7233],\n",
            "        [ 4.3238, -4.7292],\n",
            "        [ 4.4108, -4.7305],\n",
            "        [ 4.3887, -4.7332],\n",
            "        [ 4.4062, -4.7693],\n",
            "        [ 4.4337, -4.7376],\n",
            "        [ 4.3003, -4.7192],\n",
            "        [-3.6194,  4.0115],\n",
            "        [ 4.4237, -4.7231],\n",
            "        [-3.7108,  4.0549],\n",
            "        [ 4.3725, -4.7304],\n",
            "        [-3.6007,  4.0148]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.4059, -4.7238],\n",
            "        [-3.6270,  4.0314],\n",
            "        [ 4.3878, -4.7916],\n",
            "        [ 4.2897, -4.7427],\n",
            "        [ 4.4266, -4.7684],\n",
            "        [-3.6771,  4.0288],\n",
            "        [ 4.3559, -4.6796],\n",
            "        [ 4.3718, -4.7193],\n",
            "        [ 4.4266, -4.7167],\n",
            "        [ 4.0619, -4.5631],\n",
            "        [ 4.3082, -4.5810],\n",
            "        [ 4.2985, -4.6993],\n",
            "        [ 4.4077, -4.7619],\n",
            "        [-3.8396,  4.0161],\n",
            "        [ 4.2616, -4.5974],\n",
            "        [ 4.3216, -4.6119]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.2963,  3.6387],\n",
            "        [ 4.2800, -4.7411],\n",
            "        [ 4.3235, -4.6199],\n",
            "        [-3.6147,  4.0177],\n",
            "        [ 4.3562, -4.6881],\n",
            "        [ 4.3911, -4.6709],\n",
            "        [ 4.4186, -4.7636],\n",
            "        [ 4.3754, -4.7874],\n",
            "        [ 4.3156, -4.7326],\n",
            "        [-3.3893,  3.9113],\n",
            "        [ 4.3241, -4.7620],\n",
            "        [ 4.3974, -4.7945],\n",
            "        [ 4.3189, -4.6613],\n",
            "        [ 4.3328, -4.7458],\n",
            "        [ 4.3196, -4.6722],\n",
            "        [ 4.2272, -4.6892]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3444, -4.7757],\n",
            "        [ 4.4572, -4.7361],\n",
            "        [ 4.2652, -4.6095],\n",
            "        [-3.6430,  4.0259],\n",
            "        [-3.5109,  3.8346],\n",
            "        [ 4.3184, -4.8037],\n",
            "        [ 4.3746, -4.7276],\n",
            "        [ 4.4135, -4.7512],\n",
            "        [ 4.4240, -4.7760],\n",
            "        [ 4.3623, -4.7035],\n",
            "        [ 4.4402, -4.7777],\n",
            "        [ 4.4044, -4.7329],\n",
            "        [-3.6444,  4.0355],\n",
            "        [ 4.3271, -4.6943],\n",
            "        [ 4.3780, -4.7174],\n",
            "        [ 4.3359, -4.7446]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[-3.5524,  3.9636],\n",
            "        [ 4.3191, -4.7321],\n",
            "        [ 4.0894, -4.6183],\n",
            "        [ 4.4588, -4.7477],\n",
            "        [ 4.4407, -4.7841],\n",
            "        [ 4.3791, -4.7093],\n",
            "        [ 4.4298, -4.8000],\n",
            "        [-3.3386,  3.8711],\n",
            "        [ 4.3579, -4.6539],\n",
            "        [ 4.4346, -4.7229],\n",
            "        [-3.4124,  3.7177],\n",
            "        [ 4.3515, -4.7367],\n",
            "        [ 4.2182, -4.7095],\n",
            "        [ 4.3557, -4.7225],\n",
            "        [ 4.4557, -4.7476],\n",
            "        [ 4.1693, -4.6149]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3959, -4.7530],\n",
            "        [-1.6600,  1.8360],\n",
            "        [-3.3461,  3.8940],\n",
            "        [ 4.4155, -4.7161],\n",
            "        [ 4.3305, -4.7589],\n",
            "        [ 4.3332, -4.7769],\n",
            "        [ 4.3819, -4.7690],\n",
            "        [ 4.3821, -4.6776],\n",
            "        [-3.6564,  4.0228],\n",
            "        [ 4.4156, -4.7986],\n",
            "        [ 4.1122, -4.5641],\n",
            "        [-3.7038,  3.9861],\n",
            "        [ 4.3809, -4.7323],\n",
            "        [ 4.4397, -4.7923],\n",
            "        [ 4.4326, -4.7503],\n",
            "        [ 4.4491, -4.7591]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.4029, -4.6724],\n",
            "        [ 4.2784, -4.7889],\n",
            "        [ 4.4297, -4.7327],\n",
            "        [ 4.4428, -4.7982],\n",
            "        [ 4.3018, -4.7287],\n",
            "        [-3.5563,  4.0082],\n",
            "        [-3.5851,  4.0114],\n",
            "        [ 4.3467, -4.7535],\n",
            "        [ 4.4316, -4.7773],\n",
            "        [-3.6560,  4.0275],\n",
            "        [-3.6427,  3.9724],\n",
            "        [ 4.2363, -4.5174],\n",
            "        [-3.6427,  3.9724],\n",
            "        [ 4.3751, -4.7307],\n",
            "        [ 4.3583, -4.6492],\n",
            "        [ 4.4464, -4.7914]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.3738, -4.7699],\n",
            "        [ 4.4400, -4.7818],\n",
            "        [ 4.4022, -4.7926],\n",
            "        [ 4.4688, -4.7869],\n",
            "        [ 4.3708, -4.8098],\n",
            "        [ 4.4575, -4.6955],\n",
            "        [ 4.2934, -4.7119],\n",
            "        [ 4.3808, -4.7318],\n",
            "        [ 4.4537, -4.7942],\n",
            "        [ 4.3210, -4.7411],\n",
            "        [ 4.4033, -4.7855],\n",
            "        [ 4.4467, -4.7538],\n",
            "        [ 4.4496, -4.7984],\n",
            "        [-3.5208,  4.0077],\n",
            "        [ 4.4284, -4.7303],\n",
            "        [ 4.4065, -4.7031]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.4600, -4.7508],\n",
            "        [ 4.4247, -4.7717],\n",
            "        [ 4.3271, -4.7725],\n",
            "        [ 4.4224, -4.7393],\n",
            "        [ 4.4038, -4.7937],\n",
            "        [-3.6933,  4.0453],\n",
            "        [ 4.3300, -4.6274],\n",
            "        [ 4.4076, -4.7830],\n",
            "        [ 4.2569, -4.7318],\n",
            "        [-3.7297,  4.0606],\n",
            "        [ 4.4428, -4.7097],\n",
            "        [ 4.4711, -4.7712],\n",
            "        [-2.2898,  2.6295],\n",
            "        [ 4.3975, -4.7388],\n",
            "        [ 4.3820, -4.7585],\n",
            "        [ 4.4239, -4.7771]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.4612, -4.7388],\n",
            "        [ 4.4551, -4.7656],\n",
            "        [ 4.1442, -4.6664],\n",
            "        [ 4.3943, -4.8011],\n",
            "        [ 4.4617, -4.7702],\n",
            "        [ 4.4629, -4.7689],\n",
            "        [ 4.4545, -4.7566],\n",
            "        [ 4.2995, -4.7203],\n",
            "        [ 4.4629, -4.7634],\n",
            "        [ 4.3956, -4.7044],\n",
            "        [-3.6181,  4.0260],\n",
            "        [-3.7108,  4.0438],\n",
            "        [ 4.3707, -4.7046],\n",
            "        [ 4.4084, -4.7951],\n",
            "        [ 4.3887, -4.7847],\n",
            "        [ 4.3543, -4.7087]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.2924, -4.7357],\n",
            "        [-2.2351,  2.5332],\n",
            "        [ 4.3594, -4.7659],\n",
            "        [ 4.4439, -4.7835],\n",
            "        [ 4.4647, -4.7736],\n",
            "        [ 4.4590, -4.7821],\n",
            "        [ 4.3958, -4.7487],\n",
            "        [ 4.4284, -4.7670],\n",
            "        [ 4.4067, -4.8222],\n",
            "        [ 4.4497, -4.7351],\n",
            "        [ 4.4179, -4.7584],\n",
            "        [ 4.4716, -4.7131],\n",
            "        [ 4.3810, -4.7314],\n",
            "        [ 4.3628, -4.6779],\n",
            "        [ 4.3747, -4.8324],\n",
            "        [ 4.4088, -4.7951]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "4 SequenceClassifierOutput(loss=tensor(0.0002, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 4.4145, -4.8033],\n",
            "        [ 4.4483, -4.7628],\n",
            "        [ 4.2666, -4.7250],\n",
            "        [ 4.4598, -4.7264],\n",
            "        [-3.6098,  3.9754],\n",
            "        [ 4.4079, -4.7779],\n",
            "        [ 4.4377, -4.6769],\n",
            "        [ 4.4041, -4.7977],\n",
            "        [ 4.3541, -4.7286],\n",
            "        [-3.5257,  3.8703],\n",
            "        [ 4.4530, -4.7622],\n",
            "        [ 4.4557, -4.7094]], device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sghgHr4XPmF8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}